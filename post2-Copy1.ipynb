{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv('train.tsv', sep='\\t')\n",
    "df_train, df_test = train_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1111901, 8), (370634, 8))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1169704</th>\n",
       "      <td>1169704</td>\n",
       "      <td>Jessica Simpson IPad Mini Cover</td>\n",
       "      <td>3</td>\n",
       "      <td>Electronics/Cell Phones &amp; Accessories/Cases, C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Great iPad mini case/cover. Has room for your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383372</th>\n",
       "      <td>383372</td>\n",
       "      <td>Aum Alex and Ani bracelet</td>\n",
       "      <td>3</td>\n",
       "      <td>Women/Jewelry/Bracelets</td>\n",
       "      <td>ALEX AND ANI</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Aum symbol Alex and Ani bracelet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946265</th>\n",
       "      <td>946265</td>\n",
       "      <td>Chantel bundle special</td>\n",
       "      <td>3</td>\n",
       "      <td>Women/Dresses/Full-Length</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1</td>\n",
       "      <td>These two dresses are listed individually in m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103938</th>\n",
       "      <td>1103938</td>\n",
       "      <td>Sticker - Mickey Hat - iPhone - Black</td>\n",
       "      <td>1</td>\n",
       "      <td>Electronics/Cell Phones &amp; Accessories/Cell Pho...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Sticker - Disney Mickey Hat - iPhone - Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960040</th>\n",
       "      <td>960040</td>\n",
       "      <td>Free ship xs pink vs panties</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Underwear/Panties</td>\n",
       "      <td>PINK</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Brand new Nwt Green panty is thong Other two a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         train_id                                   name  item_condition_id  \\\n",
       "1169704   1169704        Jessica Simpson IPad Mini Cover                  3   \n",
       "383372     383372              Aum Alex and Ani bracelet                  3   \n",
       "946265     946265                 Chantel bundle special                  3   \n",
       "1103938   1103938  Sticker - Mickey Hat - iPhone - Black                  1   \n",
       "960040     960040           Free ship xs pink vs panties                  1   \n",
       "\n",
       "                                             category_name    brand_name  \\\n",
       "1169704  Electronics/Cell Phones & Accessories/Cases, C...           NaN   \n",
       "383372                             Women/Jewelry/Bracelets  ALEX AND ANI   \n",
       "946265                           Women/Dresses/Full-Length           NaN   \n",
       "1103938  Electronics/Cell Phones & Accessories/Cell Pho...           NaN   \n",
       "960040                             Women/Underwear/Panties          PINK   \n",
       "\n",
       "         price  shipping                                   item_description  \n",
       "1169704   14.0         0  Great iPad mini case/cover. Has room for your ...  \n",
       "383372    14.0         0                   Aum symbol Alex and Ani bracelet  \n",
       "946265   120.0         1  These two dresses are listed individually in m...  \n",
       "1103938    3.0         1       Sticker - Disney Mickey Hat - iPhone - Black  \n",
       "960040    13.0         1  Brand new Nwt Green panty is thong Other two a...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.111901e+06</td>\n",
       "      <td>1111901</td>\n",
       "      <td>1.111901e+06</td>\n",
       "      <td>1107138</td>\n",
       "      <td>637030</td>\n",
       "      <td>1.111901e+06</td>\n",
       "      <td>1.111901e+06</td>\n",
       "      <td>1111898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>936631</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1263</td>\n",
       "      <td>4456</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>967670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Bundle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Women/Athletic Apparel/Pants, Tights, Leggings</td>\n",
       "      <td>Nike</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No description yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1663</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44950</td>\n",
       "      <td>40514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.410784e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.907864e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.677402e+01</td>\n",
       "      <td>4.467430e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.278977e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.032937e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.880237e+01</td>\n",
       "      <td>4.971558e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.705090e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.411490e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.700000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.111453e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.900000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.482532e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.009000e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            train_id     name  item_condition_id  \\\n",
       "count   1.111901e+06  1111901       1.111901e+06   \n",
       "unique           NaN   936631                NaN   \n",
       "top              NaN   Bundle                NaN   \n",
       "freq             NaN     1663                NaN   \n",
       "mean    7.410784e+05      NaN       1.907864e+00   \n",
       "std     4.278977e+05      NaN       9.032937e-01   \n",
       "min     0.000000e+00      NaN       1.000000e+00   \n",
       "25%     3.705090e+05      NaN       1.000000e+00   \n",
       "50%     7.411490e+05      NaN       2.000000e+00   \n",
       "75%     1.111453e+06      NaN       3.000000e+00   \n",
       "max     1.482532e+06      NaN       5.000000e+00   \n",
       "\n",
       "                                         category_name brand_name  \\\n",
       "count                                          1107138     637030   \n",
       "unique                                            1263       4456   \n",
       "top     Women/Athletic Apparel/Pants, Tights, Leggings       Nike   \n",
       "freq                                             44950      40514   \n",
       "mean                                               NaN        NaN   \n",
       "std                                                NaN        NaN   \n",
       "min                                                NaN        NaN   \n",
       "25%                                                NaN        NaN   \n",
       "50%                                                NaN        NaN   \n",
       "75%                                                NaN        NaN   \n",
       "max                                                NaN        NaN   \n",
       "\n",
       "               price      shipping    item_description  \n",
       "count   1.111901e+06  1.111901e+06             1111898  \n",
       "unique           NaN           NaN              967670  \n",
       "top              NaN           NaN  No description yet  \n",
       "freq             NaN           NaN               61777  \n",
       "mean    2.677402e+01  4.467430e-01                 NaN  \n",
       "std     3.880237e+01  4.971558e-01                 NaN  \n",
       "min     0.000000e+00  0.000000e+00                 NaN  \n",
       "25%     1.000000e+01  0.000000e+00                 NaN  \n",
       "50%     1.700000e+01  0.000000e+00                 NaN  \n",
       "75%     2.900000e+01  1.000000e+00                 NaN  \n",
       "max     2.009000e+03  1.000000e+00                 NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/dante/venvs/python36/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/dante/venvs/python36/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/home/dante/venvs/python36/lib/python3.6/site-packages/pandas/core/frame.py:3790: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n",
      "/home/dante/venvs/python36/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/dante/venvs/python36/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "def preprocess(df):\n",
    "    category_ids = {v: i for i, v in enumerate(df.category_name.unique(), start=1)}\n",
    "    brand_ids = {v: i for i, v in enumerate(df.brand_name.unique(), start=1)}\n",
    "    df['category_id'] = df.category_name.map(category_ids)\n",
    "    df['brand_id'] = df.brand_name.map(brand_ids)\n",
    "    \n",
    "    df[['category_id', 'brand_id', 'item_condition_id']].fillna(0, inplace=True)\n",
    "    df['text'] = df.name + ' ' + df.item_description.str.replace('No description yet', '')\n",
    "    df['text'] = df.text.astype(str)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_train = preprocess(df_train)\n",
    "df_test = preprocess(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.111901e+06\n",
       "mean     2.899281e+01\n",
       "std      3.090929e+01\n",
       "min      0.000000e+00\n",
       "25%      1.000000e+01\n",
       "50%      1.900000e+01\n",
       "75%      3.500000e+01\n",
       "max      2.510000e+02\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.text.str.count(' ').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "      <th>category_id</th>\n",
       "      <th>brand_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1169704</th>\n",
       "      <td>1169704</td>\n",
       "      <td>Jessica Simpson IPad Mini Cover</td>\n",
       "      <td>3</td>\n",
       "      <td>Electronics/Cell Phones &amp; Accessories/Cases, C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Great iPad mini case/cover. Has room for your ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Jessica Simpson IPad Mini Cover Great iPad min...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383372</th>\n",
       "      <td>383372</td>\n",
       "      <td>Aum Alex and Ani bracelet</td>\n",
       "      <td>3</td>\n",
       "      <td>Women/Jewelry/Bracelets</td>\n",
       "      <td>ALEX AND ANI</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Aum symbol Alex and Ani bracelet</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Aum Alex and Ani bracelet Aum symbol Alex and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946265</th>\n",
       "      <td>946265</td>\n",
       "      <td>Chantel bundle special</td>\n",
       "      <td>3</td>\n",
       "      <td>Women/Dresses/Full-Length</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1</td>\n",
       "      <td>These two dresses are listed individually in m...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Chantel bundle special These two dresses are l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103938</th>\n",
       "      <td>1103938</td>\n",
       "      <td>Sticker - Mickey Hat - iPhone - Black</td>\n",
       "      <td>1</td>\n",
       "      <td>Electronics/Cell Phones &amp; Accessories/Cell Pho...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Sticker - Disney Mickey Hat - iPhone - Black</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Sticker - Mickey Hat - iPhone - Black Sticker ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960040</th>\n",
       "      <td>960040</td>\n",
       "      <td>Free ship xs pink vs panties</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Underwear/Panties</td>\n",
       "      <td>PINK</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Brand new Nwt Green panty is thong Other two a...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Free ship xs pink vs panties Brand new Nwt Gre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         train_id                                   name  item_condition_id  \\\n",
       "1169704   1169704        Jessica Simpson IPad Mini Cover                  3   \n",
       "383372     383372              Aum Alex and Ani bracelet                  3   \n",
       "946265     946265                 Chantel bundle special                  3   \n",
       "1103938   1103938  Sticker - Mickey Hat - iPhone - Black                  1   \n",
       "960040     960040           Free ship xs pink vs panties                  1   \n",
       "\n",
       "                                             category_name    brand_name  \\\n",
       "1169704  Electronics/Cell Phones & Accessories/Cases, C...           NaN   \n",
       "383372                             Women/Jewelry/Bracelets  ALEX AND ANI   \n",
       "946265                           Women/Dresses/Full-Length           NaN   \n",
       "1103938  Electronics/Cell Phones & Accessories/Cell Pho...           NaN   \n",
       "960040                             Women/Underwear/Panties          PINK   \n",
       "\n",
       "         price  shipping                                   item_description  \\\n",
       "1169704   14.0         0  Great iPad mini case/cover. Has room for your ...   \n",
       "383372    14.0         0                   Aum symbol Alex and Ani bracelet   \n",
       "946265   120.0         1  These two dresses are listed individually in m...   \n",
       "1103938    3.0         1       Sticker - Disney Mickey Hat - iPhone - Black   \n",
       "960040    13.0         1  Brand new Nwt Green panty is thong Other two a...   \n",
       "\n",
       "         category_id  brand_id  \\\n",
       "1169704            1         1   \n",
       "383372             2         2   \n",
       "946265             3         1   \n",
       "1103938            4         1   \n",
       "960040             5         3   \n",
       "\n",
       "                                                      text  \n",
       "1169704  Jessica Simpson IPad Mini Cover Great iPad min...  \n",
       "383372   Aum Alex and Ani bracelet Aum symbol Alex and ...  \n",
       "946265   Chantel bundle special These two dresses are l...  \n",
       "1103938  Sticker - Mickey Hat - iPhone - Black Sticker ...  \n",
       "960040   Free ship xs pink vs panties Brand new Nwt Gre...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build byte pair encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, parent=None):\n",
    "        self.parent = parent\n",
    "        self.children = {}\n",
    "        self.index = None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Node(index={self.index}, children={self.children})'\n",
    "    \n",
    "    def get(self, key, default=None):\n",
    "        return self.children.get(key, default)\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return self.children[key]\n",
    "    \n",
    "    def __setitem__(self, key, value):\n",
    "        self.children[key] = value\n",
    "        \n",
    "    def __contains__(self, key):\n",
    "        return key in self.children\n",
    "\n",
    "\n",
    "def build_bpe_tree(vocab):\n",
    "    root = Node()\n",
    "    for word, index in vocab.items():\n",
    "        current_node = root\n",
    "        for n, c in enumerate(word, start=1):\n",
    "            if not c in current_node:\n",
    "                current_node[c] = Node()\n",
    "            current_node = current_node[c]\n",
    "            if n == len(word):\n",
    "                current_node.index = index\n",
    "    return root\n",
    "\n",
    "\n",
    "def apply_bpe_tree(text, tree):\n",
    "    output = []\n",
    "    pos = 0\n",
    "    last_node = tree\n",
    "    while pos <= len(text) - 1:\n",
    "        node = last_node.get(text[pos])\n",
    "        # we can't search the tree any further\n",
    "        if node is None:\n",
    "            # we couldn't search the tree any further but we\n",
    "            # ended up at a node that doesn't correspond to a\n",
    "            # word in the learned vocabulary.\n",
    "            # In this case we'll traverse back through the tree\n",
    "            # until we hit a node with an index.\n",
    "            if last_node.index is None:\n",
    "                while last_node.index is not None:\n",
    "                    last_node = last_node.parent\n",
    "                    pos -= 1\n",
    "            # add the last seen index to the output\n",
    "            # and reset variables for next run through\n",
    "            output.append(last_node.index)\n",
    "            if last_node is not tree:\n",
    "                last_node = tree\n",
    "                continue\n",
    "            node = tree\n",
    "        last_node = node\n",
    "        pos += 1\n",
    "    output.append(last_node.index)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "def get_stats(list vocab):\n",
    "    cdef c1, c2\n",
    "    cdef list word\n",
    "    cdef int freq, vocab_pos, word_pos\n",
    "    cdef dict pair_stats = {}\n",
    "    cdef dict pair_indices = {}\n",
    "    cdef tuple pair\n",
    "    for vocab_pos in range(len(vocab)):\n",
    "        word, freq = vocab[vocab_pos]\n",
    "        for word_pos in range(len(word) - 1):\n",
    "            pair = word[word_pos], word[word_pos + 1]\n",
    "            if not pair in pair_stats:\n",
    "                pair_stats[pair] = 0\n",
    "            pair_stats[pair] += freq\n",
    "            if not pair in pair_indices:\n",
    "                pair_indices[pair] = []\n",
    "            pair_indices[pair].append((vocab_pos, word_pos))\n",
    "    return pair_stats, pair_indices\n",
    "\n",
    "\n",
    "def merge_vocab(tuple pair, list vocab, list pair_indices):\n",
    "    cdef int vocab_pos, word_pos\n",
    "    cdef list word\n",
    "    for vocab_pos, word_pos in reversed(pair_indices):\n",
    "        word, _ = vocab[vocab_pos]\n",
    "        word[word_pos] = word[word_pos] + word[word_pos + 1]\n",
    "        word.pop(word_pos + 1)\n",
    "    return vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import time\n",
    "\n",
    "import sklearn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class BytePairEncoder(sklearn.base.TransformerMixin):    \n",
    "    _unkown_character = '<unk>'\n",
    "    _space_escape = '▁'\n",
    "\n",
    "    def __init__(self, target_vocab_size, vocab_threshold=None, log_level=None):\n",
    "        self.target_vocab_size = target_vocab_size\n",
    "        self.log_level = log_level\n",
    "        self.vocab_threshold = vocab_threshold\n",
    "\n",
    "        # these will all be set during .fit()\n",
    "        self.vocab = None\n",
    "        self._vocab_stats = None\n",
    "        self._reverse_vocab = None\n",
    "        self._bpe_tree = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        # get the initial vocabular consisting of all unique characters\n",
    "        initial_vocab = set(X)\n",
    "        initial_vocab.add(self._space_escape)\n",
    "\n",
    "        words = self._split_X(X)\n",
    "        vocab = [(list(word), freq) for word, freq in collections.Counter(words).items()]\n",
    "\n",
    "        t_started = time.time()\n",
    "        i = 0\n",
    "        while self._vocab_size(vocab) < self.target_vocab_size:\n",
    "            if self.log_level is not None \\\n",
    "                    and i and (i + 1) % self.log_level == 0:\n",
    "                print(f'{i+1} iterations complete in {time.time() - t_started}')\n",
    "            pair_stats, pair_index = get_stats(vocab)\n",
    "            best = max(pair_stats, key=pair_stats.get)\n",
    "            if self.vocab_threshold is not None \\\n",
    "                    and pair_stats[best] < self.vocab_threshold:\n",
    "                print(f'Stopping after {i} iterations. Best pair occurs '\n",
    "                      f'{pair_stats[best]} < {self.vocab_threshold} times')\n",
    "                break\n",
    "            vocab = merge_vocab(best, vocab, pair_index[best])\n",
    "            i += 1\n",
    "\n",
    "        # build the final vocabulary\n",
    "        vocab_stats = collections.Counter()\n",
    "        _ = [vocab_stats.update({subword: freq})\n",
    "                                for word, freq in vocab\n",
    "                                for subword in word]\n",
    "        final_vocab = set(vocab_stats)\n",
    "        final_vocab.update(initial_vocab)\n",
    "        final_vocab = {k: i for i, k in enumerate(final_vocab, start=1)}\n",
    "        final_vocab[self._unkown_character] = 0\n",
    "        self.vocab = final_vocab\n",
    "\n",
    "        # these are needed for .transform() and .inverse_transform()\n",
    "        self._reverse_vocab = {i: k for k, i in self.vocab.items()}\n",
    "        self._bpe_tree = build_bpe_tree(self.vocab)\n",
    "\n",
    "        # keep this for curiosity/debugging\n",
    "        self._vocab_stats = vocab_stats\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = self._split_X(X)\n",
    "        return np.concatenate([self._transform_string(x) for x in X])\n",
    "\n",
    "    def _transform_string(self, X):\n",
    "        tokens = apply_bpe_tree(X, self._bpe_tree)\n",
    "        return np.array([0 if t is None else t for t in tokens])                \n",
    "\n",
    "    def inverse_transform(self, X):\n",
    "        return [self._reverse_vocab[t] for t in X]\n",
    "\n",
    "    def _split_X(self, X):\n",
    "        return [word + self._space_escape for word in X.split()]\n",
    "\n",
    "    def _vocab_size(self, vocab):\n",
    "        return len(set(subword for word, _ in vocab for subword in word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Size small Bought from converse store New with tags Color is black retail 19.99$ Size 6 toddler kids unisex red,black,white Uniqlo black zip up. Size '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe_text = ' '.join(df_train.item_description.sample(30000))\n",
    "bpe_text[:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bpe_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 iterations complete in 319.35621762275696\n",
      "2000 iterations complete in 649.30331158638\n",
      "3000 iterations complete in 986.5436532497406\n",
      "4000 iterations complete in 1325.2175116539001\n",
      "5000 iterations complete in 1665.115700006485\n",
      "6000 iterations complete in 2003.7753021717072\n",
      "7000 iterations complete in 2338.2903730869293\n",
      "8000 iterations complete in 2670.8005607128143\n",
      "9000 iterations complete in 3000.8742854595184\n",
      "10000 iterations complete in 3329.566202402115\n",
      "11000 iterations complete in 3653.9510748386383\n",
      "12000 iterations complete in 3974.5807600021362\n",
      "13000 iterations complete in 4291.8101375103\n",
      "14000 iterations complete in 4604.424010753632\n",
      "15000 iterations complete in 4913.072614192963\n",
      "16000 iterations complete in 5218.674493312836\n",
      "17000 iterations complete in 5519.2871832847595\n",
      "18000 iterations complete in 5816.421611070633\n",
      "19000 iterations complete in 6109.66294169426\n",
      "20000 iterations complete in 6399.095827817917\n",
      "21000 iterations complete in 6684.125005722046\n",
      "22000 iterations complete in 6965.381956100464\n",
      "23000 iterations complete in 7245.120498418808\n",
      "24000 iterations complete in 7519.603207826614\n",
      "Stopping after 24741 iterations. Best pair occurs 4 < 5 times\n",
      "CPU times: user 2h 8min 35s, sys: 1.65 s, total: 2h 8min 37s\n",
      "Wall time: 2h 8min 44s\n"
     ]
    }
   ],
   "source": [
    "bpe = BytePairEncoder(30000, log_level=1000, vocab_threshold=5)\n",
    "%time bpe.fit(bpe_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24557"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bpe.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'System': 1,\n",
       " 'Frances': 2,\n",
       " 'cast': 3,\n",
       " 'FedEx▁': 4,\n",
       " 'creamy▁': 5,\n",
       " 'Tiffany▁': 6,\n",
       " 'sive▁': 7,\n",
       " 'wings▁': 8,\n",
       " 'eu': 9,\n",
       " 'ona▁': 10,\n",
       " 'shire▁': 11,\n",
       " 'DOU': 12,\n",
       " 'Bees▁': 13,\n",
       " 'Rat': 14,\n",
       " 'EXCLUS': 15,\n",
       " 'mer)▁': 16,\n",
       " 'Sequin▁': 17,\n",
       " 'spaghetti▁': 18,\n",
       " 'MSRP:▁': 19,\n",
       " 'kin▁': 20,\n",
       " 'empty▁': 21,\n",
       " 'zed▁': 22,\n",
       " 'scape▁': 23,\n",
       " 'steel.▁': 24,\n",
       " 'shu': 25,\n",
       " 'y;▁': 26,\n",
       " 'FORM▁': 27,\n",
       " 'HUGE▁': 28,\n",
       " 'Blur▁': 29,\n",
       " 'RARE': 30,\n",
       " 'pl': 31,\n",
       " 'count': 32,\n",
       " '●●▁': 33,\n",
       " 'fabric': 34,\n",
       " 'Froz': 35,\n",
       " \"Disney's▁\": 36,\n",
       " 'towards▁': 37,\n",
       " '21,▁': 38,\n",
       " 'langu': 39,\n",
       " 'Tw': 40,\n",
       " 'only!▁': 41,\n",
       " 'sh!▁': 42,\n",
       " 'Playstation▁': 43,\n",
       " 'Gabbana▁': 44,\n",
       " 'AM': 45,\n",
       " 'Oh▁': 46,\n",
       " 'Ornam': 47,\n",
       " '6.5': 48,\n",
       " 'free/': 49,\n",
       " 'image▁': 50,\n",
       " 'mugs,▁': 51,\n",
       " '36\"▁': 52,\n",
       " 'War▁': 53,\n",
       " 'shir': 54,\n",
       " 'Best▁': 55,\n",
       " 'B,▁': 56,\n",
       " 'individual▁': 57,\n",
       " 'Mercari': 58,\n",
       " 'AV': 59,\n",
       " 'Jack▁': 60,\n",
       " 'Collagen▁': 61,\n",
       " 'Knee▁': 62,\n",
       " 'etc..▁': 63,\n",
       " 'ussy▁': 64,\n",
       " 'hands▁': 65,\n",
       " 'GY': 66,\n",
       " 'Helps▁': 67,\n",
       " 'stuck▁': 68,\n",
       " 'chak': 69,\n",
       " '************': 70,\n",
       " 'sad▁': 71,\n",
       " 'plumping▁': 72,\n",
       " 'closet▁': 73,\n",
       " 'Ro': 74,\n",
       " 'Than': 75,\n",
       " '11.5▁': 76,\n",
       " 'am,▁': 77,\n",
       " 'DATE▁': 78,\n",
       " 'Lenses▁': 79,\n",
       " 'ears,▁': 80,\n",
       " 'hex': 81,\n",
       " 'tun': 82,\n",
       " 'skelet': 83,\n",
       " '(size▁': 84,\n",
       " 'Smart▁': 85,\n",
       " 'cat▁': 86,\n",
       " 'bam': 87,\n",
       " 'NATURAL▁': 88,\n",
       " 'delays.▁': 89,\n",
       " 'look.▁': 90,\n",
       " 'Android,▁': 91,\n",
       " 'savings!▁': 92,\n",
       " 'Shipping:▁': 93,\n",
       " 'policy)▁': 94,\n",
       " 'orange▁': 95,\n",
       " 'flaws/': 96,\n",
       " 'Purchase▁': 97,\n",
       " 'effected.▁': 98,\n",
       " 'book▁': 99,\n",
       " 'T-Mobile▁': 100,\n",
       " '3.5\"▁': 101,\n",
       " 'NIKE▁': 102,\n",
       " 'Awesome▁': 103,\n",
       " 'Leaves▁': 104,\n",
       " '\"lowest\"▁': 105,\n",
       " 'CONDITION!▁': 106,\n",
       " '-High▁': 107,\n",
       " \"WOMEN'S▁\": 108,\n",
       " 'MUL': 109,\n",
       " 'Shoulder▁': 110,\n",
       " 'interested.▁': 111,\n",
       " 'ender▁': 112,\n",
       " 'locket▁': 113,\n",
       " 'as:▁': 114,\n",
       " 'person▁': 115,\n",
       " 'time': 116,\n",
       " 'brid': 117,\n",
       " 'PIL': 118,\n",
       " 'OTHER': 119,\n",
       " 'protec': 120,\n",
       " 'drawer.▁': 121,\n",
       " 'incredible▁': 122,\n",
       " 'US▁': 123,\n",
       " 'problems,▁': 124,\n",
       " 'chee': 125,\n",
       " 'r.▁': 126,\n",
       " \"Women's▁\": 127,\n",
       " 'masters▁': 128,\n",
       " 'Ē': 129,\n",
       " 'electric▁': 130,\n",
       " 'FedEX,▁': 131,\n",
       " 'Retail:▁': 132,\n",
       " 'Camouflage▁': 133,\n",
       " 'indoors▁': 134,\n",
       " '*If▁': 135,\n",
       " 'Amber▁': 136,\n",
       " 'measurement▁': 137,\n",
       " 'top': 138,\n",
       " 'Jord': 139,\n",
       " '[rm],': 140,\n",
       " 'perform': 141,\n",
       " 'cotton,▁': 142,\n",
       " 'pencils▁': 143,\n",
       " 'Loose▁': 144,\n",
       " 'Levi▁': 145,\n",
       " 'toothpaste▁': 146,\n",
       " 'down.▁': 147,\n",
       " 'save**▁': 148,\n",
       " 'Content:▁': 149,\n",
       " 'Stand': 150,\n",
       " 'manufacturer': 151,\n",
       " 'Carbon▁': 152,\n",
       " 'shape▁': 153,\n",
       " 'outlet▁': 154,\n",
       " 'low-balling▁': 155,\n",
       " '(White,▁': 156,\n",
       " 'random': 157,\n",
       " 'unopened▁': 158,\n",
       " 'bamboo▁': 159,\n",
       " 'authentic,▁': 160,\n",
       " '❀▁': 161,\n",
       " 'vac': 162,\n",
       " 'glo': 163,\n",
       " '1x': 164,\n",
       " 'Exact▁': 165,\n",
       " 'Blooming▁': 166,\n",
       " 'romper.▁': 167,\n",
       " 'decrease▁': 168,\n",
       " 'deluxe▁': 169,\n",
       " '(Blue,▁': 170,\n",
       " 'only)▁': 171,\n",
       " 'taupe': 172,\n",
       " 'ington▁': 173,\n",
       " 'outside.▁': 174,\n",
       " 'Ordered▁': 175,\n",
       " 'Minis▁': 176,\n",
       " 'Balance▁': 177,\n",
       " 'Bir': 178,\n",
       " 'Engl': 179,\n",
       " 'DIREC': 180,\n",
       " 'you': 181,\n",
       " 'lobster▁': 182,\n",
       " 't.': 183,\n",
       " 'description▁': 184,\n",
       " 'used,▁': 185,\n",
       " 'nude.▁': 186,\n",
       " 'free▁': 187,\n",
       " 'battery.▁': 188,\n",
       " 'apa▁': 189,\n",
       " 'CST▁': 190,\n",
       " 'Easily▁': 191,\n",
       " '4/4S▁': 192,\n",
       " 'ne.▁': 193,\n",
       " 'FFE': 194,\n",
       " '31\"▁': 195,\n",
       " '™': 196,\n",
       " 'BUND': 197,\n",
       " 'improved▁': 198,\n",
       " 'Guarante': 199,\n",
       " 'proper▁': 200,\n",
       " 'damages▁': 201,\n",
       " 'Till': 202,\n",
       " 'package': 203,\n",
       " '1PC▁': 204,\n",
       " 'it,▁': 205,\n",
       " 'thrown▁': 206,\n",
       " '❌❌': 207,\n",
       " 'Walmart▁': 208,\n",
       " 'COLOR▁': 209,\n",
       " 'MI▁': 210,\n",
       " \"Burt's▁\": 211,\n",
       " 'Maternity▁': 212,\n",
       " 'kids,▁': 213,\n",
       " 'branded▁': 214,\n",
       " 'include▁': 215,\n",
       " 'repl': 216,\n",
       " 'KIT': 217,\n",
       " 'extend▁': 218,\n",
       " 'throw▁': 219,\n",
       " 'Seal▁': 220,\n",
       " 'Fer': 221,\n",
       " 'Lap': 222,\n",
       " 'italizing▁': 223,\n",
       " 'measure': 224,\n",
       " '30-': 225,\n",
       " 'tons▁': 226,\n",
       " 'ball.▁': 227,\n",
       " 'GLASSES▁': 228,\n",
       " 'animals▁': 229,\n",
       " 'typically▁': 230,\n",
       " 'look': 231,\n",
       " 'Contains:▁': 232,\n",
       " 'buying.▁': 233,\n",
       " 'often▁': 234,\n",
       " 'sneaker▁': 235,\n",
       " 'G4▁': 236,\n",
       " 'Kyli': 237,\n",
       " 'discolor': 238,\n",
       " 'yeah,▁': 239,\n",
       " 'ight,▁': 240,\n",
       " 'Dr': 241,\n",
       " 'save.▁': 242,\n",
       " 'Fit:▁': 243,\n",
       " 'Instructions:▁': 244,\n",
       " 'SUB': 245,\n",
       " 'moun': 246,\n",
       " 'TRE': 247,\n",
       " '32D▁': 248,\n",
       " '-new▁': 249,\n",
       " 'STYLE': 250,\n",
       " 'tote.▁': 251,\n",
       " 'Phys': 252,\n",
       " 'interchangeable▁': 253,\n",
       " 'GOL': 254,\n",
       " 'seper': 255,\n",
       " 'concerns▁': 256,\n",
       " 'ac▁': 257,\n",
       " 'grass▁': 258,\n",
       " 'Tap': 259,\n",
       " 'wii▁': 260,\n",
       " 'wor': 261,\n",
       " 'flannel▁': 262,\n",
       " 'manual.▁': 263,\n",
       " 'BR': 264,\n",
       " 'review▁': 265,\n",
       " 'Boo': 266,\n",
       " 'o▁': 267,\n",
       " 'rol': 268,\n",
       " 'woods▁': 269,\n",
       " 'from': 270,\n",
       " 'for▁': 271,\n",
       " 'pm▁': 272,\n",
       " 'dim': 273,\n",
       " 'Mc': 274,\n",
       " 'Fit▁': 275,\n",
       " 'pine▁': 276,\n",
       " 'Camera,▁': 277,\n",
       " 'Directions▁': 278,\n",
       " 'upcoming▁': 279,\n",
       " 'APER▁': 280,\n",
       " 'always▁': 281,\n",
       " 'info.▁': 282,\n",
       " 'fer': 283,\n",
       " 'MICHAEL▁': 284,\n",
       " 'seri': 285,\n",
       " 'SOLD▁': 286,\n",
       " 'oll▁': 287,\n",
       " 'Usu': 288,\n",
       " 'marks▁': 289,\n",
       " '#handmade▁': 290,\n",
       " 'ly,▁': 291,\n",
       " 'PILLOW▁': 292,\n",
       " 'Madison▁': 293,\n",
       " 'experience▁': 294,\n",
       " 'gative▁': 295,\n",
       " 'Wid': 296,\n",
       " 'rais': 297,\n",
       " 'Cy': 298,\n",
       " 'embossed▁': 299,\n",
       " 'spell': 300,\n",
       " 'KITS▁': 301,\n",
       " '13)▁': 302,\n",
       " '(4th▁': 303,\n",
       " 'adidas,': 304,\n",
       " 'Turquo': 305,\n",
       " 'LENGTH▁': 306,\n",
       " 'judge▁': 307,\n",
       " 'anced▁': 308,\n",
       " 'Quantit': 309,\n",
       " 'soph': 310,\n",
       " 't-shirts,▁': 311,\n",
       " 'jacket!▁': 312,\n",
       " 'Put▁': 313,\n",
       " 'bundles,▁': 314,\n",
       " 'Wip': 315,\n",
       " 'ecrets▁': 316,\n",
       " '；': 317,\n",
       " 'pc▁': 318,\n",
       " 'Belted▁': 319,\n",
       " 'sed▁': 320,\n",
       " 'want▁': 321,\n",
       " 'Cap': 322,\n",
       " \"Girl's▁\": 323,\n",
       " '8.5,▁': 324,\n",
       " 'chair▁': 325,\n",
       " '55▁': 326,\n",
       " 'dom': 327,\n",
       " 'van': 328,\n",
       " '39': 329,\n",
       " 'manufact': 330,\n",
       " 'Socks▁': 331,\n",
       " 'drops!▁': 332,\n",
       " 'Monkey▁': 333,\n",
       " 'ings.▁': 334,\n",
       " 'nylon,▁': 335,\n",
       " 'ER,▁': 336,\n",
       " 'REVIE': 337,\n",
       " 'Rhinest': 338,\n",
       " 'ALSO▁': 339,\n",
       " 'tough▁': 340,\n",
       " 'Lucy▁': 341,\n",
       " 'cellphone▁': 342,\n",
       " 'glam▁': 343,\n",
       " 'Orig': 344,\n",
       " 'gain▁': 345,\n",
       " 'body,▁': 346,\n",
       " 'FLOR': 347,\n",
       " 'dimensi': 348,\n",
       " 'studs▁': 349,\n",
       " 'Low': 350,\n",
       " 'L.': 351,\n",
       " 'nexpec': 352,\n",
       " 'Comb': 353,\n",
       " 'sealed.▁': 354,\n",
       " 'itiz': 355,\n",
       " 'Essence▁': 356,\n",
       " 'Sales▁': 357,\n",
       " 'REALLY▁': 358,\n",
       " 'Text': 359,\n",
       " 'slots▁': 360,\n",
       " 'r': 361,\n",
       " 'JENNER▁': 362,\n",
       " 'here.▁': 363,\n",
       " 'brush▁': 364,\n",
       " 'putting▁': 365,\n",
       " 'hearts▁': 366,\n",
       " 'shes▁': 367,\n",
       " 'Oshkosh▁': 368,\n",
       " 'fortune▁': 369,\n",
       " 'Always▁': 370,\n",
       " 'Wi': 371,\n",
       " 'Mil': 372,\n",
       " 'curly▁': 373,\n",
       " 'Ever': 374,\n",
       " 'Ba': 375,\n",
       " 'creates▁': 376,\n",
       " 'transition▁': 377,\n",
       " 'TIL▁': 378,\n",
       " 'STORES▁': 379,\n",
       " 'iv': 380,\n",
       " 'CHARGER▁': 381,\n",
       " 'tighter▁': 382,\n",
       " 'Discreet▁': 383,\n",
       " 'R.▁': 384,\n",
       " ';': 385,\n",
       " 'Brand-new▁': 386,\n",
       " 'can.▁': 387,\n",
       " 'Headphone▁': 388,\n",
       " 'fighting▁': 389,\n",
       " 'glass,▁': 390,\n",
       " 'Tablet▁': 391,\n",
       " 'up,▁': 392,\n",
       " '//': 393,\n",
       " 'Imported.▁': 394,\n",
       " 'Dut': 395,\n",
       " 'Cucum': 396,\n",
       " 'Paisley▁': 397,\n",
       " 'tops▁': 398,\n",
       " '(M)▁': 399,\n",
       " '**We▁': 400,\n",
       " 'SP▁': 401,\n",
       " 'nails,▁': 402,\n",
       " 'ola▁': 403,\n",
       " 'Guess▁': 404,\n",
       " '13.': 405,\n",
       " 'written▁': 406,\n",
       " 'lation.▁': 407,\n",
       " 'colorful▁': 408,\n",
       " 'matte,▁': 409,\n",
       " 'camping▁': 410,\n",
       " 'ventures▁': 411,\n",
       " 'rest▁': 412,\n",
       " 'ss!▁': 413,\n",
       " 'shine,▁': 414,\n",
       " '7.5x': 415,\n",
       " '9.▁': 416,\n",
       " 'flag': 417,\n",
       " 'M/L.▁': 418,\n",
       " 'intere': 419,\n",
       " 'mandar': 420,\n",
       " 'ett': 421,\n",
       " 'ASK!▁': 422,\n",
       " \"'ve▁\": 423,\n",
       " 'BRAND': 424,\n",
       " '29.▁': 425,\n",
       " 'dom▁': 426,\n",
       " 'aut': 427,\n",
       " 'Hoops▁': 428,\n",
       " 'ness!▁': 429,\n",
       " 'LOWBALL': 430,\n",
       " 'polishes▁': 431,\n",
       " '100▁': 432,\n",
       " 'Jap': 433,\n",
       " 'Hum': 434,\n",
       " 'ideal▁': 435,\n",
       " 'BKE▁': 436,\n",
       " 'Indones': 437,\n",
       " 'choice.▁': 438,\n",
       " '1*': 439,\n",
       " 'arrived▁': 440,\n",
       " 'Garment▁': 441,\n",
       " 'H▁': 442,\n",
       " 'discontinu': 443,\n",
       " 'Larger▁': 444,\n",
       " 'eld▁': 445,\n",
       " 'Miss▁': 446,\n",
       " 'Navy▁': 447,\n",
       " 'icide▁': 448,\n",
       " 'Provid': 449,\n",
       " 'diamet': 450,\n",
       " 'yester': 451,\n",
       " 'CHE': 452,\n",
       " 'Cover,▁': 453,\n",
       " 'padd': 454,\n",
       " 'ys': 455,\n",
       " 'too!!▁': 456,\n",
       " 'akkuma▁': 457,\n",
       " 'authenticity.▁': 458,\n",
       " 'fra': 459,\n",
       " 'odeon▁': 460,\n",
       " 'Due▁': 461,\n",
       " 'transm': 462,\n",
       " 'February▁': 463,\n",
       " '❣▁': 464,\n",
       " 'Plum': 465,\n",
       " 'ch▁': 466,\n",
       " 'lead▁': 467,\n",
       " '6.6': 468,\n",
       " 'unched▁': 469,\n",
       " 'Sizes:▁': 470,\n",
       " 'RUNS▁': 471,\n",
       " '#1▁': 472,\n",
       " 'ovals▁': 473,\n",
       " 'Teddy▁': 474,\n",
       " 'lot': 475,\n",
       " 'Tarte▁': 476,\n",
       " 'AGE▁': 477,\n",
       " 'hook': 478,\n",
       " 'J5▁': 479,\n",
       " 'melts▁': 480,\n",
       " '6/6+': 481,\n",
       " 'quick': 482,\n",
       " 'Pokémon▁': 483,\n",
       " '⛔': 484,\n",
       " 'melville▁': 485,\n",
       " 'Jun': 486,\n",
       " 'Lined▁': 487,\n",
       " 'oil▁': 488,\n",
       " 'hour▁': 489,\n",
       " 'household.▁': 490,\n",
       " 'Wide▁': 491,\n",
       " 'room,▁': 492,\n",
       " 'Material▁': 493,\n",
       " 'RAM▁': 494,\n",
       " 'center': 495,\n",
       " 'justice▁': 496,\n",
       " 'ex': 497,\n",
       " 'ROSE▁': 498,\n",
       " 'strip▁': 499,\n",
       " 'wrapp': 500,\n",
       " 'Suit▁': 501,\n",
       " 'train': 502,\n",
       " 'glasses.▁': 503,\n",
       " 'rubber': 504,\n",
       " 'Gild': 505,\n",
       " 'Fallout▁': 506,\n",
       " 'card▁': 507,\n",
       " 'innam': 508,\n",
       " 'Super-': 509,\n",
       " 'tain▁': 510,\n",
       " 'footbed▁': 511,\n",
       " 'is.▁': 512,\n",
       " 'wrinkled▁': 513,\n",
       " 'bag)▁': 514,\n",
       " 'lim': 515,\n",
       " 'LE▁': 516,\n",
       " 'INFO▁': 517,\n",
       " 'material)▁': 518,\n",
       " 'Dust': 519,\n",
       " 'apper': 520,\n",
       " 'fading,▁': 521,\n",
       " 'EAS': 522,\n",
       " '10%.▁': 523,\n",
       " 'screw': 524,\n",
       " 'EY▁': 525,\n",
       " 'sprint▁': 526,\n",
       " 'Sen': 527,\n",
       " 'camer': 528,\n",
       " 'Maui▁': 529,\n",
       " 'Powder': 530,\n",
       " 'tr': 531,\n",
       " '_____________________________________________________________': 532,\n",
       " 'Specifications▁': 533,\n",
       " 'ish▁': 534,\n",
       " 'material!▁': 535,\n",
       " '32B.▁': 536,\n",
       " 'expires▁': 537,\n",
       " 'coup': 538,\n",
       " 'Dual▁': 539,\n",
       " 'fum': 540,\n",
       " 'Crib▁': 541,\n",
       " 'name': 542,\n",
       " 'good▁': 543,\n",
       " 'Butter': 544,\n",
       " 'want,▁': 545,\n",
       " 'comple': 546,\n",
       " 'magenta▁': 547,\n",
       " 'Thunderbolt▁': 548,\n",
       " 'Size.▁': 549,\n",
       " 'coat▁': 550,\n",
       " 'cont': 551,\n",
       " 'Gray,▁': 552,\n",
       " ':)▁': 553,\n",
       " 'Vac': 554,\n",
       " 'birthday▁': 555,\n",
       " 'By▁': 556,\n",
       " 'lowest,▁': 557,\n",
       " 'Rub': 558,\n",
       " 'revi': 559,\n",
       " 'U.K.▁': 560,\n",
       " 'soft▁': 561,\n",
       " 'films▁': 562,\n",
       " 'bask': 563,\n",
       " 'PURCHASE.▁': 564,\n",
       " 'Large)▁': 565,\n",
       " 'carved▁': 566,\n",
       " 'succul': 567,\n",
       " 'Therefore,▁': 568,\n",
       " '➰': 569,\n",
       " 'beyond▁': 570,\n",
       " 'ttery▁': 571,\n",
       " '13\"▁': 572,\n",
       " 't-shirt▁': 573,\n",
       " '™▁': 574,\n",
       " 'psorias': 575,\n",
       " 'point': 576,\n",
       " 'â': 577,\n",
       " 'lining/': 578,\n",
       " 'left.▁': 579,\n",
       " 'sponges▁': 580,\n",
       " 'es-▁': 581,\n",
       " 'Victoria▁': 582,\n",
       " '❗️❗️▁': 583,\n",
       " 'Aeropostale▁': 584,\n",
       " 'this!▁': 585,\n",
       " '-------------': 586,\n",
       " 'automatically▁': 587,\n",
       " 'dispo': 588,\n",
       " 'scrapes▁': 589,\n",
       " 'Yeezy▁': 590,\n",
       " 'shipped.▁': 591,\n",
       " 'SEL': 592,\n",
       " 'Fil': 593,\n",
       " 'cleaning▁': 594,\n",
       " 'ental▁': 595,\n",
       " 'ft▁': 596,\n",
       " 'appli': 597,\n",
       " 'Mail▁': 598,\n",
       " 'crepe▁': 599,\n",
       " 'Blends▁': 600,\n",
       " 'day.▁': 601,\n",
       " 'fitted▁': 602,\n",
       " 'Health▁': 603,\n",
       " 'Listing▁': 604,\n",
       " 'y,': 605,\n",
       " '12': 606,\n",
       " '925': 607,\n",
       " 'Sprin': 608,\n",
       " 'x-': 609,\n",
       " 'S6▁': 610,\n",
       " 'tar▁': 611,\n",
       " 'ablo▁': 612,\n",
       " 'dusting▁': 613,\n",
       " 'y/▁': 614,\n",
       " '(deep▁': 615,\n",
       " 'TIONAL▁': 616,\n",
       " 'bling▁': 617,\n",
       " 'xocheyaxo▁': 618,\n",
       " 'ler▁': 619,\n",
       " 'almost▁': 620,\n",
       " 'back!▁': 621,\n",
       " 'nic': 622,\n",
       " 'P.': 623,\n",
       " 'Square▁': 624,\n",
       " 'person!▁': 625,\n",
       " 'control.▁': 626,\n",
       " 'flexible▁': 627,\n",
       " 'Elizabeth▁': 628,\n",
       " 'sheer,▁': 629,\n",
       " 'triangle▁': 630,\n",
       " \"Can't▁\": 631,\n",
       " 'Stand▁': 632,\n",
       " 'deterg': 633,\n",
       " 'each!▁': 634,\n",
       " 'Virgin▁': 635,\n",
       " 'Tall▁': 636,\n",
       " 'binding▁': 637,\n",
       " 'dia▁': 638,\n",
       " 'Yankee▁': 639,\n",
       " 'code:▁': 640,\n",
       " 's.▁': 641,\n",
       " 'tting▁': 642,\n",
       " 'oz.)▁': 643,\n",
       " 'decorations.▁': 644,\n",
       " '❇️▁': 645,\n",
       " 'tex': 646,\n",
       " '***Will▁': 647,\n",
       " 'RAL▁': 648,\n",
       " 'low': 649,\n",
       " 'Head': 650,\n",
       " 'sat': 651,\n",
       " 'LOVE▁': 652,\n",
       " '-O': 653,\n",
       " 'IME': 654,\n",
       " 'skirts,▁': 655,\n",
       " '2.25\"▁': 656,\n",
       " 'bott': 657,\n",
       " 'ᴍ': 658,\n",
       " 'reflected▁': 659,\n",
       " 'Revolution▁': 660,\n",
       " 'buttery▁': 661,\n",
       " 'BOX,▁': 662,\n",
       " 'bowl▁': 663,\n",
       " 'picture)▁': 664,\n",
       " 'Whis': 665,\n",
       " 'downsizing▁': 666,\n",
       " 'dresser▁': 667,\n",
       " '(20)▁': 668,\n",
       " 'irt': 669,\n",
       " 'Ass': 670,\n",
       " 'age!▁': 671,\n",
       " 'form': 672,\n",
       " 'Bluetooth': 673,\n",
       " 'value!▁': 674,\n",
       " 'resistant,▁': 675,\n",
       " 'anthropologie▁': 676,\n",
       " 'house!▁': 677,\n",
       " 'crime▁': 678,\n",
       " 'Tele': 679,\n",
       " 'Booster▁': 680,\n",
       " 'ori▁': 681,\n",
       " 'pir': 682,\n",
       " 'itt': 683,\n",
       " 'wt▁': 684,\n",
       " 'iting▁': 685,\n",
       " 'Crossbody▁': 686,\n",
       " 'USPS▁': 687,\n",
       " 'PLS▁': 688,\n",
       " 'ord▁': 689,\n",
       " 'arrive▁': 690,\n",
       " 'contour,▁': 691,\n",
       " 'bar▁': 692,\n",
       " 'pierc': 693,\n",
       " 'turquoise,▁': 694,\n",
       " 'STRE': 695,\n",
       " 'applying▁': 696,\n",
       " 'Ended▁': 697,\n",
       " 'MEASURE▁': 698,\n",
       " 'lu': 699,\n",
       " 'roe▁': 700,\n",
       " 'pop,▁': 701,\n",
       " 'ints▁': 702,\n",
       " 'sleeping▁': 703,\n",
       " 'ME!▁': 704,\n",
       " 'astas': 705,\n",
       " 'es***▁': 706,\n",
       " 'them▁': 707,\n",
       " 'GET,▁': 708,\n",
       " 'Cars▁': 709,\n",
       " 'DON': 710,\n",
       " 'batman▁': 711,\n",
       " 'ed:▁': 712,\n",
       " 'OIL': 713,\n",
       " 'Dest': 714,\n",
       " 'lowing▁': 715,\n",
       " '⚡⚡⚡⚡': 716,\n",
       " 'y..▁': 717,\n",
       " 'PL▁': 718,\n",
       " 'ide▁': 719,\n",
       " 'ord': 720,\n",
       " 'neckline,▁': 721,\n",
       " 'rag': 722,\n",
       " 'Pad': 723,\n",
       " 'stand.▁': 724,\n",
       " 'ature▁': 725,\n",
       " 'MUCH▁': 726,\n",
       " 'straight▁': 727,\n",
       " 'm': 728,\n",
       " 'proof!▁': 729,\n",
       " '2007▁': 730,\n",
       " 'EASY▁': 731,\n",
       " 'Use': 732,\n",
       " 'Dose▁': 733,\n",
       " 'TAIN▁': 734,\n",
       " 'cuff': 735,\n",
       " 'color:▁': 736,\n",
       " 'black': 737,\n",
       " 'Flag': 738,\n",
       " 'Wii▁': 739,\n",
       " 'bb': 740,\n",
       " 'Lauren,▁': 741,\n",
       " 'Usps▁': 742,\n",
       " '12-hour▁': 743,\n",
       " 'TUR': 744,\n",
       " 'Included:▁': 745,\n",
       " 'separatel': 746,\n",
       " 'is:▁': 747,\n",
       " 'LuMee▁': 748,\n",
       " 'reviews❤️▁': 749,\n",
       " 'priority.▁': 750,\n",
       " 'Accent': 751,\n",
       " 'NAKED': 752,\n",
       " 'Victori': 753,\n",
       " 'anymore.▁': 754,\n",
       " 'Changing▁': 755,\n",
       " 'instead▁': 756,\n",
       " 'FEATURE': 757,\n",
       " 'ooch▁': 758,\n",
       " 'Gla': 759,\n",
       " 'applicator▁': 760,\n",
       " 'occasion.▁': 761,\n",
       " 'GA': 762,\n",
       " 'trac': 763,\n",
       " 'restor': 764,\n",
       " 'caused▁': 765,\n",
       " 'handled▁': 766,\n",
       " 'Two': 767,\n",
       " '10-': 768,\n",
       " 'le-': 769,\n",
       " 'Magic': 770,\n",
       " 'writing.▁': 771,\n",
       " '25': 772,\n",
       " 'PU': 773,\n",
       " 'matte▁': 774,\n",
       " 'antas': 775,\n",
       " 'shaver▁': 776,\n",
       " 'OOO': 777,\n",
       " 'attoo': 778,\n",
       " 'mering▁': 779,\n",
       " 'New.▁': 780,\n",
       " 'polish': 781,\n",
       " 'Cal': 782,\n",
       " 'wrapping.▁': 783,\n",
       " 'contouring▁': 784,\n",
       " 'faced▁': 785,\n",
       " 'JEAN': 786,\n",
       " 'Headphones▁': 787,\n",
       " 't,': 788,\n",
       " 'Fem': 789,\n",
       " 'discreet▁': 790,\n",
       " 'cheap▁': 791,\n",
       " 'newborn▁': 792,\n",
       " 'SO▁': 793,\n",
       " 'carefully▁': 794,\n",
       " '...I▁': 795,\n",
       " 'wall,▁': 796,\n",
       " 'fraction▁': 797,\n",
       " 'FIRM,▁': 798,\n",
       " 'technology.▁': 799,\n",
       " 'ᴋ': 800,\n",
       " 'Lunch▁': 801,\n",
       " 'shelf▁': 802,\n",
       " 'steps▁': 803,\n",
       " 'batter': 804,\n",
       " 'DETAILS▁': 805,\n",
       " 'expres': 806,\n",
       " 'dirt,▁': 807,\n",
       " 'holder▁': 808,\n",
       " 'flats.▁': 809,\n",
       " 'Grey/': 810,\n",
       " 'reduc': 811,\n",
       " 'bbled▁': 812,\n",
       " 'plumper▁': 813,\n",
       " 'col': 814,\n",
       " 'enam': 815,\n",
       " 'ither▁': 816,\n",
       " 'only▁': 817,\n",
       " 'adap': 818,\n",
       " 'bagg': 819,\n",
       " 'outdoor▁': 820,\n",
       " 'differently▁': 821,\n",
       " \"doesn't▁\": 822,\n",
       " '----▁': 823,\n",
       " 'Takes▁': 824,\n",
       " 'TOM': 825,\n",
       " 'Speed': 826,\n",
       " \"5'3▁\": 827,\n",
       " 'insulated▁': 828,\n",
       " 'Jaclyn▁': 829,\n",
       " 'TRACKING!▁': 830,\n",
       " 'spand': 831,\n",
       " 'CLO': 832,\n",
       " \"I'd▁\": 833,\n",
       " 'ho': 834,\n",
       " 'Dav': 835,\n",
       " 'STICKER▁': 836,\n",
       " 'hin': 837,\n",
       " 'resem': 838,\n",
       " 'Dock▁': 839,\n",
       " '(7-': 840,\n",
       " 'GO▁': 841,\n",
       " 'Clu': 842,\n",
       " 'SET▁': 843,\n",
       " 'ickstand▁': 844,\n",
       " 'mission▁': 845,\n",
       " 'effect▁': 846,\n",
       " 'S/5': 847,\n",
       " 'Blueberry▁': 848,\n",
       " 'standing▁': 849,\n",
       " 'color.▁': 850,\n",
       " 'Shopping!▁': 851,\n",
       " 'patches.▁': 852,\n",
       " '1.0g)▁': 853,\n",
       " 'sil': 854,\n",
       " 'Vintag': 855,\n",
       " 'Sealed': 856,\n",
       " 'Therma-Fit▁': 857,\n",
       " 'OFFERS': 858,\n",
       " 'mother': 859,\n",
       " 'deliver▁': 860,\n",
       " 'Thongs▁': 861,\n",
       " 'Shadows▁': 862,\n",
       " 'AST▁': 863,\n",
       " 'products,▁': 864,\n",
       " 'requi': 865,\n",
       " 'pops▁': 866,\n",
       " '(5': 867,\n",
       " 'grinders,▁': 868,\n",
       " 'RS▁': 869,\n",
       " 'Eco▁': 870,\n",
       " '7%▁': 871,\n",
       " 'prob▁': 872,\n",
       " 'wood': 873,\n",
       " 'wore▁': 874,\n",
       " 'sitting▁': 875,\n",
       " 'beautifully▁': 876,\n",
       " 'Valued▁': 877,\n",
       " 'GENUINE▁': 878,\n",
       " 'Lingerie▁': 879,\n",
       " 'tified▁': 880,\n",
       " 'hil': 881,\n",
       " 'full.▁': 882,\n",
       " 'REA': 883,\n",
       " '(from▁': 884,\n",
       " 'Crew': 885,\n",
       " 'cross.▁': 886,\n",
       " 'Blu-Ray▁': 887,\n",
       " 'z.▁': 888,\n",
       " '·': 889,\n",
       " 'iPad': 890,\n",
       " 'get:▁': 891,\n",
       " 'Valentin': 892,\n",
       " 'Merona▁': 893,\n",
       " '(3': 894,\n",
       " 'application▁': 895,\n",
       " 'acks▁': 896,\n",
       " 'VS,▁': 897,\n",
       " 'comes▁': 898,\n",
       " 'Selec': 899,\n",
       " '!*▁': 900,\n",
       " 'S4▁': 901,\n",
       " 'purchasing!▁': 902,\n",
       " '(XS': 903,\n",
       " '⬛': 904,\n",
       " 'Franc': 905,\n",
       " 'inspir': 906,\n",
       " 'Metal:▁': 907,\n",
       " 'photo)▁': 908,\n",
       " 'mens,▁': 909,\n",
       " '&▁': 910,\n",
       " 'two▁': 911,\n",
       " 'VINTAGE▁': 912,\n",
       " 'heels,▁': 913,\n",
       " 'tight,▁': 914,\n",
       " 'resses▁': 915,\n",
       " 'long-': 916,\n",
       " 'bright▁': 917,\n",
       " 'sewing▁': 918,\n",
       " 'work.▁': 919,\n",
       " 'ob': 920,\n",
       " 'decay▁': 921,\n",
       " 'Platform▁': 922,\n",
       " 's)': 923,\n",
       " 'wea': 924,\n",
       " 'Have▁': 925,\n",
       " 'shoes)▁': 926,\n",
       " 'Size,▁': 927,\n",
       " 'bac▁': 928,\n",
       " \"'re▁\": 929,\n",
       " 'POP': 930,\n",
       " 'abras': 931,\n",
       " '*Smoke▁': 932,\n",
       " 'finish▁': 933,\n",
       " 'henn': 934,\n",
       " 'top)▁': 935,\n",
       " 'Tons▁': 936,\n",
       " 'Forever▁': 937,\n",
       " 'up.▁': 938,\n",
       " 'be!▁': 939,\n",
       " 'youth▁': 940,\n",
       " '10mm▁': 941,\n",
       " '.25oz▁': 942,\n",
       " 'Handcrafted▁': 943,\n",
       " '⛔️RUDE▁': 944,\n",
       " 'alls▁': 945,\n",
       " 'ened▁': 946,\n",
       " 'weight': 947,\n",
       " 'Cute': 948,\n",
       " 'pill▁': 949,\n",
       " 'ml)▁': 950,\n",
       " 'Unfortunately,▁': 951,\n",
       " 'iPhone/': 952,\n",
       " 'Status▁': 953,\n",
       " 'Drop:▁': 954,\n",
       " 'generated▁': 955,\n",
       " 'Favorite▁': 956,\n",
       " 'official▁': 957,\n",
       " 'GORGEOUS▁': 958,\n",
       " 'GS▁': 959,\n",
       " 'amps▁': 960,\n",
       " 'shi': 961,\n",
       " 'wood▁': 962,\n",
       " 'Lasts▁': 963,\n",
       " 'assort': 964,\n",
       " 'ril': 965,\n",
       " 'fly▁': 966,\n",
       " 'ria▁': 967,\n",
       " 'skinn': 968,\n",
       " 'ynthetic▁': 969,\n",
       " 'pages.▁': 970,\n",
       " 'teach': 971,\n",
       " 'Zara▁': 972,\n",
       " 'particular▁': 973,\n",
       " 'Booties▁': 974,\n",
       " '·▁': 975,\n",
       " 'send▁': 976,\n",
       " 'iP': 977,\n",
       " 'New!▁': 978,\n",
       " 'maj': 979,\n",
       " 'ture': 980,\n",
       " 'crate▁': 981,\n",
       " 'Ban▁': 982,\n",
       " 'ched▁': 983,\n",
       " 'pad': 984,\n",
       " 'COMB': 985,\n",
       " 'Clean▁': 986,\n",
       " 'Serial▁': 987,\n",
       " 'Rom': 988,\n",
       " '.)▁': 989,\n",
       " 'Squ': 990,\n",
       " 'Balloon▁': 991,\n",
       " 'Ke': 992,\n",
       " 'wallet▁': 993,\n",
       " '(H': 994,\n",
       " 'ATION▁': 995,\n",
       " 'array▁': 996,\n",
       " 'socks▁': 997,\n",
       " 'jasmine,▁': 998,\n",
       " 'consum': 999,\n",
       " 'Gorgeou': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe._vocab_stats['92%▁']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['byte-pair-encoder-raw-case.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(bpe, 'byte-pair-encoder-raw-case.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# encode/decode some strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4452222"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bpe_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.97 s, sys: 32 ms, total: 4.01 s\n",
      "Wall time: 4.01 s\n"
     ]
    }
   ],
   "source": [
    "%time tokens = bpe.transform(bpe_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 227 ms, sys: 4 ms, total: 231 ms\n",
      "Wall time: 231 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Size▁',\n",
       " 'small▁',\n",
       " 'Bought▁',\n",
       " 'from▁',\n",
       " 'converse▁',\n",
       " 'store▁',\n",
       " 'New▁',\n",
       " 'with▁',\n",
       " 'tags▁',\n",
       " 'Color▁',\n",
       " 'is▁',\n",
       " 'black▁',\n",
       " 'retail▁',\n",
       " '19.',\n",
       " '99',\n",
       " '$▁',\n",
       " 'Size▁',\n",
       " '6▁',\n",
       " 'toddler▁',\n",
       " 'kids▁',\n",
       " 'unisex▁',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " 'white▁',\n",
       " '<unk>',\n",
       " 'lo▁',\n",
       " 'black▁',\n",
       " 'zip▁',\n",
       " 'up.▁',\n",
       " 'Size▁',\n",
       " 'small.▁',\n",
       " 'Basic▁',\n",
       " 'black▁',\n",
       " 'zip▁',\n",
       " 'up▁',\n",
       " 'will▁',\n",
       " 'match▁',\n",
       " 'everything.▁',\n",
       " 'Hooded▁',\n",
       " 'and▁',\n",
       " 'slim▁',\n",
       " 'fit.▁',\n",
       " '<unk>',\n",
       " '#▁',\n",
       " 'Abercrombie▁',\n",
       " 'and▁',\n",
       " '<unk>',\n",
       " '/▁',\n",
       " '<unk>',\n",
       " '/▁',\n",
       " '<unk>',\n",
       " '/▁',\n",
       " 'American▁',\n",
       " '<unk>',\n",
       " '/▁',\n",
       " 'American▁',\n",
       " '<unk>',\n",
       " '/▁',\n",
       " 'American▁',\n",
       " 'rag',\n",
       " '/▁',\n",
       " 'Ann▁',\n",
       " '<unk>',\n",
       " '/▁',\n",
       " 'Ann▁',\n",
       " 'Taylor▁',\n",
       " 'LO',\n",
       " 'FT',\n",
       " '/▁',\n",
       " 'A',\n",
       " '|',\n",
       " 'X▁',\n",
       " 'Armani▁',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " '/▁',\n",
       " 'Banana▁',\n",
       " '<unk>',\n",
       " '/▁',\n",
       " 'Big▁',\n",
       " 'Star',\n",
       " '/▁',\n",
       " 'Brandy▁',\n",
       " '<unk>',\n",
       " '/▁',\n",
       " 'Calvin▁',\n",
       " '<unk>',\n",
       " '/▁',\n",
       " 'Charlotte▁',\n",
       " 'Russe',\n",
       " '/▁',\n",
       " 'Club▁',\n",
       " '<unk>',\n",
       " 'co',\n",
       " '/▁',\n",
       " '<unk>',\n",
       " '/▁',\n",
       " '<unk>',\n",
       " '/▁',\n",
       " 'Forever▁',\n",
       " '21',\n",
       " '/▁',\n",
       " 'Free▁',\n",
       " '<unk>',\n",
       " '/▁',\n",
       " 'French▁',\n",
       " '<unk>',\n",
       " 'ion',\n",
       " '/▁',\n",
       " 'Gap',\n",
       " '/▁',\n",
       " '<unk>',\n",
       " '/▁',\n",
       " '<unk>',\n",
       " '/▁',\n",
       " 'J.▁',\n",
       " 'Crew',\n",
       " '/▁',\n",
       " 'Lululemon',\n",
       " '/▁',\n",
       " '<unk>',\n",
       " '/▁',\n",
       " 'MAR',\n",
       " 'C▁',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " 'S/',\n",
       " '▁',\n",
       " 'Michael▁',\n",
       " '<unk>',\n",
       " '/▁',\n",
       " 'Nec',\n",
       " 'ess',\n",
       " '<unk>',\n",
       " '/▁',\n",
       " 'Nike',\n",
       " '/▁',\n",
       " 'Nine▁',\n",
       " 'West',\n",
       " '/▁',\n",
       " 'Nordstrom',\n",
       " '/▁',\n",
       " 'Old▁',\n",
       " '<unk>',\n",
       " '/▁',\n",
       " 'PINK',\n",
       " '/▁',\n",
       " 'Polo▁',\n",
       " 'Ralph▁',\n",
       " '<unk>',\n",
       " '/▁',\n",
       " 'PU',\n",
       " 'MA',\n",
       " '/▁',\n",
       " '<unk>',\n",
       " '/▁',\n",
       " 'Super',\n",
       " 'dry',\n",
       " '/▁',\n",
       " '<unk>',\n",
       " '/▁',\n",
       " 'The▁',\n",
       " 'North▁',\n",
       " 'Face',\n",
       " '/▁',\n",
       " '<unk>',\n",
       " '/▁',\n",
       " 'Tommy▁',\n",
       " '<unk>',\n",
       " '/▁',\n",
       " '<unk>',\n",
       " 'lo',\n",
       " '/▁',\n",
       " 'Urban▁',\n",
       " '<unk>',\n",
       " '/▁',\n",
       " 'Wet▁',\n",
       " '<unk>',\n",
       " '/▁',\n",
       " '<unk>',\n",
       " '/▁',\n",
       " '7▁',\n",
       " 'for▁',\n",
       " 'all▁',\n",
       " 'Man',\n",
       " 'kind.▁',\n",
       " 'Beautiful▁',\n",
       " 'LV▁',\n",
       " 'and▁',\n",
       " '100%▁',\n",
       " '<unk>',\n",
       " 'Has▁',\n",
       " 'some▁',\n",
       " 'wear▁',\n",
       " 'but▁',\n",
       " 'much▁',\n",
       " 'more▁',\n",
       " 'life▁',\n",
       " 'to▁',\n",
       " 'it.▁',\n",
       " 'Has▁',\n",
       " 'some▁',\n",
       " 'water▁',\n",
       " 'marks▁',\n",
       " 'that▁',\n",
       " 'can▁',\n",
       " 'be▁',\n",
       " '<unk>',\n",
       " 'd▁',\n",
       " 'out▁',\n",
       " 'and▁',\n",
       " 'inside▁',\n",
       " 'pockets▁',\n",
       " 'peeling▁',\n",
       " 'but▁',\n",
       " 'not▁',\n",
       " '<unk>',\n",
       " '!▁',\n",
       " '[rm]▁',\n",
       " 'obo▁',\n",
       " 'No▁',\n",
       " 'description▁',\n",
       " 'yet▁',\n",
       " 'The▁',\n",
       " 'color▁',\n",
       " 'in▁',\n",
       " 'the▁',\n",
       " 'second▁',\n",
       " 'picture▁',\n",
       " 'is▁',\n",
       " 'more▁',\n",
       " 'true.▁',\n",
       " 'New▁',\n",
       " 'without▁',\n",
       " 'paper▁',\n",
       " 'tag▁',\n",
       " 'or▁',\n",
       " 'LLR▁',\n",
       " 'bag.▁',\n",
       " 'One▁',\n",
       " 'Size▁',\n",
       " 'Good▁',\n",
       " 'condition▁',\n",
       " 'only▁',\n",
       " 'used▁',\n",
       " 'a▁',\n",
       " 'few▁',\n",
       " 'times▁',\n",
       " 'my▁',\n",
       " 'son▁',\n",
       " 'outgrew▁',\n",
       " 'them▁',\n",
       " 'too▁',\n",
       " '<unk>',\n",
       " '..',\n",
       " 'paid▁',\n",
       " '70▁',\n",
       " 'dollars▁',\n",
       " 'for▁',\n",
       " 'these▁',\n",
       " '<unk>',\n",
       " '...',\n",
       " 'size▁',\n",
       " '13.5▁',\n",
       " '20▁',\n",
       " 'sets▁',\n",
       " 'Long▁',\n",
       " 'sleeve▁',\n",
       " 'coast',\n",
       " 'al▁',\n",
       " 'cotton▁',\n",
       " 'tshirt.▁',\n",
       " 'Size▁',\n",
       " 'medium,▁',\n",
       " 'great▁',\n",
       " 'condition▁',\n",
       " 'Harry▁',\n",
       " 'Potter▁',\n",
       " 'complete▁',\n",
       " 'collection▁',\n",
       " 'blu▁',\n",
       " 'ray▁',\n",
       " 'brand▁',\n",
       " 'new▁',\n",
       " 'sealed▁',\n",
       " 'with▁',\n",
       " 'slip▁',\n",
       " 'cover.▁',\n",
       " 'All▁',\n",
       " '8▁',\n",
       " 'movies.▁',\n",
       " '4▁',\n",
       " 'Rolls▁',\n",
       " 'as▁',\n",
       " 'shown▁',\n",
       " '12▁',\n",
       " '<unk>',\n",
       " '9▁',\n",
       " 'each▁',\n",
       " 'roll▁',\n",
       " 'Special▁',\n",
       " 'order▁',\n",
       " 'for▁',\n",
       " 'R',\n",
       " '_',\n",
       " '<unk>',\n",
       " 'f',\n",
       " '4▁',\n",
       " 'Glitter▁',\n",
       " '<unk>',\n",
       " 'g',\n",
       " 'plant▁',\n",
       " '<unk>',\n",
       " 'rap',\n",
       " 'e,',\n",
       " 'Multi-',\n",
       " 'pink▁',\n",
       " 'and▁',\n",
       " 'raspberry▁',\n",
       " 'reg▁',\n",
       " 'iron▁',\n",
       " 'on▁',\n",
       " 'vinyl.▁',\n",
       " 'Thanks▁',\n",
       " 'for▁',\n",
       " 'your▁',\n",
       " 'interest',\n",
       " '.▁',\n",
       " 'Price▁',\n",
       " 'is▁',\n",
       " 'Firm▁',\n",
       " \"Men's▁\",\n",
       " 'Adidas▁',\n",
       " 'Respon',\n",
       " 'se▁',\n",
       " '<unk>',\n",
       " 'l▁',\n",
       " 'Sneakers▁',\n",
       " '8.5',\n",
       " 'M▁',\n",
       " 'Excellent▁',\n",
       " 'Condition▁',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " 'D▁',\n",
       " 'Bitty▁',\n",
       " 'Baby▁',\n",
       " 'Sweet▁',\n",
       " 'Dreams▁',\n",
       " 'WOO',\n",
       " 'DE',\n",
       " 'N▁',\n",
       " '<unk>',\n",
       " ',▁',\n",
       " 'not▁',\n",
       " 'plastic',\n",
       " '!▁',\n",
       " 'Authentic,▁',\n",
       " 'Brand▁',\n",
       " 'New▁',\n",
       " 'in▁',\n",
       " 'Box,▁',\n",
       " 'never▁',\n",
       " '<unk>',\n",
       " '!▁',\n",
       " 'Non-',\n",
       " '<unk>',\n",
       " 'ing,▁',\n",
       " 'Pet',\n",
       " '-Free▁',\n",
       " 'Home',\n",
       " '!▁',\n",
       " 'Will▁',\n",
       " 'be▁',\n",
       " 'shipped▁',\n",
       " 'in▁',\n",
       " 'original▁',\n",
       " 'American▁',\n",
       " 'Girl▁',\n",
       " 'Box▁',\n",
       " 'that▁',\n",
       " 'came▁',\n",
       " 'from▁',\n",
       " 'the▁',\n",
       " '<unk>',\n",
       " '.▁',\n",
       " '\"',\n",
       " 'Your▁',\n",
       " 'girl▁',\n",
       " 'can▁',\n",
       " 'lay▁',\n",
       " 'Bitty▁',\n",
       " 'Baby▁',\n",
       " 'down▁',\n",
       " 'to▁',\n",
       " 'sleep▁',\n",
       " 'in▁',\n",
       " 'this▁',\n",
       " 'beautiful▁',\n",
       " 'sle',\n",
       " 'igh',\n",
       " '<unk>',\n",
       " 'ty',\n",
       " 'le▁',\n",
       " 'crib',\n",
       " '.▁',\n",
       " 'Made▁',\n",
       " 'of▁',\n",
       " 'wood,▁',\n",
       " \"it's▁\",\n",
       " 'painted▁',\n",
       " 'creamy▁',\n",
       " 'white,▁',\n",
       " 'and▁',\n",
       " 'comes▁',\n",
       " 'with▁',\n",
       " 'two▁',\n",
       " 'reversible▁',\n",
       " 'fabric▁',\n",
       " 'panels▁',\n",
       " 'to▁',\n",
       " 'customize▁',\n",
       " 'her▁',\n",
       " '<unk>',\n",
       " '.▁',\n",
       " 'Includes▁',\n",
       " 'a▁',\n",
       " 'soft▁',\n",
       " 'mattress▁',\n",
       " 'with▁',\n",
       " 'polka▁',\n",
       " 'dots▁',\n",
       " 'on▁',\n",
       " 'one▁',\n",
       " 'side▁',\n",
       " 'and▁',\n",
       " 'pink▁',\n",
       " '<unk>',\n",
       " 'ham▁',\n",
       " 'on▁',\n",
       " 'the▁',\n",
       " '<unk>',\n",
       " '\"▁',\n",
       " 'Dimensions:▁',\n",
       " 'H',\n",
       " ':▁',\n",
       " '15\"▁',\n",
       " 'x▁',\n",
       " 'L:▁',\n",
       " '25\"▁',\n",
       " 'x▁',\n",
       " 'D',\n",
       " ':▁',\n",
       " '14.',\n",
       " '25\"▁',\n",
       " '<unk>',\n",
       " 'S)▁',\n",
       " 'Adult▁',\n",
       " 'assembly▁',\n",
       " 'required.▁',\n",
       " 'Features▁',\n",
       " ':▁',\n",
       " 'LCD▁',\n",
       " 'display▁',\n",
       " 'Two▁',\n",
       " 'shooting▁',\n",
       " 'range▁',\n",
       " 'options▁',\n",
       " '(0.',\n",
       " '9-',\n",
       " '<unk>',\n",
       " ')▁',\n",
       " 'Automatic▁',\n",
       " 'flash▁',\n",
       " 'for▁',\n",
       " 'low▁',\n",
       " 'light▁',\n",
       " 'shooting▁',\n",
       " '<unk>',\n",
       " 'ure▁',\n",
       " 'button▁',\n",
       " 'View',\n",
       " 'find',\n",
       " 'er▁',\n",
       " 'Comes▁',\n",
       " 'with:▁',\n",
       " 'Pack▁',\n",
       " 'of▁',\n",
       " 'pan',\n",
       " 'asonic▁',\n",
       " 'batteries▁',\n",
       " 'Close▁',\n",
       " 'up▁',\n",
       " 'lens▁',\n",
       " 'Camera▁',\n",
       " 'strap▁',\n",
       " 'I▁',\n",
       " 'bought▁',\n",
       " 'it▁',\n",
       " 'back▁',\n",
       " 'in▁',\n",
       " 'December▁',\n",
       " 'and▁',\n",
       " 'only▁',\n",
       " 'used▁',\n",
       " 'it▁',\n",
       " 'a▁',\n",
       " 'couple▁',\n",
       " 'times▁',\n",
       " '(▁',\n",
       " 'only▁',\n",
       " 'enough▁',\n",
       " 'to▁',\n",
       " 'go▁',\n",
       " 'through▁',\n",
       " 'one▁',\n",
       " 'pack▁',\n",
       " 'of▁',\n",
       " 'film',\n",
       " ')▁',\n",
       " 'and▁',\n",
       " 'realized▁',\n",
       " 'i▁',\n",
       " 'kinda▁',\n",
       " \"don't▁\",\n",
       " 'like▁',\n",
       " 'it.▁',\n",
       " 'Still▁',\n",
       " 'has▁',\n",
       " 'box▁',\n",
       " 'so▁',\n",
       " \"I'll▁\",\n",
       " 'ship▁',\n",
       " 'it▁',\n",
       " 'with▁',\n",
       " 'box▁',\n",
       " '!▁',\n",
       " 'Lion▁',\n",
       " '<unk>',\n",
       " '▁',\n",
       " 'costume.▁',\n",
       " 'At▁',\n",
       " 'amazon▁',\n",
       " 'they▁',\n",
       " 'have▁',\n",
       " 'it▁',\n",
       " 'for▁',\n",
       " '23▁',\n",
       " 'dollars.▁',\n",
       " 'The▁',\n",
       " 'mouse▁',\n",
       " 'is▁',\n",
       " 'missing.▁',\n",
       " 'My▁',\n",
       " 'baby▁',\n",
       " 'only▁',\n",
       " 'wore▁',\n",
       " 'it▁',\n",
       " 'once▁',\n",
       " 'last▁',\n",
       " 'year.▁',\n",
       " '6▁',\n",
       " 'to▁',\n",
       " '12▁',\n",
       " 'months.▁',\n",
       " 'FLAW',\n",
       " ':▁',\n",
       " 'tiny▁',\n",
       " 'snag▁',\n",
       " 'shown▁',\n",
       " 'in▁',\n",
       " 'second▁',\n",
       " 'photo▁',\n",
       " 'and▁',\n",
       " 'some▁',\n",
       " 'pilling▁',\n",
       " 'Maroon▁',\n",
       " 'tshirt▁',\n",
       " 'dress▁',\n",
       " 'Free▁',\n",
       " 'shipping▁',\n",
       " 'Tags:▁',\n",
       " 'fai',\n",
       " '<unk>',\n",
       " 'b',\n",
       " 'tq▁',\n",
       " 'Brandy▁',\n",
       " 'Melville▁',\n",
       " 'urban▁',\n",
       " 'outfitters▁',\n",
       " 'forever▁',\n",
       " '21▁',\n",
       " 'h&m▁',\n",
       " 'Asos▁',\n",
       " 'American▁',\n",
       " 'apparel▁',\n",
       " 'wet▁',\n",
       " 'seal▁',\n",
       " 'American▁',\n",
       " 'eagle▁',\n",
       " 'Charlotte▁',\n",
       " 'Russe▁',\n",
       " 'Pacsun▁',\n",
       " 'Zara▁',\n",
       " 'No▁',\n",
       " 'description▁',\n",
       " 'yet▁',\n",
       " 'This▁',\n",
       " 'is▁',\n",
       " 'a▁',\n",
       " 'pair▁',\n",
       " 'of▁',\n",
       " 'puma▁',\n",
       " 'fe',\n",
       " '<unk>',\n",
       " 'y▁',\n",
       " 'slides.▁',\n",
       " 'They▁',\n",
       " 'are▁',\n",
       " 'brand▁',\n",
       " 'new▁',\n",
       " 'in▁',\n",
       " 'box▁',\n",
       " 'black▁',\n",
       " 'fur▁',\n",
       " \"women's▁\",\n",
       " 'size▁',\n",
       " '8.5▁',\n",
       " 'Guaranteed▁',\n",
       " '100▁',\n",
       " 'percent▁',\n",
       " 'authentic.▁',\n",
       " 'I▁',\n",
       " 'got▁',\n",
       " 'these▁',\n",
       " 'online▁',\n",
       " 'from▁',\n",
       " 'Nordstrom▁',\n",
       " 'Check▁',\n",
       " 'out▁',\n",
       " 'my▁',\n",
       " 'other▁',\n",
       " 'items▁',\n",
       " 'for▁',\n",
       " 'sale▁',\n",
       " 'Price▁',\n",
       " 'Firm▁',\n",
       " 'SHIPS▁',\n",
       " 'TODAY▁',\n",
       " 'before▁',\n",
       " '3pm▁',\n",
       " '!▁',\n",
       " 'Priority▁',\n",
       " '2▁',\n",
       " 'DAY▁',\n",
       " 'Mail',\n",
       " '!▁',\n",
       " 'Completely▁',\n",
       " 'sold▁',\n",
       " 'out.▁',\n",
       " 'Tags▁',\n",
       " ':▁',\n",
       " 'fe',\n",
       " '<unk>',\n",
       " 'y▁',\n",
       " 'sandals▁',\n",
       " 'slides▁',\n",
       " 'slippers▁',\n",
       " 'puma▁',\n",
       " 'Nike▁',\n",
       " 'adidas▁',\n",
       " 'pink▁',\n",
       " 'vs▁',\n",
       " 'yeezy▁',\n",
       " 'jacket▁',\n",
       " 'Victoria▁',\n",
       " 'secret▁',\n",
       " 'makeup▁',\n",
       " 'No▁',\n",
       " 'description▁',\n",
       " 'yet▁',\n",
       " 'perfect▁',\n",
       " 'condition▁',\n",
       " ':)▁',\n",
       " 'These▁',\n",
       " 'black▁',\n",
       " 'Toms▁',\n",
       " 'Wedges▁',\n",
       " 'are▁',\n",
       " 'super▁',\n",
       " 'cute▁',\n",
       " '&▁',\n",
       " 'in▁',\n",
       " 'great▁',\n",
       " 'condition!▁',\n",
       " 'They▁',\n",
       " 'are▁',\n",
       " 'a▁',\n",
       " 'size▁',\n",
       " '7.5.▁',\n",
       " \"Men's▁\",\n",
       " 'Ralph▁',\n",
       " 'Lauren▁',\n",
       " 'Corduroy▁',\n",
       " 'Long▁',\n",
       " 'Sleeve▁',\n",
       " 'Button▁',\n",
       " 'Up▁',\n",
       " '<unk>',\n",
       " ':▁',\n",
       " 'Black',\n",
       " ';▁',\n",
       " 'Size▁',\n",
       " '<unk>',\n",
       " ';▁',\n",
       " 'Small▁',\n",
       " 'Hole▁',\n",
       " 'around▁',\n",
       " 'wrist▁',\n",
       " 'area',\n",
       " ';▁',\n",
       " \"can't▁\",\n",
       " 'notice▁',\n",
       " \"I'd▁\",\n",
       " 'shirts▁',\n",
       " 'rolled▁',\n",
       " 'up',\n",
       " ';▁',\n",
       " 'still▁',\n",
       " 'a▁',\n",
       " 'excellent▁',\n",
       " 'shirt▁',\n",
       " 'pottery▁',\n",
       " 'barn▁',\n",
       " 'diaper▁',\n",
       " 'bag▁',\n",
       " 'Only▁',\n",
       " 'swatched.▁',\n",
       " 'Precious▁',\n",
       " 'petals▁',\n",
       " ',▁',\n",
       " 'sweet',\n",
       " 'est▁',\n",
       " 'bling▁',\n",
       " 'and▁',\n",
       " 'lilac▁',\n",
       " 'to▁',\n",
       " '<unk>',\n",
       " 'ty▁',\n",
       " 'Only▁',\n",
       " 'problem▁',\n",
       " 'is▁',\n",
       " 'Nike▁',\n",
       " 'sign▁',\n",
       " 'is▁',\n",
       " 'peeling▁',\n",
       " 'Still▁',\n",
       " 'good▁',\n",
       " 'condition▁',\n",
       " '3▁',\n",
       " 'inches▁',\n",
       " 'These▁',\n",
       " 'zipper▁',\n",
       " 'linen▁',\n",
       " 'type▁',\n",
       " 'fabric▁',\n",
       " 'pillow',\n",
       " 'cases▁',\n",
       " 'fit▁',\n",
       " 'any▁',\n",
       " 'standard▁',\n",
       " 'throw▁',\n",
       " 'pillow.▁',\n",
       " 'Mickey▁',\n",
       " '<unk>',\n",
       " '!!▁',\n",
       " 'Adorable▁',\n",
       " 'for▁',\n",
       " 'the▁',\n",
       " 'Disney▁',\n",
       " 'fan!▁',\n",
       " 'Perfect▁',\n",
       " 'for▁',\n",
       " '<unk>',\n",
       " '<unk>',\n",
       " 'square▁',\n",
       " 'inserts.▁',\n",
       " 'Tags:▁',\n",
       " 'Minnie▁',\n",
       " 'Mouse,▁',\n",
       " 'Mickey▁',\n",
       " 'Mouse,▁',\n",
       " 'Mickey▁',\n",
       " 'Ear',\n",
       " 's,▁',\n",
       " 'Disney▁',\n",
       " '<unk>',\n",
       " 's,▁',\n",
       " 'W',\n",
       " 'D',\n",
       " 'W,▁',\n",
       " '<unk>',\n",
       " ',▁',\n",
       " 'Wedding,▁',\n",
       " 'Shower▁',\n",
       " 'gift,▁',\n",
       " '<unk>',\n",
       " 'ana,▁',\n",
       " 'polka▁',\n",
       " 'dots▁',\n",
       " 'VICTORIAS▁',\n",
       " 'SECRET▁',\n",
       " 'PINK▁',\n",
       " 'OL',\n",
       " 'IVE▁',\n",
       " 'GREEN▁',\n",
       " 'LOGO▁',\n",
       " 'SPORTS▁',\n",
       " 'BRA▁',\n",
       " 'WITH▁',\n",
       " 'MAT',\n",
       " 'CHING▁',\n",
       " '<unk>',\n",
       " 'COLOR▁',\n",
       " 'CHE',\n",
       " '<unk>',\n",
       " 'ON▁',\n",
       " 'EXTRA▁',\n",
       " 'LOW▁',\n",
       " 'RIS',\n",
       " 'E▁',\n",
       " 'CHE',\n",
       " 'E',\n",
       " '<unk>',\n",
       " 'TER▁',\n",
       " '<unk>',\n",
       " 'IE',\n",
       " '!▁',\n",
       " 'bra',\n",
       " '=',\n",
       " 'xsmall▁',\n",
       " '<unk>',\n",
       " '=',\n",
       " 'small▁',\n",
       " 'J',\n",
       " 'wo',\n",
       " 'ww',\n",
       " '▁',\n",
       " 'Natural▁',\n",
       " 'Black▁',\n",
       " '<unk>',\n",
       " ',▁',\n",
       " 'about▁',\n",
       " '1/4▁',\n",
       " 'used,▁',\n",
       " '13.5▁',\n",
       " 'fl▁',\n",
       " 'oz▁',\n",
       " 'Can▁',\n",
       " 'be▁',\n",
       " 'a▁',\n",
       " 'bracelet▁',\n",
       " 'or▁',\n",
       " '<unk>',\n",
       " 't.▁',\n",
       " 'Will▁',\n",
       " 'fit▁',\n",
       " '<unk>',\n",
       " ',▁',\n",
       " 'tie▁',\n",
       " 'to▁',\n",
       " 'fit▁',\n",
       " 'Brand▁',\n",
       " 'new▁',\n",
       " '3▁',\n",
       " 'micro▁',\n",
       " 'USB▁',\n",
       " 'for▁',\n",
       " 'Samsung▁',\n",
       " 'android▁',\n",
       " '3▁',\n",
       " 'feet▁',\n",
       " '6▁',\n",
       " '$▁',\n",
       " 'free▁',\n",
       " 'shipping▁',\n",
       " 'Brand▁',\n",
       " 'new▁',\n",
       " 'Oakley▁',\n",
       " 'jacket▁',\n",
       " 'paid▁',\n",
       " '[rm]▁',\n",
       " 'for▁',\n",
       " 'it.▁',\n",
       " 'Overall▁',\n",
       " 'very▁',\n",
       " 'warm,▁',\n",
       " 'soft▁',\n",
       " 'jacket▁',\n",
       " 'with▁',\n",
       " 'side▁',\n",
       " 'pockets.▁',\n",
       " 'Size▁',\n",
       " 'Small▁',\n",
       " 'but▁',\n",
       " 'would▁',\n",
       " 'fit▁',\n",
       " 'a▁',\n",
       " 'small',\n",
       " '-medium▁',\n",
       " \"Women's▁\",\n",
       " 'because▁',\n",
       " 'it▁',\n",
       " 'has▁',\n",
       " 'adjustable▁',\n",
       " 'straps▁',\n",
       " 'and▁',\n",
       " 'is▁',\n",
       " 'stretchy.▁',\n",
       " 'Strappy▁',\n",
       " 'back▁',\n",
       " 'and▁',\n",
       " 'cheeky▁',\n",
       " 'butt▁',\n",
       " 'if▁',\n",
       " \"you're▁\",\n",
       " 'a▁',\n",
       " 'medium▁',\n",
       " 'Deep▁',\n",
       " 'plunge▁',\n",
       " 'cut▁',\n",
       " 'From▁',\n",
       " '<unk>',\n",
       " 'ful▁',\n",
       " 'One▁',\n",
       " 'piece▁',\n",
       " '<unk>',\n",
       " 'kini▁',\n",
       " 'bodysuit▁',\n",
       " 'leot',\n",
       " 'ard▁',\n",
       " 'Beach▁',\n",
       " 'wear▁',\n",
       " 'yoga▁',\n",
       " 'apparel▁',\n",
       " 'I▁',\n",
       " 'can▁',\n",
       " 'do▁',\n",
       " 'free▁',\n",
       " 'shipping▁',\n",
       " 'at▁',\n",
       " 'best▁',\n",
       " 'Brand▁',\n",
       " 'new▁',\n",
       " 'Marc▁',\n",
       " 'Jacobs▁',\n",
       " '<unk>',\n",
       " 'ing▁',\n",
       " '<unk>',\n",
       " ',▁',\n",
       " 'can▁',\n",
       " 'also▁',\n",
       " 'be▁',\n",
       " 'used▁',\n",
       " 'as▁',\n",
       " 'a▁',\n",
       " 'makeup▁',\n",
       " 'bag.▁',\n",
       " 'Zipper▁',\n",
       " 'works,▁',\n",
       " 'no▁',\n",
       " 'flaws.▁',\n",
       " 'It▁',\n",
       " 'is▁',\n",
       " 'quilted▁',\n",
       " 'black▁',\n",
       " 'leather.▁',\n",
       " 'No▁',\n",
       " 'description▁',\n",
       " 'yet▁',\n",
       " 'Wore▁',\n",
       " '2▁',\n",
       " 'times',\n",
       " ';▁',\n",
       " 'skinny▁',\n",
       " 'leg▁',\n",
       " 'so▁',\n",
       " 'great▁',\n",
       " 'for▁',\n",
       " 'Fall▁',\n",
       " 'and▁',\n",
       " 'the▁',\n",
       " 'new▁',\n",
       " 'Fall▁',\n",
       " '<unk>',\n",
       " '!!!▁',\n",
       " 'First▁',\n",
       " '3▁',\n",
       " 'Ju',\n",
       " 'ras',\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time bpe.inverse_transform(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## look at encodings on subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Size small Bought from converse store New with tags Color is black retail 19.99$ Size 6 toddler kids'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = bpe_text[:100]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 416 µs, sys: 0 ns, total: 416 µs\n",
      "Wall time: 416 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([13369, 17397, 22224, 12654, 19409,  3645,  5714, 23369, 10213,\n",
       "        4890,  6956,  4091, 17419, 14561, 11255, 16139, 13369, 11926,\n",
       "        4252, 10689])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time tokens = bpe.transform(t)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Size▁',\n",
       " 'small▁',\n",
       " 'Bought▁',\n",
       " 'from▁',\n",
       " 'converse▁',\n",
       " 'store▁',\n",
       " 'New▁',\n",
       " 'with▁',\n",
       " 'tags▁',\n",
       " 'Color▁',\n",
       " 'is▁',\n",
       " 'black▁',\n",
       " 'retail▁',\n",
       " '19.',\n",
       " '99',\n",
       " '$▁',\n",
       " 'Size▁',\n",
       " '6▁',\n",
       " 'toddler▁',\n",
       " 'kids▁']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_tokens = bpe.inverse_transform(tokens)\n",
    "inv_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "def make_Xy(df, tokens_per_batch, max_batch_size):\n",
    "    df['text_tokens'] = df.text.apply(bpe.transform)\n",
    "    df['n_text_tokens'] = df.text_tokens.apply(len)\n",
    "    df.sort_values('n_text_tokens', inplace=True)\n",
    "    df['batch'] = df.n_text_tokens.cumsum() % tokens_per_batch\n",
    "    def gen():\n",
    "        while True:\n",
    "            for b in df.batch:\n",
    "                batch = df[df.batch == b]\n",
    "                batch = batch.sample(frac=1)\n",
    "                for i in range(len(batch) // max_batch_size):\n",
    "                    batch_chunk = batch.iloc[i*max_batch_size:(i+1)*max_batch_size]\n",
    "                    maxlen = batch_chunk.n_text_tokens.max()\n",
    "                    X = {\n",
    "                        'category_input': batch_chunk.category_id,\n",
    "                        'brand_input': batch_chunk.brand_id,\n",
    "                        'item_condition_input': batch_chunk.item_condition_id,\n",
    "                        'text_input': pad_sequences(batch_chunk.text_tokens, maxlen=maxlen),\n",
    "                        'shipping_input': batch_chunk.shipping\n",
    "                    }\n",
    "                    y = batch_chunk.price\n",
    "                    yield X, y\n",
    "    return df, gen, df.batch.nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dante/venvs/python36/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/home/dante/venvs/python36/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/dante/venvs/python36/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/home/dante/venvs/python36/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_train, Xy_train_gen, train_batches = make_Xy(df_train, 64*32, 250)\n",
    "df_test, Xy_test_gen, test_batches = make_Xy(df_test, 64*32, 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "\n",
    "category_input = keras.layers.Input(shape=(1,), name='category_input')\n",
    "brand_input = keras.layers.Input(shape=(1,), name='brand_input')\n",
    "item_condition_input = keras.layers.Input(shape=(1,), name='item_condition_input')\n",
    "text_input = keras.layers.Input(shape=(None,), name='text_input')\n",
    "shipping_input = keras.layers.Input(shape=(1,), name='shipping_input')\n",
    "inputs = [category_input, brand_input, item_condition_input, text_input, shipping_input]\n",
    "\n",
    "# categorical feature embeddings\n",
    "category_embedding = keras.layers.Embedding(\n",
    "    input_dim=df_train.category_id.nunique()+1,\n",
    "    output_dim=5, input_length=1)(category_input)\n",
    "\n",
    "brand_embedding = keras.layers.Embedding(\n",
    "    input_dim=df_train.brand_id.nunique()+1,\n",
    "    output_dim=5, input_length=1)(brand_input)\n",
    "\n",
    "item_condition_embedding = keras.layers.Embedding(\n",
    "    input_dim=df_train.item_condition_id.nunique()+1,\n",
    "    output_dim=5, input_length=1)(item_condition_input)\n",
    "\n",
    "embedding_tensors = [category_embedding, brand_embedding, item_condition_embedding]\n",
    "x_embeddings = keras.layers.Concatenate()([\n",
    "    keras.layers.Flatten()(embedding) for embedding in embedding_tensors\n",
    "])\n",
    "\n",
    "shipping_input = keras.layers.BatchNormalization()(shipping_input)\n",
    "\n",
    "\n",
    "# text feature\n",
    "Sum = keras.layers.Lambda(lambda x: K.sum(x, axis=1))\n",
    "\n",
    "def indices(dim1, dim2):\n",
    "    rows = K.arange(dim1)\n",
    "    cols = K.arange(dim2)\n",
    "    col_indices = K.reshape(K.tile(cols, [dim1]), (dim1, dim2))\n",
    "    row_indices = K.transpose(K.reshape(K.tile(rows, [dim2]), (dim2, dim1)))\n",
    "    return row_indices, col_indices\n",
    "\n",
    "def positional_encoding(inputs):\n",
    "    sequence_dim = K.shape(inputs)[1]\n",
    "    d_model_var = K.shape(inputs)[2]\n",
    "    d_model_int = K.int_shape(inputs)[2]\n",
    "    rows, cols = indices(sequence_dim, d_model_var)\n",
    "    rows, cols = K.cast(rows, dtype=K.floatx()), K.cast(cols, dtype=K.floatx())\n",
    "    numerator = rows\n",
    "    denominator = 10_000 ** ((2 * cols) / d_model_int)\n",
    "    encodings = K.switch(cols % 2, K.cos(numerator / denominator), K.sin(numerator / denominator))    \n",
    "    return inputs + encodings\n",
    "\n",
    "PositionalEncoding = keras.layers.Lambda(positional_encoding, output_shape=lambda x: x)\n",
    "\n",
    "def SelfAttention(X):\n",
    "    dim = K.int_shape(X)[-1]\n",
    "    q = keras.layers.Dense(dim)(X)\n",
    "    q = keras.layers.Dropout(0.1)(q)    \n",
    "    k = keras.layers.Dense(dim)(X)\n",
    "    k = keras.layers.Dropout(0.1)(k)\n",
    "    v = keras.layers.Dense(dim)(X)\n",
    "    v = keras.layers.Dropout(0.1)(v)\n",
    "    w = keras.layers.Dot((2, 2))([q, k])\n",
    "    w = keras.layers.Softmax(axis=1)(w)\n",
    "    return keras.layers.Dot((2, 1))([w, v])\n",
    "    \n",
    "\n",
    "text_embeddings = keras.layers.Embedding(\n",
    "    input_dim=len(bpe.vocab)+1, output_dim=10, input_length=None)(text_input)\n",
    "text_embeddings = PositionalEncoding(text_embeddings)\n",
    "text_embeddings = keras.layers.SpatialDropout1D(0.2)(text_embeddings)\n",
    "text_embeddings = keras.layers.Dropout(0.2)(text_embeddings)\n",
    "attention = SelfAttention(text_embeddings)\n",
    "x_text = Sum(attention)\n",
    "\n",
    "\n",
    "x = keras.layers.Concatenate()([x_embeddings, x_text, shipping_input])\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(K.int_shape(x)[-1], activation='relu')(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(1, activation='relu')(x)\n",
    "\n",
    "model = keras.models.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text_input (InputLayer)         (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, None, 10)     245580      text_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, None, 10)     0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, None, 10)     0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, None, 10)     0           spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 10)     110         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 10)     110         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, None, 10)     0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, None, 10)     0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "category_input (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "brand_input (InputLayer)        (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_condition_input (InputLaye (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, None, None)   0           dropout_2[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, None, 10)     110         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 5)         6325        category_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 5)         22290       brand_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 5)         30          item_condition_input[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "softmax_1 (Softmax)             (None, None, None)   0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, None, 10)     0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 5)            0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 5)            0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 5)            0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, None, 10)     0           softmax_1[0][0]                  \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "shipping_input (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 15)           0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 10)           0           dot_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1)            4           shipping_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 26)           0           concatenate_1[0][0]              \n",
      "                                                                 lambda_1[0][0]                   \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 26)           0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 26)           104         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 26)           702         batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 26)           104         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            27          batch_normalization_3[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 275,496\n",
      "Trainable params: 275,390\n",
      "Non-trainable params: 106\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"1213pt\" viewBox=\"0.00 0.00 1007.50 1213.00\" width=\"1008pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 1209)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-1209 1003.5,-1209 1003.5,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 139762046437472 -->\n",
       "<g class=\"node\" id=\"node1\"><title>139762046437472</title>\n",
       "<polygon fill=\"none\" points=\"136,-1168.5 136,-1204.5 275,-1204.5 275,-1168.5 136,-1168.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"205.5\" y=\"-1182.8\">text_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139761521153304 -->\n",
       "<g class=\"node\" id=\"node2\"><title>139761521153304</title>\n",
       "<polygon fill=\"none\" points=\"125,-1095.5 125,-1131.5 286,-1131.5 286,-1095.5 125,-1095.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"205.5\" y=\"-1109.8\">embedding_4: Embedding</text>\n",
       "</g>\n",
       "<!-- 139762046437472&#45;&gt;139761521153304 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>139762046437472-&gt;139761521153304</title>\n",
       "<path d=\"M205.5,-1168.31C205.5,-1160.29 205.5,-1150.55 205.5,-1141.57\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"209,-1141.53 205.5,-1131.53 202,-1141.53 209,-1141.53\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139761570701152 -->\n",
       "<g class=\"node\" id=\"node3\"><title>139761570701152</title>\n",
       "<polygon fill=\"none\" points=\"144,-1022.5 144,-1058.5 267,-1058.5 267,-1022.5 144,-1022.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"205.5\" y=\"-1036.8\">lambda_2: Lambda</text>\n",
       "</g>\n",
       "<!-- 139761521153304&#45;&gt;139761570701152 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>139761521153304-&gt;139761570701152</title>\n",
       "<path d=\"M205.5,-1095.31C205.5,-1087.29 205.5,-1077.55 205.5,-1068.57\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"209,-1068.53 205.5,-1058.53 202,-1068.53 209,-1068.53\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139761570393616 -->\n",
       "<g class=\"node\" id=\"node4\"><title>139761570393616</title>\n",
       "<polygon fill=\"none\" points=\"88.5,-949.5 88.5,-985.5 322.5,-985.5 322.5,-949.5 88.5,-949.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"205.5\" y=\"-963.8\">spatial_dropout1d_1: SpatialDropout1D</text>\n",
       "</g>\n",
       "<!-- 139761570701152&#45;&gt;139761570393616 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>139761570701152-&gt;139761570393616</title>\n",
       "<path d=\"M205.5,-1022.31C205.5,-1014.29 205.5,-1004.55 205.5,-995.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"209,-995.529 205.5,-985.529 202,-995.529 209,-995.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139761644086776 -->\n",
       "<g class=\"node\" id=\"node5\"><title>139761644086776</title>\n",
       "<polygon fill=\"none\" points=\"143,-876.5 143,-912.5 268,-912.5 268,-876.5 143,-876.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"205.5\" y=\"-890.8\">dropout_1: Dropout</text>\n",
       "</g>\n",
       "<!-- 139761570393616&#45;&gt;139761644086776 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>139761570393616-&gt;139761644086776</title>\n",
       "<path d=\"M205.5,-949.313C205.5,-941.289 205.5,-931.547 205.5,-922.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"209,-922.529 205.5,-912.529 202,-922.529 209,-922.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139761630788632 -->\n",
       "<g class=\"node\" id=\"node6\"><title>139761630788632</title>\n",
       "<polygon fill=\"none\" points=\"22.5,-803.5 22.5,-839.5 124.5,-839.5 124.5,-803.5 22.5,-803.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"73.5\" y=\"-817.8\">dense_1: Dense</text>\n",
       "</g>\n",
       "<!-- 139761644086776&#45;&gt;139761630788632 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>139761644086776-&gt;139761630788632</title>\n",
       "<path d=\"M173.883,-876.494C155.973,-866.861 133.377,-854.707 114.161,-844.37\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"115.782,-841.268 105.317,-839.614 112.466,-847.433 115.782,-841.268\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139761529135736 -->\n",
       "<g class=\"node\" id=\"node7\"><title>139761529135736</title>\n",
       "<polygon fill=\"none\" points=\"154.5,-803.5 154.5,-839.5 256.5,-839.5 256.5,-803.5 154.5,-803.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"205.5\" y=\"-817.8\">dense_2: Dense</text>\n",
       "</g>\n",
       "<!-- 139761644086776&#45;&gt;139761529135736 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>139761644086776-&gt;139761529135736</title>\n",
       "<path d=\"M205.5,-876.313C205.5,-868.289 205.5,-858.547 205.5,-849.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"209,-849.529 205.5,-839.529 202,-849.529 209,-849.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139761586832552 -->\n",
       "<g class=\"node\" id=\"node14\"><title>139761586832552</title>\n",
       "<polygon fill=\"none\" points=\"285.5,-803.5 285.5,-839.5 387.5,-839.5 387.5,-803.5 285.5,-803.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"336.5\" y=\"-817.8\">dense_3: Dense</text>\n",
       "</g>\n",
       "<!-- 139761644086776&#45;&gt;139761586832552 -->\n",
       "<g class=\"edge\" id=\"edge11\"><title>139761644086776-&gt;139761586832552</title>\n",
       "<path d=\"M236.878,-876.494C254.571,-866.904 276.873,-854.817 295.888,-844.511\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"297.8,-847.456 304.924,-839.614 294.465,-841.302 297.8,-847.456\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139761643386248 -->\n",
       "<g class=\"node\" id=\"node8\"><title>139761643386248</title>\n",
       "<polygon fill=\"none\" points=\"0,-730.5 0,-766.5 125,-766.5 125,-730.5 0,-730.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-744.8\">dropout_2: Dropout</text>\n",
       "</g>\n",
       "<!-- 139761630788632&#45;&gt;139761643386248 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>139761630788632-&gt;139761643386248</title>\n",
       "<path d=\"M70.8372,-803.313C69.5941,-795.289 68.0848,-785.547 66.6938,-776.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"70.1281,-775.875 65.1383,-766.529 63.2106,-776.947 70.1281,-775.875\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139761546015128 -->\n",
       "<g class=\"node\" id=\"node9\"><title>139761546015128</title>\n",
       "<polygon fill=\"none\" points=\"143,-730.5 143,-766.5 268,-766.5 268,-730.5 143,-730.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"205.5\" y=\"-744.8\">dropout_3: Dropout</text>\n",
       "</g>\n",
       "<!-- 139761529135736&#45;&gt;139761546015128 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>139761529135736-&gt;139761546015128</title>\n",
       "<path d=\"M205.5,-803.313C205.5,-795.289 205.5,-785.547 205.5,-776.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"209,-776.529 205.5,-766.529 202,-776.529 209,-776.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139761650024632 -->\n",
       "<g class=\"node\" id=\"node13\"><title>139761650024632</title>\n",
       "<polygon fill=\"none\" points=\"168,-657.5 168,-693.5 243,-693.5 243,-657.5 168,-657.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"205.5\" y=\"-671.8\">dot_1: Dot</text>\n",
       "</g>\n",
       "<!-- 139761643386248&#45;&gt;139761650024632 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>139761643386248-&gt;139761650024632</title>\n",
       "<path d=\"M96.7521,-730.494C116.33,-720.773 141.076,-708.487 162.015,-698.09\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"163.632,-701.196 171.032,-693.614 160.519,-694.926 163.632,-701.196\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139761546015128&#45;&gt;139761650024632 -->\n",
       "<g class=\"edge\" id=\"edge10\"><title>139761546015128-&gt;139761650024632</title>\n",
       "<path d=\"M205.5,-730.313C205.5,-722.289 205.5,-712.547 205.5,-703.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"209,-703.529 205.5,-693.529 202,-703.529 209,-703.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139761555896864 -->\n",
       "<g class=\"node\" id=\"node10\"><title>139761555896864</title>\n",
       "<polygon fill=\"none\" points=\"364,-657.5 364,-693.5 529,-693.5 529,-657.5 364,-657.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"446.5\" y=\"-671.8\">category_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139762046438536 -->\n",
       "<g class=\"node\" id=\"node15\"><title>139762046438536</title>\n",
       "<polygon fill=\"none\" points=\"365,-584.5 365,-620.5 526,-620.5 526,-584.5 365,-584.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"445.5\" y=\"-598.8\">embedding_1: Embedding</text>\n",
       "</g>\n",
       "<!-- 139761555896864&#45;&gt;139762046438536 -->\n",
       "<g class=\"edge\" id=\"edge12\"><title>139761555896864-&gt;139762046438536</title>\n",
       "<path d=\"M446.258,-657.313C446.145,-649.289 446.008,-639.547 445.881,-630.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"449.38,-630.479 445.74,-620.529 442.381,-630.577 449.38,-630.479\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139761555896080 -->\n",
       "<g class=\"node\" id=\"node11\"><title>139761555896080</title>\n",
       "<polygon fill=\"none\" points=\"549,-657.5 549,-693.5 698,-693.5 698,-657.5 549,-657.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"623.5\" y=\"-671.8\">brand_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139762046438816 -->\n",
       "<g class=\"node\" id=\"node16\"><title>139762046438816</title>\n",
       "<polygon fill=\"none\" points=\"544,-584.5 544,-620.5 705,-620.5 705,-584.5 544,-584.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"624.5\" y=\"-598.8\">embedding_2: Embedding</text>\n",
       "</g>\n",
       "<!-- 139761555896080&#45;&gt;139762046438816 -->\n",
       "<g class=\"edge\" id=\"edge13\"><title>139761555896080-&gt;139762046438816</title>\n",
       "<path d=\"M623.742,-657.313C623.855,-649.289 623.992,-639.547 624.119,-630.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"627.619,-630.577 624.26,-620.529 620.62,-630.479 627.619,-630.577\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139761654048696 -->\n",
       "<g class=\"node\" id=\"node12\"><title>139761654048696</title>\n",
       "<polygon fill=\"none\" points=\"716,-657.5 716,-693.5 917,-693.5 917,-657.5 716,-657.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"816.5\" y=\"-671.8\">item_condition_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139761656592312 -->\n",
       "<g class=\"node\" id=\"node17\"><title>139761656592312</title>\n",
       "<polygon fill=\"none\" points=\"729,-584.5 729,-620.5 890,-620.5 890,-584.5 729,-584.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"809.5\" y=\"-598.8\">embedding_3: Embedding</text>\n",
       "</g>\n",
       "<!-- 139761654048696&#45;&gt;139761656592312 -->\n",
       "<g class=\"edge\" id=\"edge14\"><title>139761654048696-&gt;139761656592312</title>\n",
       "<path d=\"M814.805,-657.313C814.014,-649.289 813.054,-639.547 812.169,-630.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"815.643,-630.137 811.179,-620.529 808.677,-630.824 815.643,-630.137\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139761570416736 -->\n",
       "<g class=\"node\" id=\"node18\"><title>139761570416736</title>\n",
       "<polygon fill=\"none\" points=\"166.5,-584.5 166.5,-620.5 294.5,-620.5 294.5,-584.5 166.5,-584.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"230.5\" y=\"-598.8\">softmax_1: Softmax</text>\n",
       "</g>\n",
       "<!-- 139761650024632&#45;&gt;139761570416736 -->\n",
       "<g class=\"edge\" id=\"edge15\"><title>139761650024632-&gt;139761570416736</title>\n",
       "<path d=\"M211.552,-657.313C214.438,-649.115 217.957,-639.123 221.174,-629.985\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"224.484,-631.124 224.504,-620.529 217.881,-628.799 224.484,-631.124\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139761570416512 -->\n",
       "<g class=\"node\" id=\"node19\"><title>139761570416512</title>\n",
       "<polygon fill=\"none\" points=\"286,-730.5 286,-766.5 411,-766.5 411,-730.5 286,-730.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"348.5\" y=\"-744.8\">dropout_4: Dropout</text>\n",
       "</g>\n",
       "<!-- 139761586832552&#45;&gt;139761570416512 -->\n",
       "<g class=\"edge\" id=\"edge16\"><title>139761586832552-&gt;139761570416512</title>\n",
       "<path d=\"M339.405,-803.313C340.761,-795.289 342.407,-785.547 343.925,-776.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"347.406,-776.972 345.622,-766.529 340.504,-775.806 347.406,-776.972\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139761656592872 -->\n",
       "<g class=\"node\" id=\"node20\"><title>139761656592872</title>\n",
       "<polygon fill=\"none\" points=\"416.5,-511.5 416.5,-547.5 526.5,-547.5 526.5,-511.5 416.5,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"471.5\" y=\"-525.8\">flatten_1: Flatten</text>\n",
       "</g>\n",
       "<!-- 139762046438536&#45;&gt;139761656592872 -->\n",
       "<g class=\"edge\" id=\"edge17\"><title>139762046438536-&gt;139761656592872</title>\n",
       "<path d=\"M451.794,-584.313C454.796,-576.115 458.455,-566.123 461.801,-556.985\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"465.112,-558.123 465.264,-547.529 458.539,-555.715 465.112,-558.123\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139761656591920 -->\n",
       "<g class=\"node\" id=\"node21\"><title>139761656591920</title>\n",
       "<polygon fill=\"none\" points=\"556.5,-511.5 556.5,-547.5 666.5,-547.5 666.5,-511.5 556.5,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"611.5\" y=\"-525.8\">flatten_2: Flatten</text>\n",
       "</g>\n",
       "<!-- 139762046438816&#45;&gt;139761656591920 -->\n",
       "<g class=\"edge\" id=\"edge18\"><title>139762046438816-&gt;139761656591920</title>\n",
       "<path d=\"M621.353,-584.313C619.884,-576.289 618.1,-566.547 616.456,-557.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"619.862,-556.735 614.618,-547.529 612.976,-557.996 619.862,-556.735\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139761649924136 -->\n",
       "<g class=\"node\" id=\"node22\"><title>139761649924136</title>\n",
       "<polygon fill=\"none\" points=\"684.5,-511.5 684.5,-547.5 794.5,-547.5 794.5,-511.5 684.5,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"739.5\" y=\"-525.8\">flatten_3: Flatten</text>\n",
       "</g>\n",
       "<!-- 139761656592312&#45;&gt;139761649924136 -->\n",
       "<g class=\"edge\" id=\"edge19\"><title>139761656592312-&gt;139761649924136</title>\n",
       "<path d=\"M792.555,-584.313C783.785,-575.417 772.932,-564.409 763.331,-554.672\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"765.802,-552.193 756.289,-547.529 760.817,-557.107 765.802,-552.193\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139761536827912 -->\n",
       "<g class=\"node\" id=\"node23\"><title>139761536827912</title>\n",
       "<polygon fill=\"none\" points=\"298,-511.5 298,-547.5 373,-547.5 373,-511.5 298,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"335.5\" y=\"-525.8\">dot_2: Dot</text>\n",
       "</g>\n",
       "<!-- 139761570416736&#45;&gt;139761536827912 -->\n",
       "<g class=\"edge\" id=\"edge20\"><title>139761570416736-&gt;139761536827912</title>\n",
       "<path d=\"M255.65,-584.494C269.445,-575.166 286.735,-563.474 301.696,-553.358\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"303.868,-556.114 310.191,-547.614 299.947,-550.316 303.868,-556.114\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139761570416512&#45;&gt;139761536827912 -->\n",
       "<g class=\"edge\" id=\"edge21\"><title>139761570416512-&gt;139761536827912</title>\n",
       "<path d=\"M347.48,-730.472C345.236,-693.011 339.854,-603.176 337.133,-557.764\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"340.625,-557.522 336.533,-547.749 333.638,-557.94 340.625,-557.522\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139761656594328 -->\n",
       "<g class=\"node\" id=\"node25\"><title>139761656594328</title>\n",
       "<polygon fill=\"none\" points=\"527.5,-438.5 527.5,-474.5 695.5,-474.5 695.5,-438.5 527.5,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"611.5\" y=\"-452.8\">concatenate_1: Concatenate</text>\n",
       "</g>\n",
       "<!-- 139761656592872&#45;&gt;139761656594328 -->\n",
       "<g class=\"edge\" id=\"edge22\"><title>139761656592872-&gt;139761656594328</title>\n",
       "<path d=\"M505.033,-511.494C524.114,-501.817 548.211,-489.597 568.652,-479.23\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"570.419,-482.258 577.755,-474.614 567.253,-476.015 570.419,-482.258\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139761656591920&#45;&gt;139761656594328 -->\n",
       "<g class=\"edge\" id=\"edge23\"><title>139761656591920-&gt;139761656594328</title>\n",
       "<path d=\"M611.5,-511.313C611.5,-503.289 611.5,-493.547 611.5,-484.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"615,-484.529 611.5,-474.529 608,-484.529 615,-484.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139761649924136&#45;&gt;139761656594328 -->\n",
       "<g class=\"edge\" id=\"edge24\"><title>139761649924136-&gt;139761656594328</title>\n",
       "<path d=\"M708.841,-511.494C691.553,-501.904 669.761,-489.817 651.182,-479.511\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"652.795,-476.404 642.353,-474.614 649.4,-482.525 652.795,-476.404\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139761522128040 -->\n",
       "<g class=\"node\" id=\"node26\"><title>139761522128040</title>\n",
       "<polygon fill=\"none\" points=\"330,-438.5 330,-474.5 453,-474.5 453,-438.5 330,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"391.5\" y=\"-452.8\">lambda_1: Lambda</text>\n",
       "</g>\n",
       "<!-- 139761536827912&#45;&gt;139761522128040 -->\n",
       "<g class=\"edge\" id=\"edge25\"><title>139761536827912-&gt;139761522128040</title>\n",
       "<path d=\"M349.056,-511.313C355.866,-502.679 364.245,-492.055 371.755,-482.534\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"374.624,-484.548 378.069,-474.529 369.128,-480.213 374.624,-484.548\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139762046436688 -->\n",
       "<g class=\"node\" id=\"node24\"><title>139762046436688</title>\n",
       "<polygon fill=\"none\" points=\"813,-511.5 813,-547.5 978,-547.5 978,-511.5 813,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"895.5\" y=\"-525.8\">shipping_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139761656591528 -->\n",
       "<g class=\"node\" id=\"node27\"><title>139761656591528</title>\n",
       "<polygon fill=\"none\" points=\"739.5,-438.5 739.5,-474.5 999.5,-474.5 999.5,-438.5 739.5,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"869.5\" y=\"-452.8\">batch_normalization_1: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 139762046436688&#45;&gt;139761656591528 -->\n",
       "<g class=\"edge\" id=\"edge26\"><title>139762046436688-&gt;139761656591528</title>\n",
       "<path d=\"M889.206,-511.313C886.204,-503.115 882.545,-493.123 879.199,-483.985\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"882.461,-482.715 875.736,-474.529 875.888,-485.123 882.461,-482.715\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139761570414664 -->\n",
       "<g class=\"node\" id=\"node28\"><title>139761570414664</title>\n",
       "<polygon fill=\"none\" points=\"527.5,-365.5 527.5,-401.5 695.5,-401.5 695.5,-365.5 527.5,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"611.5\" y=\"-379.8\">concatenate_2: Concatenate</text>\n",
       "</g>\n",
       "<!-- 139761656594328&#45;&gt;139761570414664 -->\n",
       "<g class=\"edge\" id=\"edge27\"><title>139761656594328-&gt;139761570414664</title>\n",
       "<path d=\"M611.5,-438.313C611.5,-430.289 611.5,-420.547 611.5,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"615,-411.529 611.5,-401.529 608,-411.529 615,-411.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139761522128040&#45;&gt;139761570414664 -->\n",
       "<g class=\"edge\" id=\"edge28\"><title>139761522128040-&gt;139761570414664</title>\n",
       "<path d=\"M444.195,-438.494C475.665,-428.338 515.817,-415.379 548.898,-404.704\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"550.03,-408.016 558.472,-401.614 547.88,-401.354 550.03,-408.016\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139761656591528&#45;&gt;139761570414664 -->\n",
       "<g class=\"edge\" id=\"edge29\"><title>139761656591528-&gt;139761570414664</title>\n",
       "<path d=\"M807.703,-438.494C770.322,-428.207 722.496,-415.045 683.421,-404.292\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"684.258,-400.892 673.687,-401.614 682.4,-407.642 684.258,-400.892\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139761521154256 -->\n",
       "<g class=\"node\" id=\"node29\"><title>139761521154256</title>\n",
       "<polygon fill=\"none\" points=\"549,-292.5 549,-328.5 674,-328.5 674,-292.5 549,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"611.5\" y=\"-306.8\">dropout_5: Dropout</text>\n",
       "</g>\n",
       "<!-- 139761570414664&#45;&gt;139761521154256 -->\n",
       "<g class=\"edge\" id=\"edge30\"><title>139761570414664-&gt;139761521154256</title>\n",
       "<path d=\"M611.5,-365.313C611.5,-357.289 611.5,-347.547 611.5,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"615,-338.529 611.5,-328.529 608,-338.529 615,-338.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139761643910704 -->\n",
       "<g class=\"node\" id=\"node30\"><title>139761643910704</title>\n",
       "<polygon fill=\"none\" points=\"481.5,-219.5 481.5,-255.5 741.5,-255.5 741.5,-219.5 481.5,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"611.5\" y=\"-233.8\">batch_normalization_2: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 139761521154256&#45;&gt;139761643910704 -->\n",
       "<g class=\"edge\" id=\"edge31\"><title>139761521154256-&gt;139761643910704</title>\n",
       "<path d=\"M611.5,-292.313C611.5,-284.289 611.5,-274.547 611.5,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"615,-265.529 611.5,-255.529 608,-265.529 615,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139761654841016 -->\n",
       "<g class=\"node\" id=\"node31\"><title>139761654841016</title>\n",
       "<polygon fill=\"none\" points=\"560.5,-146.5 560.5,-182.5 662.5,-182.5 662.5,-146.5 560.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"611.5\" y=\"-160.8\">dense_4: Dense</text>\n",
       "</g>\n",
       "<!-- 139761643910704&#45;&gt;139761654841016 -->\n",
       "<g class=\"edge\" id=\"edge32\"><title>139761643910704-&gt;139761654841016</title>\n",
       "<path d=\"M611.5,-219.313C611.5,-211.289 611.5,-201.547 611.5,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"615,-192.529 611.5,-182.529 608,-192.529 615,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139761627613728 -->\n",
       "<g class=\"node\" id=\"node32\"><title>139761627613728</title>\n",
       "<polygon fill=\"none\" points=\"481.5,-73.5 481.5,-109.5 741.5,-109.5 741.5,-73.5 481.5,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"611.5\" y=\"-87.8\">batch_normalization_3: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 139761654841016&#45;&gt;139761627613728 -->\n",
       "<g class=\"edge\" id=\"edge33\"><title>139761654841016-&gt;139761627613728</title>\n",
       "<path d=\"M611.5,-146.313C611.5,-138.289 611.5,-128.547 611.5,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"615,-119.529 611.5,-109.529 608,-119.529 615,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139761643193120 -->\n",
       "<g class=\"node\" id=\"node33\"><title>139761643193120</title>\n",
       "<polygon fill=\"none\" points=\"560.5,-0.5 560.5,-36.5 662.5,-36.5 662.5,-0.5 560.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"611.5\" y=\"-14.8\">dense_5: Dense</text>\n",
       "</g>\n",
       "<!-- 139761627613728&#45;&gt;139761643193120 -->\n",
       "<g class=\"edge\" id=\"edge34\"><title>139761627613728-&gt;139761643193120</title>\n",
       "<path d=\"M611.5,-73.3129C611.5,-65.2895 611.5,-55.5475 611.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"615,-46.5288 611.5,-36.5288 608,-46.5289 615,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(K.log(y_pred+1.) - K.log(y_true+1.))))\n",
    "model.compile(loss=rmsle, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2048/2048 [==============================] - 123s 60ms/step - loss: 0.9544 - val_loss: 0.8149\n",
      "Epoch 2/10\n",
      "2048/2048 [==============================] - 130s 64ms/step - loss: 0.5894 - val_loss: 0.8396\n",
      "Epoch 3/10\n",
      "2048/2048 [==============================] - 133s 65ms/step - loss: 0.5712 - val_loss: 0.7677\n",
      "Epoch 4/10\n",
      "2048/2048 [==============================] - 149s 73ms/step - loss: 0.5392 - val_loss: 0.7378\n",
      "Epoch 5/10\n",
      "2048/2048 [==============================] - 99s 48ms/step - loss: 0.5288 - val_loss: 0.7197\n",
      "Epoch 6/10\n",
      "2048/2048 [==============================] - 83s 41ms/step - loss: 0.5219 - val_loss: 0.7084\n",
      "Epoch 7/10\n",
      "2048/2048 [==============================] - 101s 49ms/step - loss: 0.5209 - val_loss: 0.7073\n",
      "Epoch 8/10\n",
      "2048/2048 [==============================] - 129s 63ms/step - loss: 0.5217 - val_loss: 0.6990\n",
      "Epoch 9/10\n",
      "2048/2048 [==============================] - 137s 67ms/step - loss: 0.5201 - val_loss: 0.6926\n",
      "Epoch 10/10\n",
      "2048/2048 [==============================] - 119s 58ms/step - loss: 0.5179 - val_loss: 0.6930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1ccabc32b0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    Xy_train_gen(),\n",
    "    epochs=10,\n",
    "    steps_per_epoch=train_batches,\n",
    "    validation_data=Xy_test_gen(),\n",
    "    validation_steps=test_batches,\n",
    "    callbacks=[keras.callbacks.ReduceLROnPlateau(patience=2),\n",
    "               keras.callbacks.EarlyStopping(patience=3),\n",
    "               keras.callbacks.TerminateOnNaN()]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
