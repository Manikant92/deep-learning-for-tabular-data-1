{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv('mercari-price-suggestion-challenge/train.tsv', sep='\\t')\n",
    "df_train, df_test = train_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1111901, 8), (370634, 8))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>381548</th>\n",
       "      <td>381548</td>\n",
       "      <td>Dance gymnastics leotard and shorts</td>\n",
       "      <td>3</td>\n",
       "      <td>Sports &amp; Outdoors/Exercise/Dance/Ballet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Child medium- large. Fits size 10. Like new. U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87881</th>\n",
       "      <td>87881</td>\n",
       "      <td>Fossil key fob hang tag</td>\n",
       "      <td>3</td>\n",
       "      <td>Women/Women's Accessories/Wallets</td>\n",
       "      <td>Fossil</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Euc Green leather hang tag Penny for size Smok...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1411934</th>\n",
       "      <td>1411934</td>\n",
       "      <td>Shopkins valentine target retired</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Jewelry/Bracelets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Shopkins exclusive target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841742</th>\n",
       "      <td>841742</td>\n",
       "      <td>AirPort Express</td>\n",
       "      <td>3</td>\n",
       "      <td>Electronics/Computers &amp; Tablets/Networking &amp; C...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Working conditions Model no A1264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588200</th>\n",
       "      <td>588200</td>\n",
       "      <td>Under Armour Dri Fit Shirt Capt America</td>\n",
       "      <td>3</td>\n",
       "      <td>Kids/Boys (4+)/Top &amp; T-shirts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Under Armour Fitted heat gear size YSM Don't f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         train_id                                     name  item_condition_id  \\\n",
       "381548     381548      Dance gymnastics leotard and shorts                  3   \n",
       "87881       87881                  Fossil key fob hang tag                  3   \n",
       "1411934   1411934        Shopkins valentine target retired                  1   \n",
       "841742     841742                          AirPort Express                  3   \n",
       "588200     588200  Under Armour Dri Fit Shirt Capt America                  3   \n",
       "\n",
       "                                             category_name brand_name  price  \\\n",
       "381548             Sports & Outdoors/Exercise/Dance/Ballet        NaN   13.0   \n",
       "87881                    Women/Women's Accessories/Wallets     Fossil    7.0   \n",
       "1411934                            Women/Jewelry/Bracelets        NaN   14.0   \n",
       "841742   Electronics/Computers & Tablets/Networking & C...      Apple   24.0   \n",
       "588200                       Kids/Boys (4+)/Top & T-shirts        NaN   16.0   \n",
       "\n",
       "         shipping                                   item_description  \n",
       "381548          0  Child medium- large. Fits size 10. Like new. U...  \n",
       "87881           1  Euc Green leather hang tag Penny for size Smok...  \n",
       "1411934         0                          Shopkins exclusive target  \n",
       "841742          0                  Working conditions Model no A1264  \n",
       "588200          0  Under Armour Fitted heat gear size YSM Don't f...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.111901e+06</td>\n",
       "      <td>1111901</td>\n",
       "      <td>1.111901e+06</td>\n",
       "      <td>1107161</td>\n",
       "      <td>637059</td>\n",
       "      <td>1.111901e+06</td>\n",
       "      <td>1.111901e+06</td>\n",
       "      <td>1111898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>936806</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1260</td>\n",
       "      <td>4446</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>967812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Bundle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Women/Athletic Apparel/Pants, Tights, Leggings</td>\n",
       "      <td>PINK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No description yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1699</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45146</td>\n",
       "      <td>40633</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.411717e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.907756e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.674288e+01</td>\n",
       "      <td>4.470389e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.280134e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.031632e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.865995e+01</td>\n",
       "      <td>4.971874e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.705850e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.410450e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.700000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.111970e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.900000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.482534e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.009000e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            train_id     name  item_condition_id  \\\n",
       "count   1.111901e+06  1111901       1.111901e+06   \n",
       "unique           NaN   936806                NaN   \n",
       "top              NaN   Bundle                NaN   \n",
       "freq             NaN     1699                NaN   \n",
       "mean    7.411717e+05      NaN       1.907756e+00   \n",
       "std     4.280134e+05      NaN       9.031632e-01   \n",
       "min     0.000000e+00      NaN       1.000000e+00   \n",
       "25%     3.705850e+05      NaN       1.000000e+00   \n",
       "50%     7.410450e+05      NaN       2.000000e+00   \n",
       "75%     1.111970e+06      NaN       3.000000e+00   \n",
       "max     1.482534e+06      NaN       5.000000e+00   \n",
       "\n",
       "                                         category_name brand_name  \\\n",
       "count                                          1107161     637059   \n",
       "unique                                            1260       4446   \n",
       "top     Women/Athletic Apparel/Pants, Tights, Leggings       PINK   \n",
       "freq                                             45146      40633   \n",
       "mean                                               NaN        NaN   \n",
       "std                                                NaN        NaN   \n",
       "min                                                NaN        NaN   \n",
       "25%                                                NaN        NaN   \n",
       "50%                                                NaN        NaN   \n",
       "75%                                                NaN        NaN   \n",
       "max                                                NaN        NaN   \n",
       "\n",
       "               price      shipping    item_description  \n",
       "count   1.111901e+06  1.111901e+06             1111898  \n",
       "unique           NaN           NaN              967812  \n",
       "top              NaN           NaN  No description yet  \n",
       "freq             NaN           NaN               61768  \n",
       "mean    2.674288e+01  4.470389e-01                 NaN  \n",
       "std     3.865995e+01  4.971874e-01                 NaN  \n",
       "min     0.000000e+00  0.000000e+00                 NaN  \n",
       "25%     1.000000e+01  0.000000e+00                 NaN  \n",
       "50%     1.700000e+01  0.000000e+00                 NaN  \n",
       "75%     2.900000e+01  1.000000e+00                 NaN  \n",
       "max     2.009000e+03  1.000000e+00                 NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/dgates/venvs/py3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/dgates/venvs/py3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/Users/dgates/venvs/py3/lib/python3.6/site-packages/pandas/core/frame.py:3790: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n",
      "/Users/dgates/venvs/py3/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/dgates/venvs/py3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "def make_Xy(df, *, tokenizer=None, num_words=2000, maxlen=35):\n",
    "    category_ids = {v: i for i, v in enumerate(df.category_name.unique(), start=1)}\n",
    "    brand_ids = {v: i for i, v in enumerate(df.brand_name.unique(), start=1)}\n",
    "    df['category_id'] = df.category_name.map(category_ids)\n",
    "    df['brand_id'] = df.brand_name.map(brand_ids)\n",
    "    \n",
    "    df[['category_id', 'brand_id', 'item_condition_id']].fillna(0, inplace=True)\n",
    "    df['text'] = df.name + ' ' + df.item_description.str.replace('No description yet', '')\n",
    "    df['text'] = df.text.astype(str)\n",
    "\n",
    "    X = {\n",
    "        'category_input': df.category_id,\n",
    "        'brand_input': df.brand_id,\n",
    "        'item_condition_input': df.item_condition_id\n",
    "    }\n",
    "    y = df.price\n",
    "\n",
    "    return X, y, tokenizer\n",
    "\n",
    "X_train, y_train, tokenizer = make_Xy(df_train, num_words=2000, maxlen=35)\n",
    "X_test, y_test, _ = make_Xy(df_test, tokenizer=tokenizer, num_words=2000, maxlen=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.111901e+06\n",
       "mean     2.896458e+01\n",
       "std      3.086041e+01\n",
       "min      0.000000e+00\n",
       "25%      1.000000e+01\n",
       "50%      1.900000e+01\n",
       "75%      3.500000e+01\n",
       "max      2.460000e+02\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.text.str.count(' ').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "      <th>category_id</th>\n",
       "      <th>brand_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>381548</th>\n",
       "      <td>381548</td>\n",
       "      <td>Dance gymnastics leotard and shorts</td>\n",
       "      <td>3</td>\n",
       "      <td>Sports &amp; Outdoors/Exercise/Dance/Ballet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Child medium- large. Fits size 10. Like new. U...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dance gymnastics leotard and shorts Child medi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87881</th>\n",
       "      <td>87881</td>\n",
       "      <td>Fossil key fob hang tag</td>\n",
       "      <td>3</td>\n",
       "      <td>Women/Women's Accessories/Wallets</td>\n",
       "      <td>Fossil</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Euc Green leather hang tag Penny for size Smok...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Fossil key fob hang tag Euc Green leather hang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1411934</th>\n",
       "      <td>1411934</td>\n",
       "      <td>Shopkins valentine target retired</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Jewelry/Bracelets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Shopkins exclusive target</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Shopkins valentine target retired Shopkins exc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841742</th>\n",
       "      <td>841742</td>\n",
       "      <td>AirPort Express</td>\n",
       "      <td>3</td>\n",
       "      <td>Electronics/Computers &amp; Tablets/Networking &amp; C...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Working conditions Model no A1264</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>AirPort Express Working conditions Model no A1264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588200</th>\n",
       "      <td>588200</td>\n",
       "      <td>Under Armour Dri Fit Shirt Capt America</td>\n",
       "      <td>3</td>\n",
       "      <td>Kids/Boys (4+)/Top &amp; T-shirts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Under Armour Fitted heat gear size YSM Don't f...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Under Armour Dri Fit Shirt Capt America Under ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         train_id                                     name  item_condition_id  \\\n",
       "381548     381548      Dance gymnastics leotard and shorts                  3   \n",
       "87881       87881                  Fossil key fob hang tag                  3   \n",
       "1411934   1411934        Shopkins valentine target retired                  1   \n",
       "841742     841742                          AirPort Express                  3   \n",
       "588200     588200  Under Armour Dri Fit Shirt Capt America                  3   \n",
       "\n",
       "                                             category_name brand_name  price  \\\n",
       "381548             Sports & Outdoors/Exercise/Dance/Ballet        NaN   13.0   \n",
       "87881                    Women/Women's Accessories/Wallets     Fossil    7.0   \n",
       "1411934                            Women/Jewelry/Bracelets        NaN   14.0   \n",
       "841742   Electronics/Computers & Tablets/Networking & C...      Apple   24.0   \n",
       "588200                       Kids/Boys (4+)/Top & T-shirts        NaN   16.0   \n",
       "\n",
       "         shipping                                   item_description  \\\n",
       "381548          0  Child medium- large. Fits size 10. Like new. U...   \n",
       "87881           1  Euc Green leather hang tag Penny for size Smok...   \n",
       "1411934         0                          Shopkins exclusive target   \n",
       "841742          0                  Working conditions Model no A1264   \n",
       "588200          0  Under Armour Fitted heat gear size YSM Don't f...   \n",
       "\n",
       "         category_id  brand_id  \\\n",
       "381548             1         1   \n",
       "87881              2         2   \n",
       "1411934            3         1   \n",
       "841742             4         3   \n",
       "588200             5         1   \n",
       "\n",
       "                                                      text  \n",
       "381548   Dance gymnastics leotard and shorts Child medi...  \n",
       "87881    Fossil key fob hang tag Euc Green leather hang...  \n",
       "1411934  Shopkins valentine target retired Shopkins exc...  \n",
       "841742   AirPort Express Working conditions Model no A1264  \n",
       "588200   Under Armour Dri Fit Shirt Capt America Under ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build byte pair encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "def get_stats(list vocab, set removed_indices):\n",
    "    cdef int i_left, i_right\n",
    "    cdef dict pairs = {}\n",
    "    cdef dict indices = {}\n",
    "    valid_indices = (i for i in range(len(vocab) - 1)\n",
    "                     if not i in removed_indices)\n",
    "    i_left = next(valid_indices)\n",
    "    for i_right in valid_indices:\n",
    "        pair = vocab[i_left], vocab[i_right]\n",
    "        if not pair in pairs:\n",
    "            pairs[pair] = 0\n",
    "        pairs[pair] += 1\n",
    "        if not pair in indices:\n",
    "            indices[pair] = []\n",
    "        indices[pair].append(i_left)\n",
    "    return pairs, indices\n",
    "\n",
    "def merge_vocab(tuple pair, list vocab, list pair_indices, set removed_indices):\n",
    "    cdef str new = ''.join(pair)\n",
    "    cdef int i\n",
    "    for i in pair_indices:\n",
    "        vocab[i] = new\n",
    "    removed_indices.update(pair_indices)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import collections\n",
    "\n",
    "\n",
    "# def pairwise(iterable):\n",
    "#     \"s -> (s0,s1), (s1,s2), (s2, s3), ...\"\n",
    "#     a, b = itertools.tee(iterable)\n",
    "#     next(b, None)\n",
    "#     return zip(a, b)\n",
    "\n",
    "# def get_stats(vocab, removed_indices):\n",
    "#     pairs = collections.defaultdict(int)\n",
    "#     indices = collections.defaultdict(list)\n",
    "#     valid_indices = (i for i in range(len(vocab) - 1)\n",
    "#                      if not i in removed_indices)\n",
    "#     for i_left, i_right in pairwise(valid_indices):\n",
    "#         pair = vocab[i_left], vocab[i_right]\n",
    "#         pairs[pair] += 1\n",
    "#         indices[pair].append(i_left)\n",
    "#     return pairs, indices\n",
    "\n",
    "# def merge_vocab(pair, vocab, pair_indices, removed_indices):\n",
    "#     new = ''.join(pair)\n",
    "#     for i in reversed(pair_indices):\n",
    "#         vocab[i] = new\n",
    "#     removed_indices.update(pair_indices)\n",
    "#     return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import sklearn\n",
    "import itertools\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def grouper(iterable, n, fillvalue=None):\n",
    "    \"Collect data into fixed-length chunks or blocks\"\n",
    "    # grouper('ABCDEFG', 3, 'x') --> ABC DEF Gxx\"\n",
    "    args = [iter(iterable)] * n\n",
    "    iterable = itertools.zip_longest(*args, fillvalue=fillvalue)\n",
    "    return ([g for g in group if g] for group in iterable)\n",
    "\n",
    "\n",
    "class BytePairEncoder(sklearn.base.TransformerMixin):\n",
    "    def __init__(self, n_merges, n_jobs=None, chunksize=None, log_level=None):\n",
    "        self.n_merges = n_merges\n",
    "        self.n_jobs = n_jobs\n",
    "        self.chunksize = chunksize\n",
    "        self.log_level = log_level\n",
    "        self._space_escape = '▁'\n",
    "        self._unkown_token = 0\n",
    "\n",
    "    def fit(self, X):\n",
    "        vocab = list(self._process_X(X))\n",
    "        initial_vocab = set(vocab)\n",
    "        removed_indices = set()\n",
    "        for i in range(self.n_merges):\n",
    "            if self.log_level is not None and i % self.log_level == 0:\n",
    "                print(f'{i+1} iterations complete')\n",
    "            pairs, pair_index = get_stats(vocab, removed_indices)\n",
    "            best = max(pairs, key=pairs.get)\n",
    "            vocab = merge_vocab(best, vocab, pair_index[best], removed_indices)\n",
    "\n",
    "        # reserve 0 for unkowns\n",
    "        vocab = set(vocab)\n",
    "        vocab.update(initial_vocab)\n",
    "        self.vocab = {k: i for i, k in enumerate(vocab, start=1)}\n",
    "        bpe._reverse_vocab = {v: k for k, v in bpe.vocab.items()}\n",
    "        self._bpe_tree = build_bpe_tree(self.vocab)\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = self._process_X(X)\n",
    "        tokens = apply_bpe_tree(X, self._bpe_tree)\n",
    "        return np.array([self._unkown_token if t is None else t for t in tokens])\n",
    "\n",
    "    def inverse_transform(self, X):\n",
    "        return [bpe._reverse_vocab[t] if t > 0 else '<unk>' for t in tokens]\n",
    "\n",
    "    def _process_X(self, X):\n",
    "         return self._space_escape.join(X.split())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self):\n",
    "        self.children = {}\n",
    "        self.index = None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Node(index={self.index}, children={self.children})'\n",
    "    \n",
    "    def get(self, key, default=None):\n",
    "        return self.children.get(key, default)\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return self.children[key]\n",
    "    \n",
    "    def __setitem__(self, key, value):\n",
    "        self.children[key] = value\n",
    "        \n",
    "    def __contains__(self, key):\n",
    "        return key in self.children   \n",
    "\n",
    "def build_bpe_tree(vocab):\n",
    "    root = Node()\n",
    "    for word, index in vocab.items():\n",
    "        current_node = root\n",
    "        for n, c in enumerate(word, start=1):\n",
    "            if not c in current_node:\n",
    "                current_node[c] = Node()\n",
    "            current_node = current_node[c]\n",
    "            if n == len(word):\n",
    "                current_node.index = index\n",
    "    return root\n",
    "    \n",
    "def apply_bpe_tree(text, tree):\n",
    "    output = []\n",
    "    last_node = tree\n",
    "    pos = 0\n",
    "    while pos <= len(text) - 1:\n",
    "        node = last_node.get(text[pos])\n",
    "        if node is None:\n",
    "            output.append(last_node.index)\n",
    "            if last_node is not tree:\n",
    "                last_node = tree\n",
    "                continue\n",
    "            node = tree\n",
    "        last_node = node\n",
    "        pos += 1\n",
    "    output.append(last_node.index)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe_text = ' '.join(df_train.item_description.sample(30000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4401094"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bpe_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 iterations complete\n",
      "51 iterations complete\n",
      "101 iterations complete\n",
      "151 iterations complete\n",
      "201 iterations complete\n",
      "251 iterations complete\n",
      "301 iterations complete\n",
      "351 iterations complete\n",
      "401 iterations complete\n",
      "451 iterations complete\n",
      "501 iterations complete\n",
      "551 iterations complete\n",
      "601 iterations complete\n",
      "651 iterations complete\n",
      "701 iterations complete\n",
      "751 iterations complete\n",
      "801 iterations complete\n",
      "851 iterations complete\n",
      "901 iterations complete\n",
      "951 iterations complete\n",
      "1001 iterations complete\n",
      "1051 iterations complete\n",
      "1101 iterations complete\n",
      "1151 iterations complete\n",
      "1201 iterations complete\n",
      "1251 iterations complete\n",
      "1301 iterations complete\n",
      "1351 iterations complete\n",
      "1401 iterations complete\n",
      "1451 iterations complete\n",
      "1501 iterations complete\n",
      "1551 iterations complete\n",
      "1601 iterations complete\n",
      "1651 iterations complete\n",
      "1701 iterations complete\n",
      "1751 iterations complete\n",
      "1801 iterations complete\n",
      "1851 iterations complete\n",
      "1901 iterations complete\n",
      "1951 iterations complete\n",
      "CPU times: user 1h 5s, sys: 2min 2s, total: 1h 2min 7s\n",
      "Wall time: 1h 2min 30s\n"
     ]
    }
   ],
   "source": [
    "bpe = BytePairEncoder(2000, log_level=50)\n",
    "%time bpe.fit(bpe_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bpe.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\x16': 357,\n",
       " '!': 63,\n",
       " '!▁': 305,\n",
       " '\"': 187,\n",
       " '#': 370,\n",
       " '$': 146,\n",
       " '%': 25,\n",
       " '%▁': 96,\n",
       " '&': 193,\n",
       " \"'\": 92,\n",
       " \"'▁\": 263,\n",
       " '(': 269,\n",
       " ')': 175,\n",
       " '*': 50,\n",
       " '*▁': 323,\n",
       " '+': 348,\n",
       " ',': 3,\n",
       " ',▁': 158,\n",
       " '-': 298,\n",
       " '-▁': 366,\n",
       " '.': 18,\n",
       " '.▁': 229,\n",
       " '/': 59,\n",
       " '/▁': 148,\n",
       " '0': 116,\n",
       " '0▁': 22,\n",
       " '1': 302,\n",
       " '1▁': 210,\n",
       " '2': 170,\n",
       " '2▁': 248,\n",
       " '3': 307,\n",
       " '4': 267,\n",
       " '5': 88,\n",
       " '6': 179,\n",
       " '7': 349,\n",
       " '7▁': 33,\n",
       " '8': 131,\n",
       " '9': 120,\n",
       " ':': 74,\n",
       " ':▁': 157,\n",
       " ';': 100,\n",
       " '=': 284,\n",
       " '?': 206,\n",
       " '@': 38,\n",
       " 'A': 141,\n",
       " 'A▁': 85,\n",
       " 'B': 352,\n",
       " 'B▁': 197,\n",
       " 'C': 314,\n",
       " 'C▁': 340,\n",
       " 'D': 198,\n",
       " 'D▁': 313,\n",
       " 'E': 86,\n",
       " 'F': 174,\n",
       " 'F▁': 250,\n",
       " 'G': 294,\n",
       " 'G▁': 254,\n",
       " 'H': 371,\n",
       " 'I': 337,\n",
       " 'I▁': 14,\n",
       " 'J': 311,\n",
       " 'K': 266,\n",
       " 'K▁': 39,\n",
       " 'L': 114,\n",
       " 'L▁': 261,\n",
       " 'M': 67,\n",
       " 'M▁': 112,\n",
       " 'N': 6,\n",
       " 'N▁': 205,\n",
       " 'O': 17,\n",
       " 'P': 333,\n",
       " 'P▁': 2,\n",
       " 'Q': 281,\n",
       " 'Q▁': 106,\n",
       " 'R': 293,\n",
       " 'R▁': 165,\n",
       " 'S': 272,\n",
       " 'S▁': 223,\n",
       " 'T': 228,\n",
       " 'T▁': 336,\n",
       " 'U': 221,\n",
       " 'U▁': 234,\n",
       " 'V': 82,\n",
       " 'W': 7,\n",
       " 'W▁': 140,\n",
       " 'X': 318,\n",
       " 'X▁': 160,\n",
       " 'Y': 145,\n",
       " 'Z': 117,\n",
       " '[': 211,\n",
       " '\\\\': 91,\n",
       " ']': 132,\n",
       " '^': 346,\n",
       " '_': 195,\n",
       " 'a': 216,\n",
       " 'a▁': 364,\n",
       " 'b': 61,\n",
       " 'b▁': 4,\n",
       " 'c': 181,\n",
       " 'c▁': 274,\n",
       " 'd': 169,\n",
       " 'd▁': 144,\n",
       " 'e': 154,\n",
       " 'e▁': 162,\n",
       " 'f': 325,\n",
       " 'f▁': 184,\n",
       " 'g': 227,\n",
       " 'g▁': 324,\n",
       " 'h': 342,\n",
       " 'h▁': 90,\n",
       " 'i': 341,\n",
       " 'i▁': 83,\n",
       " 'j': 123,\n",
       " 'j▁': 65,\n",
       " 'k': 285,\n",
       " 'k▁': 156,\n",
       " 'l': 122,\n",
       " 'l▁': 60,\n",
       " 'm': 138,\n",
       " 'm▁': 335,\n",
       " 'n': 150,\n",
       " 'n▁': 317,\n",
       " 'o': 257,\n",
       " 'o▁': 369,\n",
       " 'p': 270,\n",
       " 'p▁': 280,\n",
       " 'q': 19,\n",
       " 'q▁': 41,\n",
       " 'r': 295,\n",
       " 'r▁': 368,\n",
       " 's': 99,\n",
       " 's▁': 64,\n",
       " 't': 271,\n",
       " 't▁': 35,\n",
       " 'u': 243,\n",
       " 'u▁': 36,\n",
       " 'v': 136,\n",
       " 'v▁': 105,\n",
       " 'w': 37,\n",
       " 'w▁': 300,\n",
       " 'x': 361,\n",
       " 'x▁': 218,\n",
       " 'y': 339,\n",
       " 'y▁': 331,\n",
       " 'z': 46,\n",
       " 'z▁': 202,\n",
       " '{': 358,\n",
       " '|': 62,\n",
       " '}': 190,\n",
       " '~': 304,\n",
       " '\\x7f': 55,\n",
       " '\\x96': 233,\n",
       " '\\x99': 78,\n",
       " '¡': 279,\n",
       " '¢': 288,\n",
       " '£': 344,\n",
       " '¤': 310,\n",
       " '¥': 258,\n",
       " '©': 5,\n",
       " '\\xad': 101,\n",
       " '®': 87,\n",
       " '®▁': 354,\n",
       " '°': 208,\n",
       " '±': 247,\n",
       " '·': 199,\n",
       " '»': 53,\n",
       " '¼': 52,\n",
       " '½': 143,\n",
       " '¾': 49,\n",
       " 'Á': 1,\n",
       " 'È': 27,\n",
       " 'É': 42,\n",
       " 'Ð': 29,\n",
       " 'Ô': 237,\n",
       " '×': 351,\n",
       " 'Ü': 276,\n",
       " 'á': 164,\n",
       " 'â': 80,\n",
       " 'å': 327,\n",
       " 'ç': 45,\n",
       " 'è': 26,\n",
       " 'é': 303,\n",
       " 'ë': 312,\n",
       " 'î': 110,\n",
       " 'ñ': 152,\n",
       " 'ó': 290,\n",
       " 'ô': 347,\n",
       " '÷': 245,\n",
       " 'ø': 118,\n",
       " 'ü': 72,\n",
       " 'ā': 130,\n",
       " 'Ē': 134,\n",
       " 'İ': 124,\n",
       " 'ō': 322,\n",
       " 'ɢ': 176,\n",
       " 'ɪ': 23,\n",
       " 'ɴ': 58,\n",
       " 'ʀ': 28,\n",
       " 'ʖ': 241,\n",
       " 'ʙ': 360,\n",
       " 'ʟ': 244,\n",
       " '͜': 153,\n",
       " '͡': 329,\n",
       " 'ᒪ': 97,\n",
       " 'ᔕ': 283,\n",
       " 'ᕼ': 251,\n",
       " 'ᗩ': 226,\n",
       " 'ᗰ': 16,\n",
       " 'ᴀ': 98,\n",
       " 'ᴄ': 356,\n",
       " 'ᴇ': 75,\n",
       " 'ᴍ': 278,\n",
       " 'ᴏ': 66,\n",
       " 'ᴛ': 355,\n",
       " 'ᴜ': 127,\n",
       " 'ᴡ': 171,\n",
       " 'ᴢ': 8,\n",
       " 'ᵔ': 173,\n",
       " '\\u200b': 264,\n",
       " '\\u200e': 252,\n",
       " '\\u200f': 9,\n",
       " '‑': 115,\n",
       " '–': 95,\n",
       " '—': 94,\n",
       " '‘': 32,\n",
       " '’': 286,\n",
       " '“': 291,\n",
       " '“▁': 214,\n",
       " '”': 287,\n",
       " '”▁': 239,\n",
       " '•': 326,\n",
       " '…': 236,\n",
       " '\\u202d': 104,\n",
       " '″': 277,\n",
       " '‼': 24,\n",
       " '‿': 47,\n",
       " '⁄': 167,\n",
       " '⁉': 362,\n",
       " '€': 44,\n",
       " '⃣': 103,\n",
       " '℅': 224,\n",
       " '™': 84,\n",
       " '→': 332,\n",
       " '↖': 275,\n",
       " '↘': 71,\n",
       " '↙': 220,\n",
       " '⇝': 330,\n",
       " '⇻': 231,\n",
       " '∆': 31,\n",
       " '√': 149,\n",
       " '≤': 126,\n",
       " '≥': 54,\n",
       " '⏹': 93,\n",
       " '⏺': 282,\n",
       " 'Ⓜ': 338,\n",
       " 'ⓕ': 320,\n",
       " 'ⓛ': 129,\n",
       " 'ⓞ': 255,\n",
       " 'ⓦ': 215,\n",
       " '▁': 345,\n",
       " '▁▁': 161,\n",
       " '█': 289,\n",
       " '■': 259,\n",
       " '▪': 13,\n",
       " '▫': 219,\n",
       " '▵': 186,\n",
       " '▶': 121,\n",
       " '►': 260,\n",
       " '◆': 125,\n",
       " '◇': 79,\n",
       " '◈': 222,\n",
       " '◉': 196,\n",
       " '○': 81,\n",
       " '●': 57,\n",
       " '◔': 77,\n",
       " '◕': 142,\n",
       " '◡': 139,\n",
       " '◦': 343,\n",
       " '◼': 182,\n",
       " '◾': 177,\n",
       " '☁': 128,\n",
       " '☄': 265,\n",
       " '★': 256,\n",
       " '☆': 194,\n",
       " '☇': 107,\n",
       " '☑': 133,\n",
       " '☕': 365,\n",
       " '☝': 207,\n",
       " '☞': 168,\n",
       " '☡': 217,\n",
       " '☺': 296,\n",
       " '☽': 111,\n",
       " '☾': 51,\n",
       " '♠': 299,\n",
       " '♡': 30,\n",
       " '♢': 328,\n",
       " '♤': 232,\n",
       " '♥': 119,\n",
       " '♦': 359,\n",
       " '♨': 225,\n",
       " '♻': 230,\n",
       " '⚜': 301,\n",
       " '⚠': 353,\n",
       " '⚡': 163,\n",
       " '⚪': 159,\n",
       " '⚫': 334,\n",
       " '⛅': 308,\n",
       " '⛔': 235,\n",
       " '✄': 309,\n",
       " '✅': 262,\n",
       " '✈': 183,\n",
       " '✌': 350,\n",
       " '✏': 20,\n",
       " '✓': 180,\n",
       " '✔': 321,\n",
       " '✖': 135,\n",
       " '✧': 147,\n",
       " '✨': 297,\n",
       " '✬': 70,\n",
       " '✯': 109,\n",
       " '✳': 319,\n",
       " '✴': 273,\n",
       " '✽': 372,\n",
       " '✿': 253,\n",
       " '❁': 240,\n",
       " '❃': 204,\n",
       " '❄': 209,\n",
       " '❇': 242,\n",
       " '❈': 178,\n",
       " '❉': 192,\n",
       " '❌': 238,\n",
       " '❎': 76,\n",
       " '❓': 166,\n",
       " '❕': 155,\n",
       " '❗': 292,\n",
       " '❣': 68,\n",
       " '❤': 108,\n",
       " '❥': 191,\n",
       " '❦': 15,\n",
       " '➔': 201,\n",
       " '➕': 363,\n",
       " '➖': 367,\n",
       " '➡': 172,\n",
       " '➰': 188,\n",
       " '➳': 203,\n",
       " '⠀': 212,\n",
       " '⬅': 113,\n",
       " '⬇': 249,\n",
       " '⬛': 185,\n",
       " '⭐': 11,\n",
       " '⭕': 12,\n",
       " '。': 137,\n",
       " '《': 48,\n",
       " '》': 56,\n",
       " '【': 246,\n",
       " '】': 34,\n",
       " '〰': 40,\n",
       " '゜': 102,\n",
       " '・': 213,\n",
       " 'ꕥ': 89,\n",
       " '︎': 268,\n",
       " '️': 21,\n",
       " '\\ufeff': 69,\n",
       " '！': 306,\n",
       " '（': 43,\n",
       " '）': 316,\n",
       " '＊': 189,\n",
       " '，': 315,\n",
       " '：': 200,\n",
       " '［': 10,\n",
       " '］': 151,\n",
       " '�': 73}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.21 s, sys: 120 ms, total: 5.33 s\n",
      "Wall time: 5.43 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([174, 295, 154, ..., 352, 257, 361])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time tokens = bpe.transform(bpe_text)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe._reverse_vocab = {v: k for k, v in bpe.vocab.items()}\n",
    "inv_tokens = [bpe._reverse_vocab[t] if t > 0 else '<unk>' for t in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F',\n",
       " 'r',\n",
       " 'e',\n",
       " 'e▁',\n",
       " 's',\n",
       " 'h',\n",
       " 'i',\n",
       " 'p',\n",
       " 'p',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g▁',\n",
       " 'L',\n",
       " 'i',\n",
       " 'k',\n",
       " 'e▁',\n",
       " 'n',\n",
       " 'e',\n",
       " 'w▁',\n",
       " 'L',\n",
       " 'a',\n",
       " 'l',\n",
       " 'i▁',\n",
       " 'L',\n",
       " 'a',\n",
       " 'y',\n",
       " 'l',\n",
       " 'a▁',\n",
       " 'A',\n",
       " 'r']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_tokens[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Free▁shipping▁Like▁new▁Lali▁Layla▁Ar'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(inv_tokens[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Free shipping Like new Lali Layla Ariel Top, NWT in Quartz. Super sparkly!! No longer sold, rare and'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe_text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add encodings to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time X_train['text_input'] = keras.preprocessing.sequence.pad_sequences(df_train.text.apply(bpe.transform), maxlen=40)\n",
    "%time X_test['text_input'] = keras.preprocessing.sequence.pad_sequences(df_test.text.apply(bpe.transform), maxlen=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "category_input = keras.layers.Input(shape=(1,), name='category_input')\n",
    "brand_input = keras.layers.Input(shape=(1,), name='brand_input')\n",
    "item_condition_input = keras.layers.Input(shape=(1,), name='item_condition_input')\n",
    "text_input = keras.layers.Input(shape=(None,), name='text_input')\n",
    "inputs = [category_input, brand_input, item_condition_input, text_input]\n",
    "\n",
    "# categorical feature embeddings\n",
    "category_embedding = keras.layers.Embedding(\n",
    "    input_dim=df_train.category_id.nunique()+1,\n",
    "    output_dim=3, input_length=1)(category_input)\n",
    "\n",
    "brand_embedding = keras.layers.Embedding(\n",
    "    input_dim=df_train.brand_id.nunique()+1,\n",
    "    output_dim=3, input_length=1)(brand_input)\n",
    "\n",
    "item_condition_embedding = keras.layers.Embedding(\n",
    "    input_dim=df_train.item_condition_id.nunique()+1,\n",
    "    output_dim=3, input_length=1)(item_condition_input)\n",
    "\n",
    "embedding_tensors = [category_embedding, brand_embedding, item_condition_embedding]\n",
    "x_embeddings = keras.layers.Concatenate()([\n",
    "    keras.layers.Flatten()(embedding) for embedding in embedding_tensors\n",
    "])\n",
    "\n",
    "\n",
    "# text features\n",
    "import keras.backend as K\n",
    "Sum = keras.layers.Lambda(lambda x: K.sum(x, axis=1))\n",
    "\n",
    "def SelfAttention(X):\n",
    "    dim = K.int_shape(X)[-1]\n",
    "    q = keras.layers.Dense(dim)(X)\n",
    "    k = keras.layers.Dense(dim)(X)\n",
    "    v = keras.layers.Dense(dim)(X)\n",
    "    w = keras.layers.Dot((2, 2))([q, k])\n",
    "    w = keras.layers.Softmax(axis=1)(w)\n",
    "    return keras.layers.Dot((2, 1))([w, v])\n",
    "    \n",
    "\n",
    "text_embeddings = keras.layers.Embedding(\n",
    "    input_dim=len(bpe.vocab)+1, output_dim=5, input_length=None)(text_input)\n",
    "text_embeddings = keras.layers.SpatialDropout1D(0.4)(text_embeddings)\n",
    "attention = SelfAttention(text_embeddings)\n",
    "x_text = Sum(attention)\n",
    "\n",
    "\n",
    "x = keras.layers.Concatenate()([x_embeddings, x_text])\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "x = keras.layers.Dense(K.int_shape(x)[-1], activation='relu')(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(1, activation='relu')(x)\n",
    "\n",
    "model = keras.models.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(K.log(y_pred+1.) - K.log(y_true+1.))))\n",
    "model.compile(loss=rmsle, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=25,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[keras.callbacks.ReduceLROnPlateau(patience=2),\n",
    "               keras.callbacks.EarlyStopping(patience=3),\n",
    "               keras.callbacks.TerminateOnNaN()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attention_model = keras.models.Model(inputs=descr_input, outputs=attention)\n",
    "counties, county_descriptions = df[['county', 'county_description']].drop_duplicates().T.values\n",
    "\n",
    "# process descriptions through the tokenizer\n",
    "tokens = [s[:250] for s in tokenizer.texts_to_sequences(county_descriptions)]\n",
    "county_descriptions = [t.split(' ') for t in tokenizer.sequences_to_texts(tokens)]\n",
    "\n",
    "attention_scores = attention_model.predict(keras.preprocessing.sequence.pad_sequences(tokens, maxlen=250))\n",
    "# resize the scores to eliminate redundant axis\n",
    "attention_scores = descr_attention.reshape(descr_attention.shape[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped = zip(counties, descr_texts, attention_scores)\n",
    "word_importances = [\n",
    "    (county, tuple([(w, i) for w, i in zip(description, description_importances)]))\n",
    "    for county, description, description_importances in zipped\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_word_importances = {\n",
    "    county: sorted(set(importances), key=lambda x: x[-1], reverse=True)[:10]\n",
    "     for county, importances in word_importances\n",
    "}\n",
    "county_word_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_word_importances['Del Norte County']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
