{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv('mercari-price-suggestion-challenge/train.tsv', sep='\\t')\n",
    "df_train, df_test = train_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1111901, 8), (370634, 8))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>968857</th>\n",
       "      <td>968857</td>\n",
       "      <td>Charlotte Russe Skirt</td>\n",
       "      <td>3</td>\n",
       "      <td>Women/Skirts/Mini</td>\n",
       "      <td>Charlotte Russe</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>size small in good condition not worn much</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13766</th>\n",
       "      <td>13766</td>\n",
       "      <td>Adidas Shadow Tubular</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Shoes/Athletic</td>\n",
       "      <td>Adidas</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Recently released a few days ago. Cream/grey/t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006475</th>\n",
       "      <td>1006475</td>\n",
       "      <td>2x dress</td>\n",
       "      <td>2</td>\n",
       "      <td>Women/Dresses/Above Knee, Mini</td>\n",
       "      <td>Charlotte Russe</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Charlotte Russe. Only worn for a couple hours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175496</th>\n",
       "      <td>1175496</td>\n",
       "      <td>LA Rams vs ATL Falcons 2 PREMIUM SEATS</td>\n",
       "      <td>1</td>\n",
       "      <td>Sports &amp; Outdoors/Fan Shop/NFL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>310.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Pair of Los Angeles Rams vs Atlanta Falcons (2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163835</th>\n",
       "      <td>163835</td>\n",
       "      <td>LulaRoe Randy XL</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Tops &amp; Blouses/T-Shirts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Brand new never worn. Dark purple and navy wit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         train_id                                    name  item_condition_id  \\\n",
       "968857     968857                   Charlotte Russe Skirt                  3   \n",
       "13766       13766                   Adidas Shadow Tubular                  1   \n",
       "1006475   1006475                                2x dress                  2   \n",
       "1175496   1175496  LA Rams vs ATL Falcons 2 PREMIUM SEATS                  1   \n",
       "163835     163835                        LulaRoe Randy XL                  1   \n",
       "\n",
       "                          category_name       brand_name  price  shipping  \\\n",
       "968857                Women/Skirts/Mini  Charlotte Russe   12.0         0   \n",
       "13766              Women/Shoes/Athletic           Adidas   96.0         0   \n",
       "1006475  Women/Dresses/Above Knee, Mini  Charlotte Russe   15.0         0   \n",
       "1175496  Sports & Outdoors/Fan Shop/NFL              NaN  310.0         1   \n",
       "163835    Women/Tops & Blouses/T-Shirts              NaN   32.0         1   \n",
       "\n",
       "                                          item_description  \n",
       "968857          size small in good condition not worn much  \n",
       "13766    Recently released a few days ago. Cream/grey/t...  \n",
       "1006475      Charlotte Russe. Only worn for a couple hours  \n",
       "1175496  Pair of Los Angeles Rams vs Atlanta Falcons (2...  \n",
       "163835   Brand new never worn. Dark purple and navy wit...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.111901e+06</td>\n",
       "      <td>1111901</td>\n",
       "      <td>1.111901e+06</td>\n",
       "      <td>1107127</td>\n",
       "      <td>637437</td>\n",
       "      <td>1.111901e+06</td>\n",
       "      <td>1.111901e+06</td>\n",
       "      <td>1111898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>936401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1263</td>\n",
       "      <td>4457</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>967722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Bundle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Women/Athletic Apparel/Pants, Tights, Leggings</td>\n",
       "      <td>PINK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No description yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1690</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45073</td>\n",
       "      <td>40663</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.417639e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.907211e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.671932e+01</td>\n",
       "      <td>4.474265e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.279696e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.030715e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.864842e+01</td>\n",
       "      <td>4.972286e-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.711870e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.421600e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.700000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.112531e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.900000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.482534e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.009000e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            train_id     name  item_condition_id  \\\n",
       "count   1.111901e+06  1111901       1.111901e+06   \n",
       "unique           NaN   936401                NaN   \n",
       "top              NaN   Bundle                NaN   \n",
       "freq             NaN     1690                NaN   \n",
       "mean    7.417639e+05      NaN       1.907211e+00   \n",
       "std     4.279696e+05      NaN       9.030715e-01   \n",
       "min     0.000000e+00      NaN       1.000000e+00   \n",
       "25%     3.711870e+05      NaN       1.000000e+00   \n",
       "50%     7.421600e+05      NaN       2.000000e+00   \n",
       "75%     1.112531e+06      NaN       3.000000e+00   \n",
       "max     1.482534e+06      NaN       5.000000e+00   \n",
       "\n",
       "                                         category_name brand_name  \\\n",
       "count                                          1107127     637437   \n",
       "unique                                            1263       4457   \n",
       "top     Women/Athletic Apparel/Pants, Tights, Leggings       PINK   \n",
       "freq                                             45073      40663   \n",
       "mean                                               NaN        NaN   \n",
       "std                                                NaN        NaN   \n",
       "min                                                NaN        NaN   \n",
       "25%                                                NaN        NaN   \n",
       "50%                                                NaN        NaN   \n",
       "75%                                                NaN        NaN   \n",
       "max                                                NaN        NaN   \n",
       "\n",
       "               price      shipping    item_description  \n",
       "count   1.111901e+06  1.111901e+06             1111898  \n",
       "unique           NaN           NaN              967722  \n",
       "top              NaN           NaN  No description yet  \n",
       "freq             NaN           NaN               61976  \n",
       "mean    2.671932e+01  4.474265e-01                 NaN  \n",
       "std     3.864842e+01  4.972286e-01                 NaN  \n",
       "min     0.000000e+00  0.000000e+00                 NaN  \n",
       "25%     1.000000e+01  0.000000e+00                 NaN  \n",
       "50%     1.700000e+01  0.000000e+00                 NaN  \n",
       "75%     2.900000e+01  1.000000e+00                 NaN  \n",
       "max     2.009000e+03  1.000000e+00                 NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/dgates/venvs/py3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/dgates/venvs/py3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/Users/dgates/venvs/py3/lib/python3.6/site-packages/pandas/core/frame.py:3790: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n",
      "/Users/dgates/venvs/py3/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/dgates/venvs/py3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "def make_Xy(df, *, tokenizer=None, num_words=2000, maxlen=35):\n",
    "    category_ids = {v: i for i, v in enumerate(df.category_name.unique(), start=1)}\n",
    "    brand_ids = {v: i for i, v in enumerate(df.brand_name.unique(), start=1)}\n",
    "    df['category_id'] = df.category_name.map(category_ids)\n",
    "    df['brand_id'] = df.brand_name.map(brand_ids)\n",
    "    \n",
    "    df[['category_id', 'brand_id', 'item_condition_id']].fillna(0, inplace=True)\n",
    "    df['text'] = df.name + ' ' + df.item_description.str.replace('No description yet', '')\n",
    "    df['text'] = df.text.astype(str)\n",
    "\n",
    "    X = {\n",
    "        'category_input': df.category_id,\n",
    "        'brand_input': df.brand_id,\n",
    "        'item_condition_input': df.item_condition_id\n",
    "    }\n",
    "    y = df.price\n",
    "\n",
    "    return X, y, tokenizer\n",
    "\n",
    "X_train, y_train, tokenizer = make_Xy(df_train, num_words=2000, maxlen=35)\n",
    "X_test, y_test, _ = make_Xy(df_test, tokenizer=tokenizer, num_words=2000, maxlen=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.111901e+06\n",
       "mean     2.898562e+01\n",
       "std      3.089176e+01\n",
       "min      0.000000e+00\n",
       "25%      1.000000e+01\n",
       "50%      1.900000e+01\n",
       "75%      3.500000e+01\n",
       "max      2.510000e+02\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.text.str.count(' ').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "      <th>category_id</th>\n",
       "      <th>brand_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>968857</th>\n",
       "      <td>968857</td>\n",
       "      <td>Charlotte Russe Skirt</td>\n",
       "      <td>3</td>\n",
       "      <td>Women/Skirts/Mini</td>\n",
       "      <td>Charlotte Russe</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>size small in good condition not worn much</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Charlotte Russe Skirt size small in good condi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13766</th>\n",
       "      <td>13766</td>\n",
       "      <td>Adidas Shadow Tubular</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Shoes/Athletic</td>\n",
       "      <td>Adidas</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Recently released a few days ago. Cream/grey/t...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Adidas Shadow Tubular Recently released a few ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006475</th>\n",
       "      <td>1006475</td>\n",
       "      <td>2x dress</td>\n",
       "      <td>2</td>\n",
       "      <td>Women/Dresses/Above Knee, Mini</td>\n",
       "      <td>Charlotte Russe</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Charlotte Russe. Only worn for a couple hours</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2x dress Charlotte Russe. Only worn for a coup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175496</th>\n",
       "      <td>1175496</td>\n",
       "      <td>LA Rams vs ATL Falcons 2 PREMIUM SEATS</td>\n",
       "      <td>1</td>\n",
       "      <td>Sports &amp; Outdoors/Fan Shop/NFL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>310.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Pair of Los Angeles Rams vs Atlanta Falcons (2...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>LA Rams vs ATL Falcons 2 PREMIUM SEATS Pair of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163835</th>\n",
       "      <td>163835</td>\n",
       "      <td>LulaRoe Randy XL</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Tops &amp; Blouses/T-Shirts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Brand new never worn. Dark purple and navy wit...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>LulaRoe Randy XL Brand new never worn. Dark pu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         train_id                                    name  item_condition_id  \\\n",
       "968857     968857                   Charlotte Russe Skirt                  3   \n",
       "13766       13766                   Adidas Shadow Tubular                  1   \n",
       "1006475   1006475                                2x dress                  2   \n",
       "1175496   1175496  LA Rams vs ATL Falcons 2 PREMIUM SEATS                  1   \n",
       "163835     163835                        LulaRoe Randy XL                  1   \n",
       "\n",
       "                          category_name       brand_name  price  shipping  \\\n",
       "968857                Women/Skirts/Mini  Charlotte Russe   12.0         0   \n",
       "13766              Women/Shoes/Athletic           Adidas   96.0         0   \n",
       "1006475  Women/Dresses/Above Knee, Mini  Charlotte Russe   15.0         0   \n",
       "1175496  Sports & Outdoors/Fan Shop/NFL              NaN  310.0         1   \n",
       "163835    Women/Tops & Blouses/T-Shirts              NaN   32.0         1   \n",
       "\n",
       "                                          item_description  category_id  \\\n",
       "968857          size small in good condition not worn much            1   \n",
       "13766    Recently released a few days ago. Cream/grey/t...            2   \n",
       "1006475      Charlotte Russe. Only worn for a couple hours            3   \n",
       "1175496  Pair of Los Angeles Rams vs Atlanta Falcons (2...            4   \n",
       "163835   Brand new never worn. Dark purple and navy wit...            5   \n",
       "\n",
       "         brand_id                                               text  \n",
       "968857          1  Charlotte Russe Skirt size small in good condi...  \n",
       "13766           2  Adidas Shadow Tubular Recently released a few ...  \n",
       "1006475         1  2x dress Charlotte Russe. Only worn for a coup...  \n",
       "1175496         3  LA Rams vs ATL Falcons 2 PREMIUM SEATS Pair of...  \n",
       "163835          3  LulaRoe Randy XL Brand new never worn. Dark pu...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build byte pair encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "def get_stats(list vocab):\n",
    "    cdef int i\n",
    "    cdef dict pairs = {}\n",
    "    cdef dict indices = {}\n",
    "    for i in range(len(vocab) - 1):\n",
    "        pair = vocab[i], vocab[i+1]\n",
    "        if not pair in pairs:\n",
    "            pairs[pair] = 0\n",
    "        pairs[pair] += 1\n",
    "        if not pair in indices:\n",
    "            indices[pair] = []\n",
    "        indices[pair].append(i)\n",
    "    return pairs, indices\n",
    "\n",
    "def merge_vocab(tuple pair, list vocab, list indices):\n",
    "    cdef str new = ''.join(pair)\n",
    "    cdef int i\n",
    "    for i in reversed(indices):\n",
    "        vocab[i] = new\n",
    "        vocab.pop(i+1)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import sklearn\n",
    "\n",
    "class BytePairEncoder(sklearn.base.TransformerMixin):\n",
    "    def __init__(self, n_merges, n_jobs=None):\n",
    "        self.n_merges = n_merges\n",
    "        self.n_jobs = n_jobs\n",
    "        self._space_escape = '▁'\n",
    "        self._unkown_token = 0\n",
    "\n",
    "    def fit(self, X):\n",
    "        vocab = list(self._process_X(X))\n",
    "        initial_vocab = set(vocab)\n",
    "        for i in range(self.n_merges):\n",
    "            if self.n_jobs is None:\n",
    "                pairs, pair_index = get_stats(vocab)\n",
    "            else:\n",
    "                \n",
    "            best = max(pairs, key=pairs.get)\n",
    "            vocab = merge_vocab(best, vocab, pair_index[best])\n",
    "\n",
    "        # reserve 0 for unkowns\n",
    "        vocab = set(vocab)\n",
    "        vocab.update(initial_vocab)\n",
    "        self.vocab = {k: i for i, k in enumerate(vocab, start=1)}\n",
    "        bpe._reverse_vocab = {v: k for k, v in bpe.vocab.items()}\n",
    "        self._bpe_tree = build_bpe_tree(self.vocab)\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = self._process_X(X)\n",
    "        tokens = apply_bpe_tree(X, self._bpe_tree)\n",
    "        return np.array([self._unkown_token if t is None else t for t in tokens])\n",
    "\n",
    "    def inverse_transform(self, X):\n",
    "        return [bpe._reverse_vocab[t] if t > 0 else '<unk>' for t in tokens]\n",
    "\n",
    "    def _process_X(self, X):\n",
    "         return self._space_escape.join(X.split())\n",
    "    \n",
    "    def _build_encoding_map(self):\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self):\n",
    "        self.children = {}\n",
    "        self.index = None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Node(index={self.index}, children={self.children})'\n",
    "    \n",
    "    def get(self, key, default=None):\n",
    "        return self.children.get(key, default)\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return self.children[key]\n",
    "    \n",
    "    def __setitem__(self, key, value):\n",
    "        self.children[key] = value\n",
    "        \n",
    "    def __contains__(self, key):\n",
    "        return key in self.children   \n",
    "\n",
    "def build_bpe_tree(vocab):\n",
    "    root = Node()\n",
    "    for word, index in vocab.items():\n",
    "        current_node = root\n",
    "        for n, c in enumerate(word, start=1):\n",
    "            if not c in current_node:\n",
    "                current_node[c] = Node()\n",
    "            current_node = current_node[c]\n",
    "            if n == len(word):\n",
    "                current_node.index = index\n",
    "    return root\n",
    "    \n",
    "def apply_bpe_tree(text, tree):\n",
    "    output = []\n",
    "    last_node = tree\n",
    "    pos = 0\n",
    "    while pos <= len(text) - 1:\n",
    "        node = last_node.get(text[pos])\n",
    "        if node is None:\n",
    "            output.append(last_node.index)\n",
    "            if last_node is not tree:\n",
    "                last_node = tree\n",
    "                continue\n",
    "            node = tree\n",
    "        last_node = node\n",
    "        pos += 1\n",
    "    output.append(last_node.index)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe_text = ' '.join(df_train.item_description.sample(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.1 s, sys: 85 ms, total: 13.2 s\n",
      "Wall time: 13.3 s\n"
     ]
    }
   ],
   "source": [
    "bpe = BytePairEncoder(2000, -1)\n",
    "%time bpe.fit(bpe_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1140"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bpe.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'very▁': 1,\n",
       " 'back▁': 2,\n",
       " 'ad': 3,\n",
       " '▁re': 4,\n",
       " 'gg': 5,\n",
       " 'ard▁': 6,\n",
       " \"'s▁\": 7,\n",
       " 'for▁looking': 8,\n",
       " 'clip▁on▁earrings-▁Length': 9,\n",
       " 'open': 10,\n",
       " 'clip▁on▁': 11,\n",
       " 'of▁the▁': 12,\n",
       " 'NEW▁': 13,\n",
       " 'great▁condition': 14,\n",
       " 'No▁description▁yet▁': 15,\n",
       " 'm▁s': 16,\n",
       " 'mor': 17,\n",
       " 'min': 18,\n",
       " '2': 19,\n",
       " 'All▁': 20,\n",
       " 'ensitiv': 21,\n",
       " 'wom': 22,\n",
       " 'e▁with▁': 23,\n",
       " 'oun': 24,\n",
       " 's,▁': 25,\n",
       " 'edress▁#': 26,\n",
       " 'Thank▁you': 27,\n",
       " 'or': 28,\n",
       " 'air▁': 29,\n",
       " 'a▁few▁times.▁': 30,\n",
       " '0%': 31,\n",
       " 'Soothing▁': 32,\n",
       " 'your▁p': 33,\n",
       " 'Comes▁with▁': 34,\n",
       " 'ed▁in▁': 35,\n",
       " 'h▁': 36,\n",
       " 'as▁': 37,\n",
       " 'mater': 38,\n",
       " 'great▁': 39,\n",
       " \"men's▁\": 40,\n",
       " 'peach': 41,\n",
       " '\"': 42,\n",
       " 'co': 43,\n",
       " 'but▁': 44,\n",
       " 'otherwise▁': 45,\n",
       " 'urns.▁': 46,\n",
       " '&▁': 47,\n",
       " 'any▁questions▁': 48,\n",
       " 'lu': 49,\n",
       " 'ray▁': 50,\n",
       " 'plus': 51,\n",
       " 'from▁': 52,\n",
       " 'ed▁on▁': 53,\n",
       " 'out▁': 54,\n",
       " 'gap▁': 55,\n",
       " '!▁Th': 56,\n",
       " '14': 57,\n",
       " 'men': 58,\n",
       " 'ater▁': 59,\n",
       " 'e,▁': 60,\n",
       " 'ab': 61,\n",
       " 'day,▁': 62,\n",
       " 'for▁iPhone▁': 63,\n",
       " 'es▁': 64,\n",
       " 'da': 65,\n",
       " 'eets▁': 66,\n",
       " 'ad▁': 67,\n",
       " 'me▁': 68,\n",
       " 'S▁': 69,\n",
       " 'av': 70,\n",
       " '2▁x▁': 71,\n",
       " 'ow': 72,\n",
       " '5▁': 73,\n",
       " 'combin': 74,\n",
       " 'fin': 75,\n",
       " 'over▁': 76,\n",
       " 'so': 77,\n",
       " 'free▁home▁': 78,\n",
       " 'is▁a▁': 79,\n",
       " 'app': 80,\n",
       " 'stain': 81,\n",
       " 'Hyaluron': 82,\n",
       " 'on▁': 83,\n",
       " 'z': 84,\n",
       " 'urchas': 85,\n",
       " 'has▁a▁': 86,\n",
       " 'K▁': 87,\n",
       " 'Be': 88,\n",
       " 'Medium▁': 89,\n",
       " 'ke▁': 90,\n",
       " 'able▁': 91,\n",
       " 't▁': 92,\n",
       " 'ogra': 93,\n",
       " '1-': 94,\n",
       " 'if▁you▁': 95,\n",
       " 'E▁': 96,\n",
       " 'wear▁': 97,\n",
       " 'IP': 98,\n",
       " 'color▁': 99,\n",
       " 'for▁': 100,\n",
       " 'M': 101,\n",
       " 'or▁t': 102,\n",
       " '6': 103,\n",
       " 'l': 104,\n",
       " 'H': 105,\n",
       " 'hoes▁': 106,\n",
       " 'e▁with▁b': 107,\n",
       " 'f▁': 108,\n",
       " '▁shipp': 109,\n",
       " 'kee': 110,\n",
       " 'day': 111,\n",
       " 'ter': 112,\n",
       " '▁sh': 113,\n",
       " 'id▁': 114,\n",
       " 'top': 115,\n",
       " '⭐': 116,\n",
       " 'as▁you': 117,\n",
       " 'new▁': 118,\n",
       " 'du': 119,\n",
       " 't.▁': 120,\n",
       " 'e▁s': 121,\n",
       " 'ris': 122,\n",
       " 'ch': 123,\n",
       " 'y.▁': 124,\n",
       " 'ac': 125,\n",
       " 'Note▁7▁': 126,\n",
       " '▫️F': 127,\n",
       " 'ony▁': 128,\n",
       " 'also▁': 129,\n",
       " 'my▁list': 130,\n",
       " 'bus': 131,\n",
       " '6.5▁': 132,\n",
       " '|': 133,\n",
       " 'oz': 134,\n",
       " 'se.▁': 135,\n",
       " 'ef': 136,\n",
       " '❇': 137,\n",
       " 'comfort': 138,\n",
       " 'Never▁been▁': 139,\n",
       " 'lack': 140,\n",
       " 'used.▁': 141,\n",
       " 'ic': 142,\n",
       " 'ize▁': 143,\n",
       " 'This▁is▁for▁': 144,\n",
       " 'e▁sk': 145,\n",
       " '10k▁10kt▁': 146,\n",
       " 'Ex': 147,\n",
       " '▁sm': 148,\n",
       " 'ome▁': 149,\n",
       " 'ul': 150,\n",
       " 'tion.▁': 151,\n",
       " 'SE': 152,\n",
       " 'FE': 153,\n",
       " 'ap▁': 154,\n",
       " 'ret': 155,\n",
       " 'I▁p': 156,\n",
       " '$▁Preowned▁used.▁': 157,\n",
       " 'ality▁': 158,\n",
       " 'Note▁': 159,\n",
       " 'next▁': 160,\n",
       " 'lov': 161,\n",
       " 'reme▁': 162,\n",
       " '▁pr': 163,\n",
       " 'after▁': 164,\n",
       " 'no▁p': 165,\n",
       " 'ard': 166,\n",
       " 'moke▁': 167,\n",
       " 'Se': 168,\n",
       " 'grab▁': 169,\n",
       " 'medium': 170,\n",
       " 'Whit': 171,\n",
       " 'Y▁': 172,\n",
       " 'w': 173,\n",
       " '▁in▁': 174,\n",
       " 'par': 175,\n",
       " 'o▁': 176,\n",
       " 'ears▁': 177,\n",
       " 'art▁s': 178,\n",
       " 'Mad': 179,\n",
       " 'Beautiful▁': 180,\n",
       " 'Ch': 181,\n",
       " 'ev': 182,\n",
       " 'ack': 183,\n",
       " '[rm]': 184,\n",
       " 'tion▁': 185,\n",
       " '▁shi': 186,\n",
       " 'ly.▁B': 187,\n",
       " '4': 188,\n",
       " 'iz': 189,\n",
       " 'urple▁': 190,\n",
       " ',▁never▁': 191,\n",
       " 'gold▁colored▁': 192,\n",
       " 'ES▁': 193,\n",
       " '▫️': 194,\n",
       " 'Pow': 195,\n",
       " 'wear': 196,\n",
       " 'gre': 197,\n",
       " 'Worn▁on': 198,\n",
       " 'set▁': 199,\n",
       " 'party,▁': 200,\n",
       " 'ick': 201,\n",
       " 'TI': 202,\n",
       " 'y▁material▁': 203,\n",
       " 'mar': 204,\n",
       " 'ce,▁': 205,\n",
       " 'no▁': 206,\n",
       " 'PL': 207,\n",
       " 'GLAD▁': 208,\n",
       " 'Blue▁': 209,\n",
       " 'XL': 210,\n",
       " 'ated▁': 211,\n",
       " '(': 212,\n",
       " 'p▁': 213,\n",
       " 'shipp': 214,\n",
       " 'Thank▁You▁1': 215,\n",
       " '.▁G': 216,\n",
       " 'x': 217,\n",
       " 'INAL': 218,\n",
       " 'to': 219,\n",
       " 'ott': 220,\n",
       " 'S': 221,\n",
       " 'desig': 222,\n",
       " 'ict': 223,\n",
       " 'et▁': 224,\n",
       " 'ang': 225,\n",
       " 'orts▁': 226,\n",
       " \"'s,▁\": 227,\n",
       " 'per': 228,\n",
       " 'ere▁': 229,\n",
       " 'e/': 230,\n",
       " 'mul': 231,\n",
       " 'litt': 232,\n",
       " 'nd': 233,\n",
       " 'pan': 234,\n",
       " 'fir': 235,\n",
       " 'ake▁': 236,\n",
       " 'structions▁': 237,\n",
       " 'es▁are▁': 238,\n",
       " 'll▁': 239,\n",
       " 'us': 240,\n",
       " 'yn': 241,\n",
       " 'sized▁': 242,\n",
       " ')▁A': 243,\n",
       " \"'\": 244,\n",
       " 'a▁re': 245,\n",
       " '18': 246,\n",
       " 'charger': 247,\n",
       " 'used▁': 248,\n",
       " 'you': 249,\n",
       " 'ent▁but▁': 250,\n",
       " 'bund': 251,\n",
       " '10k▁': 252,\n",
       " 'lac': 253,\n",
       " 'ailable▁': 254,\n",
       " 'dress.▁': 255,\n",
       " 'From▁': 256,\n",
       " 'OG': 257,\n",
       " 'il': 258,\n",
       " 'mediu': 259,\n",
       " 'DI': 260,\n",
       " '1': 261,\n",
       " 'dec': 262,\n",
       " 'loss': 263,\n",
       " 'ical▁': 264,\n",
       " 'les': 265,\n",
       " 'ow▁': 266,\n",
       " 'm': 267,\n",
       " 'ight': 268,\n",
       " 'inches▁With▁self▁adhesive▁seal▁': 269,\n",
       " 'ct▁': 270,\n",
       " 'pri': 271,\n",
       " 'urchase▁': 272,\n",
       " 'ent▁': 273,\n",
       " 'dings▁': 274,\n",
       " 's.▁': 275,\n",
       " 'the': 276,\n",
       " 's▁#': 277,\n",
       " 'ike▁': 278,\n",
       " 'Size▁(': 279,\n",
       " 'able': 280,\n",
       " 'h': 281,\n",
       " 'The': 282,\n",
       " 'ne': 283,\n",
       " '+▁': 284,\n",
       " 'im': 285,\n",
       " 'so▁': 286,\n",
       " 'Su': 287,\n",
       " 'e▁re': 288,\n",
       " '.5▁': 289,\n",
       " 'been▁': 290,\n",
       " 'work': 291,\n",
       " 'siz': 292,\n",
       " 'oney▁': 293,\n",
       " 'be▁': 294,\n",
       " 'Will▁come▁with▁': 295,\n",
       " 'ful▁': 296,\n",
       " 'used': 297,\n",
       " 'ear': 298,\n",
       " '.7': 299,\n",
       " 'tly▁': 300,\n",
       " 'leaning▁': 301,\n",
       " 'ie▁': 302,\n",
       " 'B': 303,\n",
       " 'offer!▁': 304,\n",
       " 'bu': 305,\n",
       " 'le▁': 306,\n",
       " 'a▁s': 307,\n",
       " '▁swe': 308,\n",
       " 'y': 309,\n",
       " 'CK': 310,\n",
       " '#floral': 311,\n",
       " 'R': 312,\n",
       " 'check▁out▁my▁': 313,\n",
       " 'y▁': 314,\n",
       " '⚠': 315,\n",
       " 'Al': 316,\n",
       " 'and▁pre': 317,\n",
       " 'gar': 318,\n",
       " 'p▁your▁': 319,\n",
       " 'rip': 320,\n",
       " 'as▁a▁': 321,\n",
       " 'new': 322,\n",
       " 'wash▁': 323,\n",
       " '▁B': 324,\n",
       " '$': 325,\n",
       " 'thin▁': 326,\n",
       " 'es!▁': 327,\n",
       " 'sp': 328,\n",
       " 'l▁': 329,\n",
       " 'la': 330,\n",
       " 'ther▁': 331,\n",
       " 'on▁le': 332,\n",
       " 'easi': 333,\n",
       " 'Night▁': 334,\n",
       " 'E': 335,\n",
       " '3': 336,\n",
       " 'Pu': 337,\n",
       " 'eng': 338,\n",
       " 's▁of▁': 339,\n",
       " 'want▁': 340,\n",
       " 'out': 341,\n",
       " 'including': 342,\n",
       " 'j': 343,\n",
       " 'Tags:▁b': 344,\n",
       " 'inc': 345,\n",
       " ']': 346,\n",
       " ':▁1': 347,\n",
       " 'ure▁': 348,\n",
       " 'ire': 349,\n",
       " 'Will▁': 350,\n",
       " 'Size▁medium': 351,\n",
       " '5$': 352,\n",
       " 'x▁L': 353,\n",
       " 'Y': 354,\n",
       " 'G': 355,\n",
       " ')▁': 356,\n",
       " 'ity▁': 357,\n",
       " '▁': 358,\n",
       " 'L': 359,\n",
       " 'Size▁': 360,\n",
       " '4▁': 361,\n",
       " '0)▁': 362,\n",
       " 'left': 363,\n",
       " '/': 364,\n",
       " '/▁D': 365,\n",
       " 'for▁[rm]': 366,\n",
       " 'do': 367,\n",
       " 'Col': 368,\n",
       " 'lin': 369,\n",
       " 'let': 370,\n",
       " 'jeans,▁': 371,\n",
       " ',▁comfortable▁': 372,\n",
       " '▁s': 373,\n",
       " 'und': 374,\n",
       " 'se': 375,\n",
       " 'Or': 376,\n",
       " 'ts,▁': 377,\n",
       " 'our': 378,\n",
       " 'atteries▁': 379,\n",
       " 'wh': 380,\n",
       " 'q': 381,\n",
       " 'et': 382,\n",
       " 'K': 383,\n",
       " 'like▁': 384,\n",
       " 'if▁': 385,\n",
       " 'on': 386,\n",
       " 'ices▁are▁': 387,\n",
       " 'of': 388,\n",
       " 'SC': 389,\n",
       " 'e': 390,\n",
       " 'NoRe': 391,\n",
       " 'can': 392,\n",
       " 'inches▁': 393,\n",
       " 'tion': 394,\n",
       " ',▁t': 395,\n",
       " \"I'\": 396,\n",
       " 'man': 397,\n",
       " 'So': 398,\n",
       " 'you▁': 399,\n",
       " 'rea': 400,\n",
       " 'Fi': 401,\n",
       " 'at▁': 402,\n",
       " 'USE': 403,\n",
       " '[rm]▁': 404,\n",
       " '#': 405,\n",
       " 'make▁': 406,\n",
       " '=': 407,\n",
       " 'ings▁': 408,\n",
       " 'W▁x▁': 409,\n",
       " 'ings!▁': 410,\n",
       " 'our▁': 411,\n",
       " 'Excell': 412,\n",
       " 'plu': 413,\n",
       " 'Z': 414,\n",
       " 'Pink': 415,\n",
       " 'all▁': 416,\n",
       " 'bundle▁': 417,\n",
       " 'in▁': 418,\n",
       " 'on▁the▁': 419,\n",
       " 'lace▁': 420,\n",
       " 'faux▁': 421,\n",
       " 'es▁+': 422,\n",
       " \"it's▁\": 423,\n",
       " 'ill': 424,\n",
       " 'irl': 425,\n",
       " 'b': 426,\n",
       " 'tions▁': 427,\n",
       " 'ro': 428,\n",
       " 'a▁small▁': 429,\n",
       " '▁G': 430,\n",
       " 'ags▁': 431,\n",
       " 'looking': 432,\n",
       " 'brand▁new▁': 433,\n",
       " 'ery▁': 434,\n",
       " '▁for▁[rm]': 435,\n",
       " '#whit': 436,\n",
       " '\"▁': 437,\n",
       " 'ton▁': 438,\n",
       " 'ing': 439,\n",
       " 'cloth': 440,\n",
       " 'n': 441,\n",
       " 'ING': 442,\n",
       " 'too▁': 443,\n",
       " 'gap▁pants▁:▁youth▁x▁large▁': 444,\n",
       " 'grunge,▁': 445,\n",
       " 'Galaxy▁Note▁7▁Case▁': 446,\n",
       " 'oly': 447,\n",
       " 'igh': 448,\n",
       " 'Good': 449,\n",
       " 'still▁': 450,\n",
       " 'OUNT': 451,\n",
       " ',▁': 452,\n",
       " 'No▁': 453,\n",
       " '▁T': 454,\n",
       " 'N': 455,\n",
       " 'know▁': 456,\n",
       " 'd▁': 457,\n",
       " 'i▁': 458,\n",
       " 'eck▁': 459,\n",
       " 'and▁': 460,\n",
       " 'Q': 461,\n",
       " 't▁condition▁': 462,\n",
       " 'o': 463,\n",
       " 'ap': 464,\n",
       " 'C': 465,\n",
       " 'not▁': 466,\n",
       " 'rat': 467,\n",
       " 'ch▁': 468,\n",
       " 'er,▁': 469,\n",
       " 'less▁': 470,\n",
       " \"I'm▁a▁\": 471,\n",
       " 'iP': 472,\n",
       " 'Viper▁Venom▁': 473,\n",
       " 'Po': 474,\n",
       " 'f': 475,\n",
       " 'lus': 476,\n",
       " 'items▁': 477,\n",
       " 'E▁A': 478,\n",
       " 'ag': 479,\n",
       " 'Magic▁Band▁': 480,\n",
       " 'oz▁Dish▁Soap▁(': 481,\n",
       " 'ta': 482,\n",
       " 'unless▁': 483,\n",
       " 'pres': 484,\n",
       " 'tens': 485,\n",
       " 'ord': 486,\n",
       " ':▁': 487,\n",
       " '_1/': 488,\n",
       " 'in': 489,\n",
       " 'U': 490,\n",
       " 'e▁': 491,\n",
       " '**': 492,\n",
       " '▁S': 493,\n",
       " 'en▁': 494,\n",
       " 'THE': 495,\n",
       " 'is▁': 496,\n",
       " 'AL': 497,\n",
       " 'om': 498,\n",
       " 'cute.▁': 499,\n",
       " 'is': 500,\n",
       " 'plac': 501,\n",
       " 'ER': 502,\n",
       " '.▁S': 503,\n",
       " 'LA': 504,\n",
       " 'em': 505,\n",
       " 'Sec': 506,\n",
       " 'dres': 507,\n",
       " 'St': 508,\n",
       " 'st': 509,\n",
       " 'ers▁': 510,\n",
       " 'ory▁': 511,\n",
       " 'ation▁': 512,\n",
       " 'ood▁': 513,\n",
       " 'eal▁': 514,\n",
       " \"'t▁\": 515,\n",
       " 'ts▁': 516,\n",
       " 'eas': 517,\n",
       " 'REA': 518,\n",
       " 'ends▁': 519,\n",
       " 'ece▁': 520,\n",
       " 'qu': 521,\n",
       " '▁c': 522,\n",
       " 'ckers▁': 523,\n",
       " 'the▁charging▁': 524,\n",
       " 'X': 525,\n",
       " '(2)▁': 526,\n",
       " 'ting▁': 527,\n",
       " 'car': 528,\n",
       " 'mon': 529,\n",
       " 'SIZE▁': 530,\n",
       " 'e.▁I': 531,\n",
       " 'di': 532,\n",
       " 'otherwi': 533,\n",
       " 'hone▁': 534,\n",
       " 'ax': 535,\n",
       " 'res': 536,\n",
       " 'e▁#whitelac': 537,\n",
       " 'Clean▁': 538,\n",
       " 'American▁': 539,\n",
       " '[': 540,\n",
       " 'per▁': 541,\n",
       " 'shi': 542,\n",
       " 'New▁Y': 543,\n",
       " 'green▁': 544,\n",
       " 'ches▁': 545,\n",
       " 'ce▁': 546,\n",
       " 'LU': 547,\n",
       " 'SHIPPING': 548,\n",
       " 'avy▁': 549,\n",
       " 'it.▁': 550,\n",
       " 'Pink▁': 551,\n",
       " 'rare▁': 552,\n",
       " 'and▁p': 553,\n",
       " 'have▁': 554,\n",
       " 'order': 555,\n",
       " 'pp': 556,\n",
       " '⭐️': 557,\n",
       " '10k': 558,\n",
       " 'color▁and▁': 559,\n",
       " 'its▁': 560,\n",
       " 'discoun': 561,\n",
       " 'use▁': 562,\n",
       " 'pi': 563,\n",
       " 'dark▁': 564,\n",
       " 'Large▁': 565,\n",
       " 'de▁': 566,\n",
       " '14k▁': 567,\n",
       " '13▁': 568,\n",
       " 'ets▁': 569,\n",
       " '10': 570,\n",
       " 'sti': 571,\n",
       " 'NWT': 572,\n",
       " 'iv': 573,\n",
       " 'cu': 574,\n",
       " 'it': 575,\n",
       " 'condition.▁': 576,\n",
       " 'stand▁': 577,\n",
       " 'Th': 578,\n",
       " 'Worn▁': 579,\n",
       " 'oot▁': 580,\n",
       " 'ust': 581,\n",
       " 'RE': 582,\n",
       " '▁FREE▁': 583,\n",
       " 'fi': 584,\n",
       " '.▁I▁': 585,\n",
       " 'bundle▁to▁sav': 586,\n",
       " 'in▁per': 587,\n",
       " '25': 588,\n",
       " 'i': 589,\n",
       " 'D': 590,\n",
       " 'el▁': 591,\n",
       " '18\"▁doll▁': 592,\n",
       " 'leep': 593,\n",
       " 'most▁': 594,\n",
       " 'never▁': 595,\n",
       " 't▁sleev': 596,\n",
       " 'MES▁': 597,\n",
       " 'prov': 598,\n",
       " 'a▁few▁tim': 599,\n",
       " 'Only▁': 600,\n",
       " 'ask▁any▁questions▁': 601,\n",
       " 'ame▁': 602,\n",
       " 'case▁': 603,\n",
       " 'saver▁': 604,\n",
       " '?': 605,\n",
       " 'ed.▁': 606,\n",
       " 'g▁': 607,\n",
       " 'ould▁fit▁': 608,\n",
       " 'O': 609,\n",
       " 'ovi': 610,\n",
       " 'ret▁': 611,\n",
       " 'are▁': 612,\n",
       " ')': 613,\n",
       " 'ed': 614,\n",
       " 'ely▁': 615,\n",
       " 'ty▁': 616,\n",
       " 'ial▁': 617,\n",
       " 'Good▁condition▁': 618,\n",
       " 'bend': 619,\n",
       " 'wi': 620,\n",
       " 'your': 621,\n",
       " 'er▁': 622,\n",
       " 'go': 623,\n",
       " 'for': 624,\n",
       " 'other▁': 625,\n",
       " 'it▁': 626,\n",
       " 'come▁in▁': 627,\n",
       " '.': 628,\n",
       " 'I▁will▁': 629,\n",
       " 'Very▁': 630,\n",
       " 'ant▁': 631,\n",
       " 'NE': 632,\n",
       " 'my▁': 633,\n",
       " 'sc': 634,\n",
       " 'Fragile▁': 635,\n",
       " 'leeve▁': 636,\n",
       " 'T▁B': 637,\n",
       " '❇️': 638,\n",
       " 'life▁': 639,\n",
       " 'has▁': 640,\n",
       " 'QU': 641,\n",
       " 'scoun': 642,\n",
       " 'he': 643,\n",
       " ':)▁': 644,\n",
       " '▁st': 645,\n",
       " 'ell': 646,\n",
       " 'USED▁': 647,\n",
       " 'or▁is▁': 648,\n",
       " 'ure': 649,\n",
       " 'card': 650,\n",
       " 'ally▁': 651,\n",
       " 'more▁': 652,\n",
       " 'W▁': 653,\n",
       " 'condition▁': 654,\n",
       " 'all': 655,\n",
       " 'ra': 656,\n",
       " 'GLA': 657,\n",
       " 'crea': 658,\n",
       " 'um': 659,\n",
       " 'fec': 660,\n",
       " 'ti': 661,\n",
       " 'pet▁free▁home.▁': 662,\n",
       " 'as▁new▁': 663,\n",
       " 'yle▁': 664,\n",
       " '!': 665,\n",
       " 'be': 666,\n",
       " 'ney▁': 667,\n",
       " 'ight▁': 668,\n",
       " 'ing▁to▁': 669,\n",
       " 'Brand▁new▁': 670,\n",
       " 'k': 671,\n",
       " 'hyd': 672,\n",
       " 'will▁': 673,\n",
       " 'typically▁': 674,\n",
       " 'I▁have▁': 675,\n",
       " 'Brand▁new▁with▁tags▁': 676,\n",
       " 'et.▁': 677,\n",
       " 'ed▁but▁': 678,\n",
       " '•PALMOLIVE▁': 679,\n",
       " 'mer': 680,\n",
       " 'les,▁': 681,\n",
       " 'I': 682,\n",
       " 'inal▁': 683,\n",
       " '!▁': 684,\n",
       " 'terior):▁': 685,\n",
       " '6▁': 686,\n",
       " 'Decal▁': 687,\n",
       " '⛔': 688,\n",
       " 'le': 689,\n",
       " 'used▁a▁few▁times.▁': 690,\n",
       " 'Galaxy▁': 691,\n",
       " 'oo': 692,\n",
       " 'ext': 693,\n",
       " 'ce': 694,\n",
       " 'Dis': 695,\n",
       " 'ic▁': 696,\n",
       " 'k▁': 697,\n",
       " 'gh': 698,\n",
       " 'guarant': 699,\n",
       " 'fits▁': 700,\n",
       " '#plus': 701,\n",
       " 'one▁pi': 702,\n",
       " 'u': 703,\n",
       " 'ks▁': 704,\n",
       " 'ular': 705,\n",
       " 'colorful▁': 706,\n",
       " '▁P': 707,\n",
       " 'pet▁': 708,\n",
       " 'day▁': 709,\n",
       " '▁1': 710,\n",
       " 'ik': 711,\n",
       " 'fl': 712,\n",
       " 'ALL': 713,\n",
       " 'You': 714,\n",
       " 'Gallon▁Tall▁Kitchen▁Quick-Tie▁': 715,\n",
       " 'ay▁': 716,\n",
       " 'Us': 717,\n",
       " 'charging▁': 718,\n",
       " 'ing.▁': 719,\n",
       " 'end': 720,\n",
       " 'IN': 721,\n",
       " 'art▁': 722,\n",
       " '8oz': 723,\n",
       " ',▁how': 724,\n",
       " 'ograp': 725,\n",
       " 'tain▁': 726,\n",
       " 'ver': 727,\n",
       " 'ew': 728,\n",
       " ':▁youth▁large▁': 729,\n",
       " 'bott': 730,\n",
       " 'ms▁': 731,\n",
       " 'au': 732,\n",
       " 'ON': 733,\n",
       " 'e,▁only▁': 734,\n",
       " 'reowned▁': 735,\n",
       " 'ship▁': 736,\n",
       " 'omp': 737,\n",
       " 'size▁': 738,\n",
       " 'ri': 739,\n",
       " '▁DE': 740,\n",
       " 'ft': 741,\n",
       " 'mp': 742,\n",
       " 'Black▁': 743,\n",
       " '.▁C': 744,\n",
       " 'Bought▁': 745,\n",
       " 'inside▁': 746,\n",
       " 'the▁': 747,\n",
       " 'condi': 748,\n",
       " 'ACK': 749,\n",
       " 'add▁': 750,\n",
       " 'rom': 751,\n",
       " 'get▁a▁': 752,\n",
       " 'floral▁': 753,\n",
       " 'card▁': 754,\n",
       " 'side▁': 755,\n",
       " 'ust▁': 756,\n",
       " 'Mon': 757,\n",
       " 'ive▁': 758,\n",
       " 'ck': 759,\n",
       " 'brand▁new': 760,\n",
       " 'by▁': 761,\n",
       " 'item': 762,\n",
       " '▁p': 763,\n",
       " 'Note▁7▁Case▁': 764,\n",
       " 'is▁a▁p': 765,\n",
       " 'good▁': 766,\n",
       " 'lease▁': 767,\n",
       " '▁shirt▁': 768,\n",
       " 'W': 769,\n",
       " 'This▁is▁a▁': 770,\n",
       " 'ain': 771,\n",
       " 'ot': 772,\n",
       " 'igns▁of▁wear': 773,\n",
       " 'ed▁with▁': 774,\n",
       " 'int▁s': 775,\n",
       " ',▁w': 776,\n",
       " 'ess': 777,\n",
       " 'hi': 778,\n",
       " 'earr': 779,\n",
       " 'hav': 780,\n",
       " 'box': 781,\n",
       " '▁BU': 782,\n",
       " 'the▁s': 783,\n",
       " 'pockets▁': 784,\n",
       " 'In': 785,\n",
       " 'bo': 786,\n",
       " 'lue▁': 787,\n",
       " 'en': 788,\n",
       " 'p': 789,\n",
       " 'ct▁FREEZER': 790,\n",
       " 'Siz': 791,\n",
       " '5': 792,\n",
       " 'ar': 793,\n",
       " '️': 794,\n",
       " 'AR': 795,\n",
       " 'each': 796,\n",
       " 'tiful▁': 797,\n",
       " 'ur': 798,\n",
       " '2▁': 799,\n",
       " 'reak': 800,\n",
       " 'D▁x▁': 801,\n",
       " 'good▁used▁': 802,\n",
       " 'ing,▁': 803,\n",
       " 'ond▁': 804,\n",
       " 'OX': 805,\n",
       " 'a▁': 806,\n",
       " 'b▁': 807,\n",
       " 'rown▁': 808,\n",
       " 'e▁in▁': 809,\n",
       " 'ing▁and▁': 810,\n",
       " 'Protec': 811,\n",
       " 'S.▁': 812,\n",
       " 'og': 813,\n",
       " 'ever▁': 814,\n",
       " 'an▁': 815,\n",
       " '▁can': 816,\n",
       " 'RA': 817,\n",
       " 'includ': 818,\n",
       " 'ewel': 819,\n",
       " 'big': 820,\n",
       " '•ZIPLOC▁Double▁Zipper▁': 821,\n",
       " '▁size▁': 822,\n",
       " 'ec': 823,\n",
       " 'es.▁': 824,\n",
       " 'Japanese▁': 825,\n",
       " 't▁s': 826,\n",
       " 'el': 827,\n",
       " \"don't▁\": 828,\n",
       " 'used,▁': 829,\n",
       " 'Please▁': 830,\n",
       " 'need▁': 831,\n",
       " 'or▁': 832,\n",
       " 'women': 833,\n",
       " 'ling▁': 834,\n",
       " 's▁': 835,\n",
       " 'ND▁': 836,\n",
       " 'Spor': 837,\n",
       " '*': 838,\n",
       " 'ould▁': 839,\n",
       " 'orang': 840,\n",
       " 'c▁': 841,\n",
       " 'ice▁': 842,\n",
       " 'enc': 843,\n",
       " 'as': 844,\n",
       " 'cr': 845,\n",
       " 'TION': 846,\n",
       " 'cable▁': 847,\n",
       " 'gold▁': 848,\n",
       " 'TH': 849,\n",
       " 'moke▁fre': 850,\n",
       " '8': 851,\n",
       " 'ens': 852,\n",
       " 'color': 853,\n",
       " 'ZE▁': 854,\n",
       " 'damag': 855,\n",
       " 'ple▁': 856,\n",
       " 'D▁': 857,\n",
       " 'provid': 858,\n",
       " 'long▁': 859,\n",
       " 'e!▁': 860,\n",
       " 'The▁': 861,\n",
       " 'ma': 862,\n",
       " 'lus▁': 863,\n",
       " 'chi': 864,\n",
       " 's:▁': 865,\n",
       " 'only▁': 866,\n",
       " 'just▁': 867,\n",
       " '▁▫️': 868,\n",
       " ':)▁Brand▁new▁': 869,\n",
       " ',▁p': 870,\n",
       " 'Wi': 871,\n",
       " '.3': 872,\n",
       " '7': 873,\n",
       " '&▁C': 874,\n",
       " '_': 875,\n",
       " 'AK': 876,\n",
       " 'ov': 877,\n",
       " 'th▁': 878,\n",
       " '▁QU': 879,\n",
       " 'in▁great▁condition▁': 880,\n",
       " 'iPhone▁': 881,\n",
       " 'ry▁': 882,\n",
       " 'lon': 883,\n",
       " '2.': 884,\n",
       " 'ts.▁': 885,\n",
       " 'with▁': 886,\n",
       " 's': 887,\n",
       " 'these▁': 888,\n",
       " 'gap▁pants▁': 889,\n",
       " 'y,▁': 890,\n",
       " 'ade▁': 891,\n",
       " 'es▁a▁sec': 892,\n",
       " 'ces▁': 893,\n",
       " 'v': 894,\n",
       " 'fit▁': 895,\n",
       " 'teri': 896,\n",
       " 'ce▁of▁': 897,\n",
       " 'P': 898,\n",
       " 'ater': 899,\n",
       " '|▁': 900,\n",
       " '%': 901,\n",
       " 'This▁is▁': 902,\n",
       " 'SH': 903,\n",
       " 'Mix▁Lightweight▁polymailers▁shipping▁envelopes▁Water▁proof▁&▁tear▁proof▁Measures▁': 904,\n",
       " 'ors▁': 905,\n",
       " '•5ct▁Bags▁GLAD▁W/▁': 906,\n",
       " 'Has▁': 907,\n",
       " 'th▁s': 908,\n",
       " 'Thank▁': 909,\n",
       " 'grip▁': 910,\n",
       " 'Michael▁Kors▁': 911,\n",
       " 'of▁': 912,\n",
       " 'se▁': 913,\n",
       " 'ing▁': 914,\n",
       " \"Size▁6▁gap▁Jean▁shorts▁New▁All▁new▁black▁phone▁grip▁and▁Stan.▁Never▁drop▁your▁phone,▁take▁better▁selfie's,▁prop▁your▁phone▁down▁to▁watch▁videos.▁One▁size▁fits▁all.▁You▁can▁grab▁it,▁make▁it▁stand,▁and▁wrap▁your▁headphones▁around▁it!!▁#PopSockets▁#BlackPopSocket▁#Tillys▁#PhoneGroup▁#Kickstand▁#PhoneGripAndStand▁Metallic▁silver.▁Brand▁new▁with▁original▁box.▁Color▁is▁black▁on▁dark▁grey.▁Black▁is▁faux▁leather.▁Size▁medium.▁Very▁comfortable▁chic▁jacket.▁Has▁hoodies.▁Pockets▁on▁both▁sides.▁As▁can▁see,▁only▁swatched.▁In▁shade▁Golden▁Peach▁03▁(color▁from▁picture▁is▁more▁peachy▁than▁in▁person,▁it's▁actually▁more▁Golden).▁Comes▁with▁box.▁Cream▁.24fl▁oz./▁7▁ml▁Powder▁.07▁oz./▁2.2g▁100%▁authentic.▁Bought▁for▁[rm]▁Price▁is▁firm,▁bundle▁to▁save.▁This▁outfit▁is▁cheery▁and▁bright▁and▁preloved▁but▁has▁a▁ton▁of▁life▁left!▁Top▁is▁a▁pullover▁hoodie▁and▁has▁butterfly▁embroidered▁on▁front▁and▁leggings▁are▁soft▁and▁smooth▁with▁bright▁colorful▁stripes.▁This▁has▁some▁wash▁wear▁I▁don't▁see▁any▁stains▁or▁holes▁(Please▁check▁out▁my▁closet▁I▁am▁cleaning▁out▁my▁daughter's▁playroom▁and▁closet▁and▁I▁will▁make▁you▁an▁awesome▁deal▁if▁you▁want▁anything▁else!)▁No▁description▁yet▁I▁probably▁only▁wore▁these▁out▁4▁times!▁They're▁too▁small▁on▁me.▁I▁love▁them▁though,▁they're▁in▁great▁condition!!▁I▁bought▁them▁for▁[rm]▁at▁Dicks▁Sporting▁Goods.▁Used▁but▁still▁in▁great▁condition▁because▁it's▁an▁old▁love▁so▁I▁took▁good▁care▁of▁it.▁Men's▁large▁but▁hangs▁nicely▁if▁you▁like▁over-sized▁clothing.▁Has▁minor▁paint▁stain▁on▁left▁sleeve.▁It's▁all▁good▁Velvet▁Smooth▁Express▁Pedicure▁Unit▁with▁2▁extra▁replacement▁rollers▁with▁Diamond▁Crystals▁Roller▁Head,▁Brand▁New▁Package▁includes:▁1▁x▁Electrical▁Foot▁File▁1▁x▁Coarse▁Roller▁Head▁1▁x▁Cover▁2▁x▁Replacement▁Rollers▁Requires▁4▁x▁AA▁Batteries▁(not▁included)▁Retails▁at▁[rm]▁&▁[rm]▁This▁is▁for▁(2)▁Nivea▁Soft▁Creme▁-▁6.8oz▁Brand▁new.▁Thank▁you.▁Very▁good▁condition.▁Nice▁and▁clean,▁comfortable▁good▁grip▁and▁nice▁laces.▁No▁description▁yet▁New▁Black,▁grey,▁white▁nikes▁Youth▁size▁6.5▁Comes▁with▁original▁box▁New▁Travel▁size▁Color:▁PLATH▁1.7▁ounces▁spray▁bottled▁used▁a▁few▁times.▁No▁box.▁Shirts▁from▁bundle▁Never▁Used.▁Excellent▁condition▁Color:Brown▁Is▁\": 915,\n",
       " 'tr': 916,\n",
       " '▁smoo': 917,\n",
       " 's▁P': 918,\n",
       " '▁small▁': 919,\n",
       " 'ps▁': 920,\n",
       " 'po': 921,\n",
       " 'lea': 922,\n",
       " 'sell': 923,\n",
       " \"Victoria's▁Sec\": 924,\n",
       " 'an': 925,\n",
       " 'erry▁': 926,\n",
       " 'minimal▁': 927,\n",
       " 'original▁': 928,\n",
       " 'in.▁': 929,\n",
       " 'Brand▁': 930,\n",
       " 'in▁st': 931,\n",
       " 'aw': 932,\n",
       " 'envelop': 933,\n",
       " 'free▁': 934,\n",
       " 'gen': 935,\n",
       " 'Protector▁': 936,\n",
       " 'tiv': 937,\n",
       " 'bab': 938,\n",
       " 'Ba': 939,\n",
       " 'aver▁': 940,\n",
       " 'd': 941,\n",
       " 'design▁': 942,\n",
       " 'tear': 943,\n",
       " 'arg': 944,\n",
       " 'hand': 945,\n",
       " ',▁s': 946,\n",
       " 'ty,▁': 947,\n",
       " 'White▁': 948,\n",
       " '-▁': 949,\n",
       " 'the▁charging▁cable▁': 950,\n",
       " '(2': 951,\n",
       " '▁sleeve▁': 952,\n",
       " 'com': 953,\n",
       " 'ned▁': 954,\n",
       " 'jean': 955,\n",
       " 'side▁with▁': 956,\n",
       " '▫': 957,\n",
       " '▁shir': 958,\n",
       " 'oll': 959,\n",
       " 'black▁': 960,\n",
       " '-▁All▁': 961,\n",
       " 'yl': 962,\n",
       " 's▁E': 963,\n",
       " '1▁': 964,\n",
       " 'lif': 965,\n",
       " 'OU': 966,\n",
       " 'generation▁': 967,\n",
       " '&': 968,\n",
       " 'col': 969,\n",
       " 'ipp': 970,\n",
       " 'irls▁': 971,\n",
       " 'V': 972,\n",
       " 'es': 973,\n",
       " '3▁': 974,\n",
       " 'tim': 975,\n",
       " 'list': 976,\n",
       " 'pants▁': 977,\n",
       " 'shir': 978,\n",
       " 'F': 979,\n",
       " 'your▁': 980,\n",
       " 'ther': 981,\n",
       " 'ed.▁M': 982,\n",
       " 'cell': 983,\n",
       " 'over': 984,\n",
       " 'cas': 985,\n",
       " 'or▁s': 986,\n",
       " '-': 987,\n",
       " 'ound▁': 988,\n",
       " 'and': 989,\n",
       " ',▁and▁': 990,\n",
       " '15': 991,\n",
       " '2x': 992,\n",
       " 'EL': 993,\n",
       " 're': 994,\n",
       " '9': 995,\n",
       " 'floral': 996,\n",
       " 'ight▁p': 997,\n",
       " '2:00▁p.m▁central▁': 998,\n",
       " '▁sk': 999,\n",
       " 'ry': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.5 ms, sys: 1.07 ms, total: 19.5 ms\n",
      "Wall time: 19.5 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 915,  367, 1069, ...,    4,    0,    0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time tokens = bpe.transform(bpe_text)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Size▁6▁gap▁Jean▁shorts▁New▁All▁new▁black▁phone▁grip▁and▁Stan.▁Never▁drop▁your▁phone,▁take▁better▁sel'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe._reverse_vocab = {v: k for k, v in bpe.vocab.items()}\n",
    "inv_tokens = [bpe._reverse_vocab[t] if t > 0 else '<unk>' for t in tokens]\n",
    "''.join(inv_tokens)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Size 6 gap Jean shorts New All new black phone grip and Stan. Never drop your phone, take better sel'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe_text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "category_input = keras.layers.Input(shape=(1,), name='category_input')\n",
    "brand_input = keras.layers.Input(shape=(1,), name='brand_input')\n",
    "item_condition_input = keras.layers.Input(shape=(1,), name='item_condition_input')\n",
    "text_input = keras.layers.Input(shape=(None,), name='text_input')\n",
    "inputs = [category_input, brand_input, item_condition_input, text_input]\n",
    "\n",
    "# categorical feature embeddings\n",
    "category_embedding = keras.layers.Embedding(\n",
    "    input_dim=df_train.category_id.nunique()+1,\n",
    "    output_dim=3, input_length=1)(category_input)\n",
    "\n",
    "brand_embedding = keras.layers.Embedding(\n",
    "    input_dim=df_train.brand_id.nunique()+1,\n",
    "    output_dim=3, input_length=1)(brand_input)\n",
    "\n",
    "item_condition_embedding = keras.layers.Embedding(\n",
    "    input_dim=df_train.item_condition_id.nunique()+1,\n",
    "    output_dim=3, input_length=1)(item_condition_input)\n",
    "\n",
    "embedding_tensors = [category_embedding, brand_embedding, item_condition_embedding]\n",
    "x_embeddings = keras.layers.Concatenate()([\n",
    "    keras.layers.Flatten()(embedding) for embedding in embedding_tensors\n",
    "])\n",
    "\n",
    "\n",
    "# text features\n",
    "import keras.backend as K\n",
    "Sum = keras.layers.Lambda(lambda x: K.sum(x, axis=1))\n",
    "\n",
    "def SelfAttention(X):\n",
    "    dim = K.int_shape(X)[-1]\n",
    "    q = keras.layers.Dense(dim)(X)\n",
    "    k = keras.layers.Dense(dim)(X)\n",
    "    v = keras.layers.Dense(dim)(X)\n",
    "    w = keras.layers.Dot((2, 2))([q, k])\n",
    "    w = keras.layers.Softmax(axis=1)(w)\n",
    "    return keras.layers.Dot((2, 1))([w, v])\n",
    "    \n",
    "\n",
    "text_embeddings = keras.layers.Embedding(\n",
    "    input_dim=2000, output_dim=5, input_length=None)(text_input)\n",
    "text_embeddings = keras.layers.SpatialDropout1D(0.4)(text_embeddings)\n",
    "attention = SelfAttention(text_embeddings)\n",
    "x_text = Sum(attention)\n",
    "\n",
    "\n",
    "x = keras.layers.Concatenate()([x_embeddings, x_text])\n",
    "x = keras.layers.Dense(K.int_shape(x)[-1], activation='relu')(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(1, activation='relu')(x)\n",
    "\n",
    "model = keras.models.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(K.log(y_pred+1.) - K.log(y_true+1.))))\n",
    "model.compile(loss=rmsle, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=25,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[keras.callbacks.ReduceLROnPlateau(patience=2),\n",
    "               keras.callbacks.EarlyStopping(patience=3),\n",
    "               keras.callbacks.TerminateOnNaN()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attention_model = keras.models.Model(inputs=descr_input, outputs=attention)\n",
    "counties, county_descriptions = df[['county', 'county_description']].drop_duplicates().T.values\n",
    "\n",
    "# process descriptions through the tokenizer\n",
    "tokens = [s[:250] for s in tokenizer.texts_to_sequences(county_descriptions)]\n",
    "county_descriptions = [t.split(' ') for t in tokenizer.sequences_to_texts(tokens)]\n",
    "\n",
    "attention_scores = attention_model.predict(keras.preprocessing.sequence.pad_sequences(tokens, maxlen=250))\n",
    "# resize the scores to eliminate redundant axis\n",
    "attention_scores = descr_attention.reshape(descr_attention.shape[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped = zip(counties, descr_texts, attention_scores)\n",
    "word_importances = [\n",
    "    (county, tuple([(w, i) for w, i in zip(description, description_importances)]))\n",
    "    for county, description, description_importances in zipped\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_word_importances = {\n",
    "    county: sorted(set(importances), key=lambda x: x[-1], reverse=True)[:10]\n",
    "     for county, importances in word_importances\n",
    "}\n",
    "county_word_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_word_importances['Del Norte County']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
